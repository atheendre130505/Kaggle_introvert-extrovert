{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c39329dad7b446d8aaead940e47ad527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccc4b81f47774e5b966f524178711a89",
              "IPY_MODEL_691a83e46ac14631a59f62d34cab9538",
              "IPY_MODEL_d7d2862cab4d406c9c98b668e725d11a"
            ],
            "layout": "IPY_MODEL_a65871abdd004b0c8e4535578472bfce"
          }
        },
        "ccc4b81f47774e5b966f524178711a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb9e80d138147eba5078b8baf8aa46e",
            "placeholder": "​",
            "style": "IPY_MODEL_931eba48a72941fca731cb4a29a96ead",
            "value": "100%"
          }
        },
        "691a83e46ac14631a59f62d34cab9538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_833162570fa54e11871f5449226b728d",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_436a830b7bb34078858269d84c632993",
            "value": 30
          }
        },
        "d7d2862cab4d406c9c98b668e725d11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52ee6b8066840cea6df064c96d9168e",
            "placeholder": "​",
            "style": "IPY_MODEL_b5c51ad9b38244cea9b342ea86a8c4fb",
            "value": " 30/30 [00:02&lt;00:00, 15.31it/s]"
          }
        },
        "a65871abdd004b0c8e4535578472bfce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb9e80d138147eba5078b8baf8aa46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931eba48a72941fca731cb4a29a96ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "833162570fa54e11871f5449226b728d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436a830b7bb34078858269d84c632993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d52ee6b8066840cea6df064c96d9168e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c51ad9b38244cea9b342ea86a8c4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba89cc0152e49c0b1332d515961edf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e3c442806494855a66d18fa9eac94b9",
              "IPY_MODEL_8329c23aa493436ca607db06b2b307a2",
              "IPY_MODEL_03fdbec91d1c4436b5c3d6d08904e6a4"
            ],
            "layout": "IPY_MODEL_355e929d0e9e4f569b2dcee78212b363"
          }
        },
        "2e3c442806494855a66d18fa9eac94b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428fe6abe1c041f5ba09d6ae853392a1",
            "placeholder": "​",
            "style": "IPY_MODEL_f1b95b95cf1448cc81a9e187e6a1f3cf",
            "value": "100%"
          }
        },
        "8329c23aa493436ca607db06b2b307a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226e75ed61bc4cedb126209499dace48",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_987100523af74c82b6e9aaae2459cde1",
            "value": 30
          }
        },
        "03fdbec91d1c4436b5c3d6d08904e6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a077ee00de194348b8a044c832a8a8d5",
            "placeholder": "​",
            "style": "IPY_MODEL_3dcd7960457a4b568650355392b9c644",
            "value": " 30/30 [00:02&lt;00:00, 14.12it/s]"
          }
        },
        "355e929d0e9e4f569b2dcee78212b363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "428fe6abe1c041f5ba09d6ae853392a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b95b95cf1448cc81a9e187e6a1f3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "226e75ed61bc4cedb126209499dace48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987100523af74c82b6e9aaae2459cde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a077ee00de194348b8a044c832a8a8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcd7960457a4b568650355392b9c644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7da430355314dbe97830de8c1026616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77bec4879e42421a9ac18484fddd23c3",
              "IPY_MODEL_f694fafe03eb40f4800b18e1d993a6ba",
              "IPY_MODEL_8cef777dab5a4bf6a3bf394f3e825616"
            ],
            "layout": "IPY_MODEL_255fd2efbf5546ebba0d4ef2ea454093"
          }
        },
        "77bec4879e42421a9ac18484fddd23c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95596167d7fa48688becf315a723e34e",
            "placeholder": "​",
            "style": "IPY_MODEL_a070319691954ae09e8ebcb8df856c66",
            "value": "  0%"
          }
        },
        "f694fafe03eb40f4800b18e1d993a6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf117e1241349f8b8b6e5ad1d87dd53",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7507e2c3d9c1447eb1b7a74eaf2b28ee",
            "value": 0
          }
        },
        "8cef777dab5a4bf6a3bf394f3e825616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c54156166674ac3850843c62b39d502",
            "placeholder": "​",
            "style": "IPY_MODEL_b1db8b4a00e146529724efd6c1d355bc",
            "value": " 0/30 [00:51&lt;?, ?it/s]"
          }
        },
        "255fd2efbf5546ebba0d4ef2ea454093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95596167d7fa48688becf315a723e34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a070319691954ae09e8ebcb8df856c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf117e1241349f8b8b6e5ad1d87dd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7507e2c3d9c1447eb1b7a74eaf2b28ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c54156166674ac3850843c62b39d502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1db8b4a00e146529724efd6c1d355bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8785bd4e2b0c4e0eb80bccae934ee390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18a4e9b288114a70bb82172ee4d97cd0",
              "IPY_MODEL_cdbec4cc99f24521927f2d19f89c49f6",
              "IPY_MODEL_a4f3309341b445aba7555670c146f072"
            ],
            "layout": "IPY_MODEL_20132234b4054dc2b5556400ed824f79"
          }
        },
        "18a4e9b288114a70bb82172ee4d97cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97926d148fbe4f0985d8ccdd62c7a384",
            "placeholder": "​",
            "style": "IPY_MODEL_1d507362973c4b63a3f31f8a8914778c",
            "value": " 13%"
          }
        },
        "cdbec4cc99f24521927f2d19f89c49f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2bc64c5c6d429399961acea9542baf",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adf48420e12a49c0b6667a3495b77291",
            "value": 4
          }
        },
        "a4f3309341b445aba7555670c146f072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9d664f299547a1873966436ee177f3",
            "placeholder": "​",
            "style": "IPY_MODEL_f742f4d9db2d43748e71df1644e31ee0",
            "value": " 4/30 [00:14&lt;01:31,  3.51s/it]"
          }
        },
        "20132234b4054dc2b5556400ed824f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97926d148fbe4f0985d8ccdd62c7a384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d507362973c4b63a3f31f8a8914778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d2bc64c5c6d429399961acea9542baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf48420e12a49c0b6667a3495b77291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9d664f299547a1873966436ee177f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f742f4d9db2d43748e71df1644e31ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84365e81f2245618baac99e60fb3f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03cccf2b05f14d7f9bbd147cad2ac3bf",
              "IPY_MODEL_2e6a5830d38b4fb5bd7fb1a704b04582",
              "IPY_MODEL_a0a964736d8544c1842ca8fba808d3e6"
            ],
            "layout": "IPY_MODEL_66341af7d1974296a36cd4e9bc65d7b6"
          }
        },
        "03cccf2b05f14d7f9bbd147cad2ac3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_017ecc2863904f22af06c01b672bc472",
            "placeholder": "​",
            "style": "IPY_MODEL_5a45365565414fb38467d31cb656972f",
            "value": " 13%"
          }
        },
        "2e6a5830d38b4fb5bd7fb1a704b04582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1fa754f1884d9f931de6060d84554d",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b0fb24b5d4049c391d9677ec0c75c61",
            "value": 4
          }
        },
        "a0a964736d8544c1842ca8fba808d3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ab743576124b8991cf846d43d56ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_b222b125edcd49ecb1ff1b327f1dceef",
            "value": " 4/30 [00:34&lt;03:32,  8.18s/it]"
          }
        },
        "66341af7d1974296a36cd4e9bc65d7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017ecc2863904f22af06c01b672bc472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a45365565414fb38467d31cb656972f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1fa754f1884d9f931de6060d84554d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0fb24b5d4049c391d9677ec0c75c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02ab743576124b8991cf846d43d56ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b222b125edcd49ecb1ff1b327f1dceef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f481ce154a5246219b4f738caa73f800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02f4f95143c34f5ca11391a6317dcf40",
              "IPY_MODEL_2808e94f4d8d48e4a053818e4188c402",
              "IPY_MODEL_91e69df7a9e8490cad9507cd9b66dcfe"
            ],
            "layout": "IPY_MODEL_048f8b4d196e4c46a74309a65322e676"
          }
        },
        "02f4f95143c34f5ca11391a6317dcf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f199952bf664a618758b1cb2aab6f0f",
            "placeholder": "​",
            "style": "IPY_MODEL_4c6a40cfafd84f6f9024ce11246e11d9",
            "value": " 13%"
          }
        },
        "2808e94f4d8d48e4a053818e4188c402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb3256755bab48cda6147ba83b0de81d",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28445be6c5e64f1b9b6eeb4444fabbe3",
            "value": 4
          }
        },
        "91e69df7a9e8490cad9507cd9b66dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59104cc94c684fbca96fe5519978a94d",
            "placeholder": "​",
            "style": "IPY_MODEL_ac00cc733d0c4829b1362d32c8d2e594",
            "value": " 4/30 [00:26&lt;02:52,  6.65s/it]"
          }
        },
        "048f8b4d196e4c46a74309a65322e676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f199952bf664a618758b1cb2aab6f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6a40cfafd84f6f9024ce11246e11d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb3256755bab48cda6147ba83b0de81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28445be6c5e64f1b9b6eeb4444fabbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59104cc94c684fbca96fe5519978a94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac00cc733d0c4829b1362d32c8d2e594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b962a6280593465e964f5c183f59d5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b889aae98f784de39889cc5ce4f684d7",
              "IPY_MODEL_47c6680c2e194894b3ac5347ca5ff8d7",
              "IPY_MODEL_b03dc453e7b743d8a0ad62e6dba609df"
            ],
            "layout": "IPY_MODEL_c6618df65c6543f7a33c9fc360919a97"
          }
        },
        "b889aae98f784de39889cc5ce4f684d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a98602e9de41dcad80d2669f85148d",
            "placeholder": "​",
            "style": "IPY_MODEL_0bfac231533d44f6961d13a9c893de7e",
            "value": "  0%"
          }
        },
        "47c6680c2e194894b3ac5347ca5ff8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79625709ea734a0cb9a57bac065c021e",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c4a446636f7412ca53fdc029cd50d50",
            "value": 0
          }
        },
        "b03dc453e7b743d8a0ad62e6dba609df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0ee7c7d2064b9595d4c69dc51ea2c9",
            "placeholder": "​",
            "style": "IPY_MODEL_7c57e37bd8ae41d7bce9e9fa4c60f34a",
            "value": " 0/30 [01:10&lt;?, ?it/s]"
          }
        },
        "c6618df65c6543f7a33c9fc360919a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a98602e9de41dcad80d2669f85148d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bfac231533d44f6961d13a9c893de7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79625709ea734a0cb9a57bac065c021e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4a446636f7412ca53fdc029cd50d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc0ee7c7d2064b9595d4c69dc51ea2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c57e37bd8ae41d7bce9e9fa4c60f34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38dc98c7b6184e1d98a69393533b39fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1892a2c0c17549a6b723ad2a54c642be",
              "IPY_MODEL_dc0b68caa7974ba7ac4e0becdfe7de49",
              "IPY_MODEL_17580d9fecfd47e795b81c2786183f77"
            ],
            "layout": "IPY_MODEL_102c6afe69184509a82462759d33ba9e"
          }
        },
        "1892a2c0c17549a6b723ad2a54c642be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159860a22fa1436893a0bbf8f2a578b8",
            "placeholder": "​",
            "style": "IPY_MODEL_445561923e8f42ca85e4b6f40f717e9c",
            "value": "  0%"
          }
        },
        "dc0b68caa7974ba7ac4e0becdfe7de49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_203d247587b04924a400c1592ef4417e",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb21db6c3b2d4ca3a21d6b5b6f000e13",
            "value": 0
          }
        },
        "17580d9fecfd47e795b81c2786183f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4091c02a4149b69502962743e3b73f",
            "placeholder": "​",
            "style": "IPY_MODEL_dba96f4dddf44c708380175993358aa6",
            "value": " 0/30 [01:10&lt;?, ?it/s]"
          }
        },
        "102c6afe69184509a82462759d33ba9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159860a22fa1436893a0bbf8f2a578b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445561923e8f42ca85e4b6f40f717e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "203d247587b04924a400c1592ef4417e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb21db6c3b2d4ca3a21d6b5b6f000e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e4091c02a4149b69502962743e3b73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba96f4dddf44c708380175993358aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e417577cb2a4348b9abf18abef2d0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5a60e0feb4c493b81e179cc7bf45ff6",
              "IPY_MODEL_8e669b9ec6d04113b93b8be16615b8a8",
              "IPY_MODEL_f7899670b4e1499180a8ae47707f5d34"
            ],
            "layout": "IPY_MODEL_737568be2b5f46c3a7d855a7efef1264"
          }
        },
        "a5a60e0feb4c493b81e179cc7bf45ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98922b521f84463c947e35b662ed7328",
            "placeholder": "​",
            "style": "IPY_MODEL_c16a6ca2bd1749e792400c4b3c51637d",
            "value": "100%"
          }
        },
        "8e669b9ec6d04113b93b8be16615b8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c698d0a5b6418ab7c992c2425eb71a",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b82a5c59d454448a3aaa42dd7a24011",
            "value": 30
          }
        },
        "f7899670b4e1499180a8ae47707f5d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04d71c9b1b946fcbf5fcf70f82a2889",
            "placeholder": "​",
            "style": "IPY_MODEL_12021108647a4497b9649850c02b01fb",
            "value": " 30/30 [00:03&lt;00:00,  9.89it/s]"
          }
        },
        "737568be2b5f46c3a7d855a7efef1264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98922b521f84463c947e35b662ed7328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16a6ca2bd1749e792400c4b3c51637d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7c698d0a5b6418ab7c992c2425eb71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b82a5c59d454448a3aaa42dd7a24011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d04d71c9b1b946fcbf5fcf70f82a2889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12021108647a4497b9649850c02b01fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0cf9f606ad40c4a7114579124ac69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_440d1124dcee4dd092602ee99f575de1",
              "IPY_MODEL_5d080788644e4d11a6adec9419033465",
              "IPY_MODEL_a1c6e3bd82764a8f80d0c8c3b69950c5"
            ],
            "layout": "IPY_MODEL_b0afe170ac9849c2bb3e3fd2dd1c7934"
          }
        },
        "440d1124dcee4dd092602ee99f575de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26c430c4b3b94f66bff1f37e71136c58",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e3df5b98d641d1b10d131795b27ad2",
            "value": "100%"
          }
        },
        "5d080788644e4d11a6adec9419033465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04fdb179674b44ef94b72dc11f033a48",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ee39e662f54a148559d41e6959477b",
            "value": 30
          }
        },
        "a1c6e3bd82764a8f80d0c8c3b69950c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881cf0b64c5645008d8b0aac3539e87c",
            "placeholder": "​",
            "style": "IPY_MODEL_661b9a57754b4a97805aa6e3651af97a",
            "value": " 30/30 [00:03&lt;00:00,  9.31it/s]"
          }
        },
        "b0afe170ac9849c2bb3e3fd2dd1c7934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c430c4b3b94f66bff1f37e71136c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e3df5b98d641d1b10d131795b27ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04fdb179674b44ef94b72dc11f033a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ee39e662f54a148559d41e6959477b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "881cf0b64c5645008d8b0aac3539e87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661b9a57754b4a97805aa6e3651af97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05febd38b2f24a56bff8aa721bbfd670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3266e99198854abe8e8ab6e9656a4d98",
              "IPY_MODEL_ec67825488cb471b91e127f854d24769",
              "IPY_MODEL_e92e5aa3da7345f5886f0c0492d1e650"
            ],
            "layout": "IPY_MODEL_53fa2ce84424481ba97b0283f43eec8f"
          }
        },
        "3266e99198854abe8e8ab6e9656a4d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c384b922eb624323ab64f8e58a21f0fc",
            "placeholder": "​",
            "style": "IPY_MODEL_f65b5a4ccd384d039545456d314fed7a",
            "value": "  0%"
          }
        },
        "ec67825488cb471b91e127f854d24769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22dc3d989da414d81f8e00513f5f7a8",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b55dbf3b6d444c2b9226065fd9bf40c9",
            "value": 0
          }
        },
        "e92e5aa3da7345f5886f0c0492d1e650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b39ce4bfe5445a8db4673a98bd2e0f",
            "placeholder": "​",
            "style": "IPY_MODEL_37aa925388be4739af4eabdd0a29c5ab",
            "value": " 0/30 [01:31&lt;?, ?it/s]"
          }
        },
        "53fa2ce84424481ba97b0283f43eec8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c384b922eb624323ab64f8e58a21f0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65b5a4ccd384d039545456d314fed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a22dc3d989da414d81f8e00513f5f7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55dbf3b6d444c2b9226065fd9bf40c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60b39ce4bfe5445a8db4673a98bd2e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37aa925388be4739af4eabdd0a29c5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c6fcc09805454e94d8d8661d228dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ed9783e32734901832c9caef8bb6d72",
              "IPY_MODEL_e0a62cec56be4080a2d49264ba933789",
              "IPY_MODEL_321d9bbadb354f6bad1aaf05e3d489a6"
            ],
            "layout": "IPY_MODEL_672f4f2486ea4cfbbdef3074016e4227"
          }
        },
        "1ed9783e32734901832c9caef8bb6d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7663047b4a4e0faeddaf9d843c72a5",
            "placeholder": "​",
            "style": "IPY_MODEL_ce770371a07a409b868df7d19c21c362",
            "value": " 13%"
          }
        },
        "e0a62cec56be4080a2d49264ba933789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36cccf3096e4952a4d471b705dd4b68",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d615dbc43d8543d0a88f7ae961d1e4a4",
            "value": 4
          }
        },
        "321d9bbadb354f6bad1aaf05e3d489a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d467c49f9d4c85a04f31b2ca4e4088",
            "placeholder": "​",
            "style": "IPY_MODEL_7eda72381f2e4606a9905b810ef69734",
            "value": " 4/30 [00:29&lt;02:54,  6.73s/it]"
          }
        },
        "672f4f2486ea4cfbbdef3074016e4227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7663047b4a4e0faeddaf9d843c72a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce770371a07a409b868df7d19c21c362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d36cccf3096e4952a4d471b705dd4b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d615dbc43d8543d0a88f7ae961d1e4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d467c49f9d4c85a04f31b2ca4e4088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eda72381f2e4606a9905b810ef69734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "934d5975eb394fae9e4335ddedf40f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cc267492bc94d21b8fb50e12404ab67",
              "IPY_MODEL_ea2626d75c694c6e9a681e61295985b4",
              "IPY_MODEL_bb64b6b43c1d47f4a40a42f4d1d033db"
            ],
            "layout": "IPY_MODEL_95485a544c80418cb73aaad5a01b5066"
          }
        },
        "8cc267492bc94d21b8fb50e12404ab67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c13137b440544bc9069716da1c80cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_93d0fb8acdf04f75b567564972a07c06",
            "value": " 13%"
          }
        },
        "ea2626d75c694c6e9a681e61295985b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fc3cdc8bd6a4e079481ba636de4649a",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3c77fed5ff94e5799c1884e1a81c10b",
            "value": 4
          }
        },
        "bb64b6b43c1d47f4a40a42f4d1d033db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d41ab3ce46444f485cd34e97cab87d1",
            "placeholder": "​",
            "style": "IPY_MODEL_357360eed0624abba48d52a5508b3e8d",
            "value": " 4/30 [00:49&lt;04:47, 11.04s/it]"
          }
        },
        "95485a544c80418cb73aaad5a01b5066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c13137b440544bc9069716da1c80cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d0fb8acdf04f75b567564972a07c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fc3cdc8bd6a4e079481ba636de4649a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c77fed5ff94e5799c1884e1a81c10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d41ab3ce46444f485cd34e97cab87d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357360eed0624abba48d52a5508b3e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe46668f8f7c4d50857363ce18654093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96cdaa6596184696a1b7a481cb5fb36e",
              "IPY_MODEL_c70c9084d1a44c6eab74b202bdd782fb",
              "IPY_MODEL_4fa1efe6019745fb89c1f0b9baed0179"
            ],
            "layout": "IPY_MODEL_9aa82e400d9a435593981eae420563ef"
          }
        },
        "96cdaa6596184696a1b7a481cb5fb36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2275b9fd3e4e5daab1333e368ac704",
            "placeholder": "​",
            "style": "IPY_MODEL_74375220f75e4190a18ff3c32b92a0ae",
            "value": " 13%"
          }
        },
        "c70c9084d1a44c6eab74b202bdd782fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65272d8f79b4add8a0fe96ae3a92d29",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d8addff75b54bd1afd0d947f3bc15e2",
            "value": 4
          }
        },
        "4fa1efe6019745fb89c1f0b9baed0179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8785256cc3484baddeabd562a81aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_8196229585aa4133a76869bb4717a37e",
            "value": " 4/30 [01:03&lt;06:27, 14.90s/it]"
          }
        },
        "9aa82e400d9a435593981eae420563ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2275b9fd3e4e5daab1333e368ac704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74375220f75e4190a18ff3c32b92a0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f65272d8f79b4add8a0fe96ae3a92d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8addff75b54bd1afd0d947f3bc15e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b8785256cc3484baddeabd562a81aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8196229585aa4133a76869bb4717a37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9706b21aea72425c91d8ff50c7d4f581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ed7941df77415cb2a6805bbc08df68",
              "IPY_MODEL_21c6ae7b8b3549fbb0f8915d5788beed",
              "IPY_MODEL_00f796491a9244de9de503e2e412c2ca"
            ],
            "layout": "IPY_MODEL_2b4270802e5041b3a7e5b73785e93353"
          }
        },
        "d4ed7941df77415cb2a6805bbc08df68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850e15b9cd86478099023d0c9e615cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_44a16e2ab44b43dab477d3716e1b1106",
            "value": "  0%"
          }
        },
        "21c6ae7b8b3549fbb0f8915d5788beed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_943a83a3b5664e0f8a884eea6e50ec19",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66186d2e697b4e7e8e9c4847447cc84e",
            "value": 0
          }
        },
        "00f796491a9244de9de503e2e412c2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3d68c5022946c0a7df33c13146b5e6",
            "placeholder": "​",
            "style": "IPY_MODEL_20364673c9ef4e8c82c0555693ac2825",
            "value": " 0/30 [01:50&lt;?, ?it/s]"
          }
        },
        "2b4270802e5041b3a7e5b73785e93353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850e15b9cd86478099023d0c9e615cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a16e2ab44b43dab477d3716e1b1106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "943a83a3b5664e0f8a884eea6e50ec19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66186d2e697b4e7e8e9c4847447cc84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a3d68c5022946c0a7df33c13146b5e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20364673c9ef4e8c82c0555693ac2825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747224649c7b45ab9222ecc2ff976163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df84d3ddbf01408789527670999667f2",
              "IPY_MODEL_c0e324850cd34337846459f7610fdc96",
              "IPY_MODEL_a7488a1d100e434da1814c653d5968a8"
            ],
            "layout": "IPY_MODEL_231241568fa849fabbd15e385381dc47"
          }
        },
        "df84d3ddbf01408789527670999667f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77870fe8c8b14e49ab67bfb2e0a71d5e",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c740e0435d4e5b9afc668e30258831",
            "value": "  0%"
          }
        },
        "c0e324850cd34337846459f7610fdc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f0fdb25ebc497e8d08c03c50685f54",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b171b5fd8b2247258bd244f672a20e46",
            "value": 0
          }
        },
        "a7488a1d100e434da1814c653d5968a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3d14430d574f769fad4ea75a6d1228",
            "placeholder": "​",
            "style": "IPY_MODEL_05536f07d153400a8265f77177ca0733",
            "value": " 0/30 [01:50&lt;?, ?it/s]"
          }
        },
        "231241568fa849fabbd15e385381dc47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77870fe8c8b14e49ab67bfb2e0a71d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c740e0435d4e5b9afc668e30258831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f0fdb25ebc497e8d08c03c50685f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b171b5fd8b2247258bd244f672a20e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f3d14430d574f769fad4ea75a6d1228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05536f07d153400a8265f77177ca0733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbd862de201946c5aa633c6364c4a34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10096f5c9d4740e49d01a5e468e1d8fa",
              "IPY_MODEL_79962fcdd65e4a22b525e20bb9130e23",
              "IPY_MODEL_b08f2cc9ee694ff695d4f2c5dafb0db5"
            ],
            "layout": "IPY_MODEL_5b6fb4a2074749018b54961ab9a9cbb5"
          }
        },
        "10096f5c9d4740e49d01a5e468e1d8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc70c8f210b47fdb049b7d42107372b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9c4eeb61fcd468fa90ea82ffe66c1e0",
            "value": "100%"
          }
        },
        "79962fcdd65e4a22b525e20bb9130e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d117573eb4024e709f5a677fce175902",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be2be969804b4ebebe1c294e7645e4dd",
            "value": 30
          }
        },
        "b08f2cc9ee694ff695d4f2c5dafb0db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b6c674f6e24befbc29bdee516eb133",
            "placeholder": "​",
            "style": "IPY_MODEL_457ac74886614d1f9fdb7b2254d0b59d",
            "value": " 30/30 [00:02&lt;00:00, 10.36it/s]"
          }
        },
        "5b6fb4a2074749018b54961ab9a9cbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc70c8f210b47fdb049b7d42107372b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c4eeb61fcd468fa90ea82ffe66c1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d117573eb4024e709f5a677fce175902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2be969804b4ebebe1c294e7645e4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49b6c674f6e24befbc29bdee516eb133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457ac74886614d1f9fdb7b2254d0b59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c321d73b51044418b98d91a4941e829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8dc2154542f4e73b3d3fb070a11b565",
              "IPY_MODEL_4ccb5634492f469a9cac686fed106a65",
              "IPY_MODEL_81bb18401ac74ec6837931662b613e03"
            ],
            "layout": "IPY_MODEL_a5978f8bcc70495f88b5b9fb3d0bacf0"
          }
        },
        "a8dc2154542f4e73b3d3fb070a11b565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17140ef83c74cbebfd7f2321d8b9f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_dcc0dabfb65a464ead0b2db617616d19",
            "value": "100%"
          }
        },
        "4ccb5634492f469a9cac686fed106a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed042bb665947ff878aa08b6af96ee5",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54c5a720d65147e188821a63a839cf32",
            "value": 30
          }
        },
        "81bb18401ac74ec6837931662b613e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6e2d55be104e86a24147be77ce716b",
            "placeholder": "​",
            "style": "IPY_MODEL_91d9d8b1459a48b2bef9e53c2dac4264",
            "value": " 30/30 [00:02&lt;00:00, 10.61it/s]"
          }
        },
        "a5978f8bcc70495f88b5b9fb3d0bacf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17140ef83c74cbebfd7f2321d8b9f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc0dabfb65a464ead0b2db617616d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eed042bb665947ff878aa08b6af96ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c5a720d65147e188821a63a839cf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd6e2d55be104e86a24147be77ce716b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d9d8b1459a48b2bef9e53c2dac4264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c164e2a97ef40a4bb149976010177c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94cbfc78eb944966aac1a8860eded3eb",
              "IPY_MODEL_e623584c6b6e4374ae6b39f3dcdb88f0",
              "IPY_MODEL_6002061a3a29491d90b52bfcca9a8e78"
            ],
            "layout": "IPY_MODEL_e6ca644803a74c6c9842112d03c080e3"
          }
        },
        "94cbfc78eb944966aac1a8860eded3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a538457e19f430ea30b7cb39a1fac61",
            "placeholder": "​",
            "style": "IPY_MODEL_2865d7e9bc6a4c98adfecc051f3aa2a0",
            "value": "  0%"
          }
        },
        "e623584c6b6e4374ae6b39f3dcdb88f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73be076e7da4be89be4f18065d7e13e",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63ae9de0c59c4a7ab23e54144146e2ea",
            "value": 0
          }
        },
        "6002061a3a29491d90b52bfcca9a8e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6258f14f5194df69df9c5c872cf5b56",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ac8c731b0f4f7685c764434ad85001",
            "value": " 0/30 [01:29&lt;?, ?it/s]"
          }
        },
        "e6ca644803a74c6c9842112d03c080e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a538457e19f430ea30b7cb39a1fac61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2865d7e9bc6a4c98adfecc051f3aa2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d73be076e7da4be89be4f18065d7e13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ae9de0c59c4a7ab23e54144146e2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6258f14f5194df69df9c5c872cf5b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ac8c731b0f4f7685c764434ad85001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc80fee0808478aa48247eb05a86f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e73d455ab5654221906f1fd7228ca931",
              "IPY_MODEL_d0e0085db358426cbf8c058d299a8014",
              "IPY_MODEL_cd5342342f6842d9ac07ff4efbf5de9f"
            ],
            "layout": "IPY_MODEL_9ac2d16c7bfa4535b432c3b576392aaf"
          }
        },
        "e73d455ab5654221906f1fd7228ca931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_958ac12efe324b6a81135dda767c2f6c",
            "placeholder": "​",
            "style": "IPY_MODEL_8a947e638cac44dfa914db39a15a1971",
            "value": " 13%"
          }
        },
        "d0e0085db358426cbf8c058d299a8014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c39e64b0e4464ce8a07d463761449499",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54884faa0e8349aeab2510da8e9b90e8",
            "value": 4
          }
        },
        "cd5342342f6842d9ac07ff4efbf5de9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7208d8e95b9f4bf6b8f23045d1429864",
            "placeholder": "​",
            "style": "IPY_MODEL_8d06137db6e943b883cd1ecab62160d7",
            "value": " 4/30 [00:24&lt;02:33,  5.90s/it]"
          }
        },
        "9ac2d16c7bfa4535b432c3b576392aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958ac12efe324b6a81135dda767c2f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a947e638cac44dfa914db39a15a1971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c39e64b0e4464ce8a07d463761449499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54884faa0e8349aeab2510da8e9b90e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7208d8e95b9f4bf6b8f23045d1429864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d06137db6e943b883cd1ecab62160d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf8db7cb35a48b6a33cf6d803642a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9faa469a1c78446a802d602daa7ae74f",
              "IPY_MODEL_3b1b5b93fb9d4120a8ac52e11f934ed7",
              "IPY_MODEL_6bb0377af2df477c9b15ff94847ee49b"
            ],
            "layout": "IPY_MODEL_d75e6f1bacd545af8c4214bcf08c233c"
          }
        },
        "9faa469a1c78446a802d602daa7ae74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9f934ea769480686ff04fe7639a5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_cc539e7e85404b209cd088ae2344885d",
            "value": " 13%"
          }
        },
        "3b1b5b93fb9d4120a8ac52e11f934ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ceb912cf0b4f56b574b0fcbd2a1308",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74dffe2b62c740adb6b1e84706aebf97",
            "value": 4
          }
        },
        "6bb0377af2df477c9b15ff94847ee49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7bf2c6ff53f4db696bbadc8170281be",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0478bd3eab4adb89b32de3dd726010",
            "value": " 4/30 [00:40&lt;04:04,  9.40s/it]"
          }
        },
        "d75e6f1bacd545af8c4214bcf08c233c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9f934ea769480686ff04fe7639a5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc539e7e85404b209cd088ae2344885d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ceb912cf0b4f56b574b0fcbd2a1308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74dffe2b62c740adb6b1e84706aebf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7bf2c6ff53f4db696bbadc8170281be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0478bd3eab4adb89b32de3dd726010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333f6cf829204adcbc0acaf9e7de0b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f2230b5358e48e2b19e5ff0d01ee882",
              "IPY_MODEL_4cdb9fbd366f44f59bff731b71657a9b",
              "IPY_MODEL_be41ff71f3a84616b4a02f4d33c37a70"
            ],
            "layout": "IPY_MODEL_c60ac8d90a1e490ca8bfc502ec4150a7"
          }
        },
        "0f2230b5358e48e2b19e5ff0d01ee882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916c2862852949d6ba72009f020c556f",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6f07f4aed8415d9fba67e68ec6559f",
            "value": " 13%"
          }
        },
        "4cdb9fbd366f44f59bff731b71657a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9a246c89a6472eafad8f3917a3719b",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da563084583d4c909f54192d49b6d4ab",
            "value": 4
          }
        },
        "be41ff71f3a84616b4a02f4d33c37a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428d6ac2f1a3474eae157c4bf3d18388",
            "placeholder": "​",
            "style": "IPY_MODEL_b528a5b8e48141009313ebaa2b9e8948",
            "value": " 4/30 [00:52&lt;05:27, 12.59s/it]"
          }
        },
        "c60ac8d90a1e490ca8bfc502ec4150a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916c2862852949d6ba72009f020c556f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6f07f4aed8415d9fba67e68ec6559f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9a246c89a6472eafad8f3917a3719b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da563084583d4c909f54192d49b6d4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "428d6ac2f1a3474eae157c4bf3d18388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b528a5b8e48141009313ebaa2b9e8948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b248bbb25c4c46a7a604b0ca73841f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9429aff0b2245b693af58ffcac80d0b",
              "IPY_MODEL_70afb7003d5b4d4280ca718b5067e30c",
              "IPY_MODEL_8788f10745bf4789ac5273a43545e18e"
            ],
            "layout": "IPY_MODEL_79e046620875405086f63985968bda97"
          }
        },
        "c9429aff0b2245b693af58ffcac80d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7123f5ccb44d4a8486f5dd6158adad",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e9c7de8872490781b5e42cc38fe975",
            "value": "  0%"
          }
        },
        "70afb7003d5b4d4280ca718b5067e30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cdc3532d8e44c38c90547fa69f932d",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_975fcabf4058431baa337cc7f1f762c7",
            "value": 0
          }
        },
        "8788f10745bf4789ac5273a43545e18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5ff00b3e5e445681b576e0acff681c",
            "placeholder": "​",
            "style": "IPY_MODEL_4da80c3539af44fda5edff788eeeff1f",
            "value": " 0/30 [02:12&lt;?, ?it/s]"
          }
        },
        "79e046620875405086f63985968bda97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7123f5ccb44d4a8486f5dd6158adad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e9c7de8872490781b5e42cc38fe975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8cdc3532d8e44c38c90547fa69f932d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "975fcabf4058431baa337cc7f1f762c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf5ff00b3e5e445681b576e0acff681c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da80c3539af44fda5edff788eeeff1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbddc0691cc4f608b948f64efca5f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8a41efed16c45e684bdf844cf924984",
              "IPY_MODEL_54f9cf3c0b1940f5b4a29754b17e1233",
              "IPY_MODEL_a4dd863e5f574c2487f35dd43a0bba71"
            ],
            "layout": "IPY_MODEL_6a4e87daa4034c8c843a171e01148d33"
          }
        },
        "e8a41efed16c45e684bdf844cf924984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959fa8ab120947129a5f989db10e2806",
            "placeholder": "​",
            "style": "IPY_MODEL_78470110d53945368b247419d974f75f",
            "value": "  0%"
          }
        },
        "54f9cf3c0b1940f5b4a29754b17e1233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_739adde51fe84fb1b9a96649a9d91a09",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b340000ea8834bb8984ce50fd7151470",
            "value": 0
          }
        },
        "a4dd863e5f574c2487f35dd43a0bba71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663e4e47ada940ac92e2c3a8b7cce39f",
            "placeholder": "​",
            "style": "IPY_MODEL_931ca17eb62442ff88e31e91fcced62d",
            "value": " 0/30 [02:15&lt;?, ?it/s]"
          }
        },
        "6a4e87daa4034c8c843a171e01148d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959fa8ab120947129a5f989db10e2806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78470110d53945368b247419d974f75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "739adde51fe84fb1b9a96649a9d91a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b340000ea8834bb8984ce50fd7151470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "663e4e47ada940ac92e2c3a8b7cce39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931ca17eb62442ff88e31e91fcced62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1afcfa698de645988b06e90174c9b8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a56a0a06258b464f8496fca9730990c2",
              "IPY_MODEL_220d5468fdac40868f40f5a20f4c1422",
              "IPY_MODEL_b0c607d9581c4510bbc4981a79a8694e"
            ],
            "layout": "IPY_MODEL_505a5b6928b247cf9628ef7761bf7a8f"
          }
        },
        "a56a0a06258b464f8496fca9730990c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6d1a0d44ee4b98873b2dd6693caae4",
            "placeholder": "​",
            "style": "IPY_MODEL_0caba4bc02be42538ad27c3d43a703ad",
            "value": "100%"
          }
        },
        "220d5468fdac40868f40f5a20f4c1422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07bca64bef58431298ca593a5b352926",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd82b4c8bc84a8ba5b2989955a77fa2",
            "value": 30
          }
        },
        "b0c607d9581c4510bbc4981a79a8694e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89ef791835044c71841b3c22b394700e",
            "placeholder": "​",
            "style": "IPY_MODEL_b6a2c3758e034482862fa7a10c98d3cb",
            "value": " 30/30 [00:02&lt;00:00, 10.46it/s]"
          }
        },
        "505a5b6928b247cf9628ef7761bf7a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6d1a0d44ee4b98873b2dd6693caae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0caba4bc02be42538ad27c3d43a703ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07bca64bef58431298ca593a5b352926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd82b4c8bc84a8ba5b2989955a77fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89ef791835044c71841b3c22b394700e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a2c3758e034482862fa7a10c98d3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf65adf50364560b4261b555ccb5518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b10297dfca644265aa69580bdc3a01d3",
              "IPY_MODEL_99a88c5f7a7b4fb993d43ec2bbb0eb8f",
              "IPY_MODEL_f62c7b64aad04f89b8be4e84f12b817e"
            ],
            "layout": "IPY_MODEL_c760d887e0bd479fb3d7f3b19b636029"
          }
        },
        "b10297dfca644265aa69580bdc3a01d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3395e7173cc46e6b227721cbce9d8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_818b8f66b39242139dafa2a9b12b8cde",
            "value": "100%"
          }
        },
        "99a88c5f7a7b4fb993d43ec2bbb0eb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58344a6d00e24e4caaedd7c659b0c317",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d09e0b6dbfca4830a785e35135a527b8",
            "value": 30
          }
        },
        "f62c7b64aad04f89b8be4e84f12b817e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_097e6b67a23448be9bd7afc74b3dcd1c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed28016fd2bb41788c40321d44600624",
            "value": " 30/30 [00:02&lt;00:00, 10.37it/s]"
          }
        },
        "c760d887e0bd479fb3d7f3b19b636029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3395e7173cc46e6b227721cbce9d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818b8f66b39242139dafa2a9b12b8cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58344a6d00e24e4caaedd7c659b0c317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09e0b6dbfca4830a785e35135a527b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "097e6b67a23448be9bd7afc74b3dcd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed28016fd2bb41788c40321d44600624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "173b8d49231a4ba3af1e54c334811373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62dcb5a1e05546b9b8143fe3d9a4b17c",
              "IPY_MODEL_97cf1eb4cc0e49e09cd49f92632f44ff",
              "IPY_MODEL_de366c1089624ca79653b062abce629f"
            ],
            "layout": "IPY_MODEL_1833875e60c74e06b08e7792723ed9cf"
          }
        },
        "62dcb5a1e05546b9b8143fe3d9a4b17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888e75dcfd8c430fb1d399234667329e",
            "placeholder": "​",
            "style": "IPY_MODEL_9a389c7f77a740f4916400ffbf569fe6",
            "value": "  3%"
          }
        },
        "97cf1eb4cc0e49e09cd49f92632f44ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9edd9a33224889a039e9ad74b4862c",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3d27e22d23145e2be095fcf160fd155",
            "value": 1
          }
        },
        "de366c1089624ca79653b062abce629f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8932e93fc050499f95662b0f42bb236b",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf2ccc348394948add22f2c109d1c5b",
            "value": " 1/30 [02:22&lt;38:21, 79.35s/it]"
          }
        },
        "1833875e60c74e06b08e7792723ed9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888e75dcfd8c430fb1d399234667329e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a389c7f77a740f4916400ffbf569fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9edd9a33224889a039e9ad74b4862c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d27e22d23145e2be095fcf160fd155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8932e93fc050499f95662b0f42bb236b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf2ccc348394948add22f2c109d1c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cad0109aabb647de94eac66232bfefc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e33e95f2634f7a96a9cf5fa7676a6e",
              "IPY_MODEL_822d5f380ce84c07ad899610eafd0d91",
              "IPY_MODEL_461ebbde0873480a985b60988bff8144"
            ],
            "layout": "IPY_MODEL_be9c73765fd54210ae1ccb985a231528"
          }
        },
        "b8e33e95f2634f7a96a9cf5fa7676a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78eb32060ba540a0b70b369a2d8e6ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_2e3b6d811cdd449b91ab026528c7b6be",
            "value": " 13%"
          }
        },
        "822d5f380ce84c07ad899610eafd0d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba36ca9d8124383bd67b40169bcdd1a",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db662e29ab8c4297b5170cae7927b05c",
            "value": 4
          }
        },
        "461ebbde0873480a985b60988bff8144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4ef02e604a4a869c82bb1313189d31",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ba8ada42094612b308c9b8fd1db2ac",
            "value": " 4/30 [00:24&lt;02:27,  5.67s/it]"
          }
        },
        "be9c73765fd54210ae1ccb985a231528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78eb32060ba540a0b70b369a2d8e6ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3b6d811cdd449b91ab026528c7b6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ba36ca9d8124383bd67b40169bcdd1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db662e29ab8c4297b5170cae7927b05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d4ef02e604a4a869c82bb1313189d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ba8ada42094612b308c9b8fd1db2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d0e45eba4844082a3582fff061da0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24334f22776f4165b2099f94cb6d2405",
              "IPY_MODEL_373ae7e947f146d899b349245506fa9c",
              "IPY_MODEL_6afb5e28fcfb46628b77e2ae6a6847b0"
            ],
            "layout": "IPY_MODEL_82ca27cff2134a1989b5afbaff3d7473"
          }
        },
        "24334f22776f4165b2099f94cb6d2405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ceaef0fde1f4958b11b111a4fc96c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_c28d1175a6ca4394b75a52f077957191",
            "value": " 13%"
          }
        },
        "373ae7e947f146d899b349245506fa9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2861fb20f9f4971ba9a7694a5cc8910",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2caebbf1a8c14b7e8cb4a23950f7329f",
            "value": 4
          }
        },
        "6afb5e28fcfb46628b77e2ae6a6847b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d81b753f77406283ffab32cf2382e8",
            "placeholder": "​",
            "style": "IPY_MODEL_a626c9dec48c4e4fb19f7c311124401f",
            "value": " 4/30 [00:40&lt;04:04,  9.40s/it]"
          }
        },
        "82ca27cff2134a1989b5afbaff3d7473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ceaef0fde1f4958b11b111a4fc96c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28d1175a6ca4394b75a52f077957191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2861fb20f9f4971ba9a7694a5cc8910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2caebbf1a8c14b7e8cb4a23950f7329f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12d81b753f77406283ffab32cf2382e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a626c9dec48c4e4fb19f7c311124401f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dabbc522c844eb19d6c76b7e7d33b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d9696e1f56e4e8b8b019c2c1eb761fc",
              "IPY_MODEL_703bc09114104211af086dc22074527d",
              "IPY_MODEL_a25a0aa7bf654a998bf33127fd5c2cb0"
            ],
            "layout": "IPY_MODEL_712168d483304835b9710e75992ca4d6"
          }
        },
        "7d9696e1f56e4e8b8b019c2c1eb761fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62115896810c414c9f7a6a53ec8456bf",
            "placeholder": "​",
            "style": "IPY_MODEL_55cefdc386fe4c1dbb622263859868a1",
            "value": " 13%"
          }
        },
        "703bc09114104211af086dc22074527d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7cbe57931774be2b07f33a31a36c1c6",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aae8b125847f4006a9f956ea181268a9",
            "value": 4
          }
        },
        "a25a0aa7bf654a998bf33127fd5c2cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e58d132deeb24173babb27041116e3ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc0a3e7c9824c0bb7355f621c4f5875",
            "value": " 4/30 [01:00&lt;06:32, 15.11s/it]"
          }
        },
        "712168d483304835b9710e75992ca4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62115896810c414c9f7a6a53ec8456bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55cefdc386fe4c1dbb622263859868a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7cbe57931774be2b07f33a31a36c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae8b125847f4006a9f956ea181268a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e58d132deeb24173babb27041116e3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc0a3e7c9824c0bb7355f621c4f5875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7ae15a9094f4a33aa2f217dc0f895ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e72b1184714b4b9cba7dc978521e8ff0",
              "IPY_MODEL_b1d77685c9e2411e8c48892b451da6e4",
              "IPY_MODEL_23cb88d9d8ab49198b621183fd80af9c"
            ],
            "layout": "IPY_MODEL_d857c989ce0c4be7bbc0ea66c2f26e90"
          }
        },
        "e72b1184714b4b9cba7dc978521e8ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c8090194d84bb4bd4673d3d8f819a8",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3acc1b122540908968c966823b47e1",
            "value": "  0%"
          }
        },
        "b1d77685c9e2411e8c48892b451da6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba77098c3e64c2faf6132614b56ec5a",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ffce6f5114a47049e13ad57e14ee8d6",
            "value": 0
          }
        },
        "23cb88d9d8ab49198b621183fd80af9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e1f4076dae434bb5d5b0c063dc9b59",
            "placeholder": "​",
            "style": "IPY_MODEL_2a1def2981504936beaad81dc9e81aeb",
            "value": " 0/30 [02:44&lt;?, ?it/s]"
          }
        },
        "d857c989ce0c4be7bbc0ea66c2f26e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c8090194d84bb4bd4673d3d8f819a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3acc1b122540908968c966823b47e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba77098c3e64c2faf6132614b56ec5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ffce6f5114a47049e13ad57e14ee8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2e1f4076dae434bb5d5b0c063dc9b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1def2981504936beaad81dc9e81aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3899a8dffd64393b29adf3cbd252f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0161943ff84e1ba0ba6eb6aafba0b9",
              "IPY_MODEL_972e5080014e41a39ca1f913370bad2f",
              "IPY_MODEL_99bc63036f1d4e24a33583ea7b3ff87a"
            ],
            "layout": "IPY_MODEL_2ed3bd4a382f44a9a626ab8eb79b6702"
          }
        },
        "6e0161943ff84e1ba0ba6eb6aafba0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a772242d9e4c6bac453678a3fb4667",
            "placeholder": "​",
            "style": "IPY_MODEL_3b19243bf36c4f46a17c5af9b9998b45",
            "value": "  0%"
          }
        },
        "972e5080014e41a39ca1f913370bad2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0d86056a6a4e0c9bf36e7eeba8b0bf",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_242dc808f539487987d6c2c22855ca92",
            "value": 0
          }
        },
        "99bc63036f1d4e24a33583ea7b3ff87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b27369295f64f22ab978ac24536db5b",
            "placeholder": "​",
            "style": "IPY_MODEL_c9b84e50804043b19da91d94504d272c",
            "value": " 0/30 [02:41&lt;?, ?it/s]"
          }
        },
        "2ed3bd4a382f44a9a626ab8eb79b6702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a772242d9e4c6bac453678a3fb4667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b19243bf36c4f46a17c5af9b9998b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0d86056a6a4e0c9bf36e7eeba8b0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242dc808f539487987d6c2c22855ca92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b27369295f64f22ab978ac24536db5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b84e50804043b19da91d94504d272c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6a50d7cfa6045ad981bb3adc1f14703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0758bf152f784ab38046bad02616cc27",
              "IPY_MODEL_991563224088486d8acb4933688247d2",
              "IPY_MODEL_eba279249ec74067913a079f7030fe13"
            ],
            "layout": "IPY_MODEL_75a53cc9ac164af0923ff7f7387d82d5"
          }
        },
        "0758bf152f784ab38046bad02616cc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c6f939774245b18634e1cc0196a8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_21885309c92848d997c25d0da7376be5",
            "value": "100%"
          }
        },
        "991563224088486d8acb4933688247d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c0f3610d024c19951927cc08a1f460",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f7c88d63b094239808f72daa17086d9",
            "value": 30
          }
        },
        "eba279249ec74067913a079f7030fe13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3c246f6b194de586b7b1494958e925",
            "placeholder": "​",
            "style": "IPY_MODEL_d4dc21e9501d4f9497ec6441101d64e5",
            "value": " 30/30 [00:02&lt;00:00, 11.11it/s]"
          }
        },
        "75a53cc9ac164af0923ff7f7387d82d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c6f939774245b18634e1cc0196a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21885309c92848d997c25d0da7376be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c0f3610d024c19951927cc08a1f460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7c88d63b094239808f72daa17086d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b3c246f6b194de586b7b1494958e925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4dc21e9501d4f9497ec6441101d64e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2e0f17512a8476da619c4b1feb3b5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_873079a0fb61466199de789a7d997399",
              "IPY_MODEL_5895c5b723f348c6afbd996452528fd2",
              "IPY_MODEL_489993851e9f40a296268cbd0999455b"
            ],
            "layout": "IPY_MODEL_2d4dd6d970f44f30a5cd17d254fcc8c6"
          }
        },
        "873079a0fb61466199de789a7d997399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_720d6cdbb0e1408abfe9a62ab689cd01",
            "placeholder": "​",
            "style": "IPY_MODEL_b866212ea6ab4d918ea1330bdc2b8b47",
            "value": "100%"
          }
        },
        "5895c5b723f348c6afbd996452528fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d32b2d94004eda9337498c7b067797",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d62a3b56170441baa5f8f1d43d2a3230",
            "value": 30
          }
        },
        "489993851e9f40a296268cbd0999455b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f96e976734e94c3ca99452b07ac57cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_ceedbc4b057045239816bf8f909a8e0b",
            "value": " 30/30 [00:02&lt;00:00, 10.93it/s]"
          }
        },
        "2d4dd6d970f44f30a5cd17d254fcc8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "720d6cdbb0e1408abfe9a62ab689cd01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b866212ea6ab4d918ea1330bdc2b8b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60d32b2d94004eda9337498c7b067797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d62a3b56170441baa5f8f1d43d2a3230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f96e976734e94c3ca99452b07ac57cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceedbc4b057045239816bf8f909a8e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3260b9ebec9b45f49d34c0a336702462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c4085548f3446e991350fee34325395",
              "IPY_MODEL_a2cac5aa97a2427387ecb0a19416bdfc",
              "IPY_MODEL_cb7af662a8364c1d9f30fdc0c56aaf9f"
            ],
            "layout": "IPY_MODEL_77e65d7d1b59418684341aa03df5f1f2"
          }
        },
        "0c4085548f3446e991350fee34325395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bfbabba022c4cea9da15891d15e07c2",
            "placeholder": "​",
            "style": "IPY_MODEL_aef034c95ad64f7290a22c8a57474435",
            "value": " 17%"
          }
        },
        "a2cac5aa97a2427387ecb0a19416bdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a962087a3124878a70835806786b7a1",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e14050c1edd461ba87b2b46661e4ad3",
            "value": 5
          }
        },
        "cb7af662a8364c1d9f30fdc0c56aaf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731114b874484a7ba261233b410998d4",
            "placeholder": "​",
            "style": "IPY_MODEL_ef7d8b62e47d43c5b1bbb02c310b2ebb",
            "value": " 5/30 [04:34&lt;22:28, 53.95s/it]"
          }
        },
        "77e65d7d1b59418684341aa03df5f1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfbabba022c4cea9da15891d15e07c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef034c95ad64f7290a22c8a57474435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a962087a3124878a70835806786b7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e14050c1edd461ba87b2b46661e4ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "731114b874484a7ba261233b410998d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef7d8b62e47d43c5b1bbb02c310b2ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c4f8808a6844e3cbd88bb2403be889d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384c1acff3894a61ba2ee93bf3a55ce4",
              "IPY_MODEL_0c7d5515c00b4d3aa8a98d7375e6a510",
              "IPY_MODEL_a6b9dafa9569455eb79c841551fb1315"
            ],
            "layout": "IPY_MODEL_5222d11336e545e5b6eaea6e66692d04"
          }
        },
        "384c1acff3894a61ba2ee93bf3a55ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846dee0ce9cc4b51b7cf14245dfa2e2e",
            "placeholder": "​",
            "style": "IPY_MODEL_641d053f5577417dbad4864e5bfe6fd4",
            "value": " 13%"
          }
        },
        "0c7d5515c00b4d3aa8a98d7375e6a510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41a05dec34645d08e6051e4576828d2",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248a17051e764df090cb9c3c4a13741e",
            "value": 4
          }
        },
        "a6b9dafa9569455eb79c841551fb1315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0431d74662cc4a71919c9d122e703f77",
            "placeholder": "​",
            "style": "IPY_MODEL_7e5338203d2e45bc9060a9bb2cdb5127",
            "value": " 4/30 [00:22&lt;02:18,  5.33s/it]"
          }
        },
        "5222d11336e545e5b6eaea6e66692d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846dee0ce9cc4b51b7cf14245dfa2e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641d053f5577417dbad4864e5bfe6fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d41a05dec34645d08e6051e4576828d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248a17051e764df090cb9c3c4a13741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0431d74662cc4a71919c9d122e703f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e5338203d2e45bc9060a9bb2cdb5127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41bec731fdaf4bf29e9d1c3f98979b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c62567c399941d7aa11222c1f16603d",
              "IPY_MODEL_3f8c2fd64a15457385e58086fa1c01a7",
              "IPY_MODEL_fdb8448a608f473a8813624af1f34a5e"
            ],
            "layout": "IPY_MODEL_9697d19eea9f4f51bf5142d56298cd68"
          }
        },
        "5c62567c399941d7aa11222c1f16603d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3cad4e06d2f441ca4abde191cc5b73c",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe733d1aa554ed8ad8705232c777e10",
            "value": " 13%"
          }
        },
        "3f8c2fd64a15457385e58086fa1c01a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10cbff6c15d54c8791f2a0d4a1aba6a3",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_738f137e510b49d691a6ec40a88bbb6e",
            "value": 4
          }
        },
        "fdb8448a608f473a8813624af1f34a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c703254497b4be48ad13eae86ee3a8b",
            "placeholder": "​",
            "style": "IPY_MODEL_57daf4eb88a4466a83eefd67295aedeb",
            "value": " 4/30 [00:41&lt;04:14,  9.77s/it]"
          }
        },
        "9697d19eea9f4f51bf5142d56298cd68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cad4e06d2f441ca4abde191cc5b73c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe733d1aa554ed8ad8705232c777e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10cbff6c15d54c8791f2a0d4a1aba6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738f137e510b49d691a6ec40a88bbb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c703254497b4be48ad13eae86ee3a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57daf4eb88a4466a83eefd67295aedeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf94ab7c79f4432aa11359cfe5f0218a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d95c879188549e2aa48b5c3b4168a2f",
              "IPY_MODEL_c319249e35684ef28d322dca574b515b",
              "IPY_MODEL_f105c36a342347c8a464651ca5f80641"
            ],
            "layout": "IPY_MODEL_669856cee8624777b2f702dc290d7988"
          }
        },
        "8d95c879188549e2aa48b5c3b4168a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1984706069354065b4dc524059810a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_b895a6137f514a81a4f8920782ae4c28",
            "value": " 13%"
          }
        },
        "c319249e35684ef28d322dca574b515b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_572e3fbb34054369adf2919b18e03f2b",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa8c595faa594861a22ed024228391cd",
            "value": 4
          }
        },
        "f105c36a342347c8a464651ca5f80641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f80930a0d94f19940a0aef112dffc7",
            "placeholder": "​",
            "style": "IPY_MODEL_c97e9ccc2f784d9c9eb01c24398f3b3a",
            "value": " 4/30 [00:37&lt;03:57,  9.12s/it]"
          }
        },
        "669856cee8624777b2f702dc290d7988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1984706069354065b4dc524059810a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b895a6137f514a81a4f8920782ae4c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572e3fbb34054369adf2919b18e03f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8c595faa594861a22ed024228391cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0f80930a0d94f19940a0aef112dffc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97e9ccc2f784d9c9eb01c24398f3b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c05c042ce224eaeaa1e6984df7fac74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29782c72843f4a21880cc0061848eabe",
              "IPY_MODEL_d6d3e69fa1a34777a362db781783dc83",
              "IPY_MODEL_2a35af1c821e44e78c08802c44f5dffc"
            ],
            "layout": "IPY_MODEL_c8d17263441446418ebadeb81ff6eb09"
          }
        },
        "29782c72843f4a21880cc0061848eabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ce3e964d0e46cab7de38f4f5a0efe1",
            "placeholder": "​",
            "style": "IPY_MODEL_e530c49341e44c04b52d6d95e8c47904",
            "value": "  3%"
          }
        },
        "d6d3e69fa1a34777a362db781783dc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5702774b58124eb2b64aa0071c99bcb7",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93de1918d29e47f9b4f6abcc3841569b",
            "value": 1
          }
        },
        "2a35af1c821e44e78c08802c44f5dffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f183488d0df4af094dd37298f49948e",
            "placeholder": "​",
            "style": "IPY_MODEL_2430b8defe394746b1e29353f50ac2b1",
            "value": " 1/30 [12:45&lt;2:24:18, 298.57s/it]"
          }
        },
        "c8d17263441446418ebadeb81ff6eb09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ce3e964d0e46cab7de38f4f5a0efe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e530c49341e44c04b52d6d95e8c47904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5702774b58124eb2b64aa0071c99bcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93de1918d29e47f9b4f6abcc3841569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f183488d0df4af094dd37298f49948e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2430b8defe394746b1e29353f50ac2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fb8f82ae83649bf9aad4ae308411608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da5f0b829061407188a9a47119846ed6",
              "IPY_MODEL_910f8720f03a4a01ad3007bb06931dfc",
              "IPY_MODEL_c9d66ba5779646c98dc6169daa64e0c7"
            ],
            "layout": "IPY_MODEL_5ea096b52f3c4ca886c970df9ba53e2f"
          }
        },
        "da5f0b829061407188a9a47119846ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef743d7a6b4144588d9e4d5f20528396",
            "placeholder": "​",
            "style": "IPY_MODEL_502ecd4144b045d4b4c897c843c152ec",
            "value": "  3%"
          }
        },
        "910f8720f03a4a01ad3007bb06931dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c78a8ced9e5e4f78b43889a22a1f97b2",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a900d34a73e42e09ad98e423b86ed22",
            "value": 1
          }
        },
        "c9d66ba5779646c98dc6169daa64e0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a05b5d91463a4655810e55d09be520dc",
            "placeholder": "​",
            "style": "IPY_MODEL_46bfef67c3ee4e0ca6e34d542094df1e",
            "value": " 1/30 [12:46&lt;2:54:08, 360.31s/it]"
          }
        },
        "5ea096b52f3c4ca886c970df9ba53e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef743d7a6b4144588d9e4d5f20528396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502ecd4144b045d4b4c897c843c152ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78a8ced9e5e4f78b43889a22a1f97b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a900d34a73e42e09ad98e423b86ed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a05b5d91463a4655810e55d09be520dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bfef67c3ee4e0ca6e34d542094df1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import All Required Libraries and Data Loading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import kagglehub\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC\n",
        "from autogluon.tabular import TabularPredictor, TabularDataset\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv('train.csv', index_col='id')\n",
        "test = pd.read_csv('test.csv', index_col='id')\n",
        "\n",
        "path_rakesh = kagglehub.dataset_download(\"rakeshkapilavai/extrovert-vs-introvert-behavior-data\")\n",
        "df_rakesh = pd.read_csv(os.path.join(path_rakesh, 'personality_dataset.csv'))\n",
        "train_combined = pd.concat([train, df_rakesh], ignore_index=True)\n",
        "\n",
        "# Remove duplicates\n",
        "train_clean = train_combined.drop_duplicates(keep='first').copy()\n",
        "print(f\"Cleaned train shape: {train_clean.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(f\"Class distribution:\\n{train_clean['Personality'].value_counts()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FAVWgv8-vGs",
        "outputId": "86d825a6-9715-4e19-b1ef-44eb5cbd460c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n",
            "Cleaned train shape: (21036, 8)\n",
            "Test shape: (6175, 7)\n",
            "Class distribution:\n",
            "Personality\n",
            "Extrovert    15116\n",
            "Introvert     5920\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: k-NN Imputation for Missing Values\n",
        "numeric_cols = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
        "                'Friends_circle_size', 'Post_frequency']\n",
        "cat_cols = ['Stage_fear', 'Drained_after_socializing']\n",
        "\n",
        "print(\"Missing values before imputation:\")\n",
        "print(\"Train:\", train_clean[numeric_cols + cat_cols].isnull().sum())\n",
        "print(\"Test:\", test[numeric_cols + cat_cols].isnull().sum())\n",
        "\n",
        "# k-NN imputation for numerics\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "train_clean.loc[:, numeric_cols] = imputer.fit_transform(train_clean[numeric_cols])\n",
        "test.loc[:, numeric_cols] = imputer.transform(test[numeric_cols])\n",
        "\n",
        "# Simple mode fill for categoricals\n",
        "for col in cat_cols:\n",
        "    if col in train_clean.columns:\n",
        "        mode_val = train_clean[col].mode()[0] if not train_clean[col].mode().empty else 'No'\n",
        "        train_clean.loc[:, col] = train_clean[col].fillna(mode_val)\n",
        "        test.loc[:, col] = test[col].fillna(mode_val)\n",
        "\n",
        "print(\"Missing values after imputation:\")\n",
        "print(\"Train:\", train_clean.isnull().sum().sum())\n",
        "print(\"Test:\", test.isnull().sum().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFW6w4Wa-v2o",
        "outputId": "a11c9ca6-474b-465c-feea-f838f31555f5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before imputation:\n",
            "Train: Time_spent_Alone             1251\n",
            "Social_event_attendance      1241\n",
            "Going_outside                1531\n",
            "Friends_circle_size          1129\n",
            "Post_frequency               1327\n",
            "Stage_fear                   1966\n",
            "Drained_after_socializing    1200\n",
            "dtype: int64\n",
            "Test: Time_spent_Alone             425\n",
            "Social_event_attendance      397\n",
            "Going_outside                466\n",
            "Friends_circle_size          350\n",
            "Post_frequency               408\n",
            "Stage_fear                   598\n",
            "Drained_after_socializing    432\n",
            "dtype: int64\n",
            "Missing values after imputation:\n",
            "Train: 0\n",
            "Test: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Label Encoding for Binary Categoricals\n",
        "# Check unique values first\n",
        "print(\"Unique values in categorical columns:\")\n",
        "for col in cat_cols:\n",
        "    if col in train_clean.columns:\n",
        "        print(f\"{col}: {train_clean[col].unique()}\")\n",
        "\n",
        "# Create mapping based on actual values\n",
        "for col in cat_cols:\n",
        "    if col in train_clean.columns:\n",
        "        unique_vals = list(train_clean[col].unique())\n",
        "        if 'Yes' in unique_vals and 'No' in unique_vals:\n",
        "            binary_map = {'Yes': 1, 'No': 0}\n",
        "        else:\n",
        "            # Create numeric mapping for whatever values exist\n",
        "            binary_map = {val: i for i, val in enumerate(unique_vals)}\n",
        "\n",
        "        train_clean.loc[:, col] = train_clean[col].map(binary_map).fillna(0)\n",
        "        test.loc[:, col] = test[col].map(binary_map).fillna(0)\n",
        "\n",
        "print(\"Encoded categorical sample:\")\n",
        "print(train_clean[cat_cols].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOlhDeQv-0i8",
        "outputId": "1afa8d63-a12a-4125-a4d3-6f4342ca88bf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in categorical columns:\n",
            "Stage_fear: ['No' 'Yes']\n",
            "Drained_after_socializing: ['No' 'Yes']\n",
            "Encoded categorical sample:\n",
            "  Stage_fear Drained_after_socializing\n",
            "0          0                         0\n",
            "1          0                         0\n",
            "2          1                         0\n",
            "3          0                         0\n",
            "4          0                         0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Standard Scaling with Log Transformation\n",
        "# Apply log transform to skewed features (positive values)\n",
        "skewed_cols = ['Time_spent_Alone', 'Post_frequency']\n",
        "\n",
        "# Check data ranges first\n",
        "print(\"Data ranges before scaling:\")\n",
        "for col in numeric_cols:\n",
        "    print(f\"{col}: {train_clean[col].min():.2f} to {train_clean[col].max():.2f}\")\n",
        "\n",
        "# Apply log transform (ensuring positive values)\n",
        "for col in skewed_cols:\n",
        "    if col in train_clean.columns:\n",
        "        train_clean.loc[:, col] = np.log1p(np.abs(train_clean[col]))\n",
        "        test.loc[:, col] = np.log1p(np.abs(test[col]))\n",
        "\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "train_clean.loc[:, numeric_cols] = scaler.fit_transform(train_clean[numeric_cols])\n",
        "test.loc[:, numeric_cols] = scaler.transform(test[numeric_cols])\n",
        "\n",
        "print(\"Data ranges after scaling:\")\n",
        "for col in numeric_cols:\n",
        "    print(f\"{col}: {train_clean[col].min():.2f} to {train_clean[col].max():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm44PBxd_AfP",
        "outputId": "fa338798-a7f5-469e-9f55-a7b45c878322"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ranges before scaling:\n",
            "Time_spent_Alone: 0.00 to 11.00\n",
            "Social_event_attendance: 0.00 to 10.00\n",
            "Going_outside: 0.00 to 7.00\n",
            "Friends_circle_size: 0.00 to 15.00\n",
            "Post_frequency: 0.00 to 10.00\n",
            "Data ranges after scaling:\n",
            "Time_spent_Alone: -1.61 to 1.76\n",
            "Social_event_attendance: -1.84 to 1.76\n",
            "Going_outside: -1.87 to 1.48\n",
            "Friends_circle_size: -1.84 to 1.70\n",
            "Post_frequency: -2.37 to 1.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Skip SMOTE - Use Original Imbalanced Data with Class Weights\n",
        "X_train = train_clean.drop('Personality', axis=1)\n",
        "y_train = train_clean['Personality']\n",
        "\n",
        "print(\"Original class distribution (keeping imbalanced):\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Calculate class weight ratio for later use in models\n",
        "extrovert_count = len(y_train[y_train == 'Extrovert'])\n",
        "introvert_count = len(y_train[y_train == 'Introvert'])\n",
        "class_weight_ratio = extrovert_count / introvert_count\n",
        "\n",
        "print(f\"Class weight ratio (Extrovert/Introvert): {class_weight_ratio:.2f}\")\n",
        "\n",
        "# Use original data without SMOTE\n",
        "train_balanced = train_clean.copy()  # Keep original imbalanced data\n",
        "print(f\"Dataset shape (no SMOTE): {train_balanced.shape}\")\n",
        "\n",
        "# Validate data integrity\n",
        "print(\"\\nData validation:\")\n",
        "print(f\"Any NaN in data: {train_balanced.isnull().any().any()}\")\n",
        "print(f\"Any infinite values: {np.isinf(train_balanced.select_dtypes(include=[np.number])).any().any()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJJAui7a_Cxn",
        "outputId": "137d39fa-3a7c-4829-81aa-88f6fad7a861"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution (keeping imbalanced):\n",
            "Personality\n",
            "Extrovert    15116\n",
            "Introvert     5920\n",
            "Name: count, dtype: int64\n",
            "Class weight ratio (Extrovert/Introvert): 2.55\n",
            "Dataset shape (no SMOTE): (21036, 8)\n",
            "\n",
            "Data validation:\n",
            "Any NaN in data: False\n",
            "Any infinite values: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Advanced Outlier Handling with Isolation Forest\n",
        "iso = IsolationForest(contamination=0.01, random_state=42)\n",
        "outlier_mask = iso.fit_predict(train_balanced.drop('Personality', axis=1)) == 1\n",
        "train_balanced_clean = train_balanced[outlier_mask].copy()\n",
        "\n",
        "print(f\"Shape after outlier removal: {train_balanced_clean.shape}\")\n",
        "print(f\"Outliers removed: {len(train_balanced) - len(train_balanced_clean)}\")\n",
        "\n",
        "# Check class distribution after outlier removal\n",
        "print(\"Class distribution after outlier removal:\")\n",
        "print(train_balanced_clean['Personality'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp0QQnzb_FYL",
        "outputId": "d0e18ca4-0dce-4b3f-8669-3defc128379f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after outlier removal: (20825, 8)\n",
            "Outliers removed: 211\n",
            "Class distribution after outlier removal:\n",
            "Personality\n",
            "Extrovert    15105\n",
            "Introvert     5720\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Enhanced Feature Engineering and Selection\n",
        "# Add basic interaction features\n",
        "if 'Stage_fear' in train_balanced_clean.columns and 'Time_spent_Alone' in train_balanced_clean.columns:\n",
        "    train_balanced_clean['Fear_Alone_Inter'] = train_balanced_clean['Stage_fear'] * train_balanced_clean['Time_spent_Alone']\n",
        "    test['Fear_Alone_Inter'] = test['Stage_fear'] * test['Time_spent_Alone']\n",
        "\n",
        "# Add social activity score\n",
        "social_cols = ['Social_event_attendance', 'Going_outside', 'Post_frequency']\n",
        "available_social_cols = [col for col in social_cols if col in train_balanced_clean.columns]\n",
        "if available_social_cols:\n",
        "    train_balanced_clean['Social_Activity_Score'] = train_balanced_clean[available_social_cols].sum(axis=1)\n",
        "    test['Social_Activity_Score'] = test[available_social_cols].sum(axis=1)\n",
        "\n",
        "# NEW: Advanced psychological feature interactions\n",
        "# Social confidence vs fear ratio\n",
        "if 'Social_event_attendance' in train_balanced_clean.columns and 'Stage_fear' in train_balanced_clean.columns:\n",
        "    train_balanced_clean['Social_Fear_Ratio'] = train_balanced_clean['Social_event_attendance'] / (train_balanced_clean['Stage_fear'] + 1)\n",
        "    test['Social_Fear_Ratio'] = test['Social_event_attendance'] / (test['Stage_fear'] + 1)\n",
        "\n",
        "# Introversion tendency score (time alone vs social activity)\n",
        "if 'Time_spent_Alone' in train_balanced_clean.columns and 'Social_event_attendance' in train_balanced_clean.columns:\n",
        "    train_balanced_clean['Introversion_Score'] = train_balanced_clean['Time_spent_Alone'] - train_balanced_clean['Social_event_attendance']\n",
        "    test['Introversion_Score'] = test['Time_spent_Alone'] - test['Social_event_attendance']\n",
        "\n",
        "# Digital vs physical social preference\n",
        "if 'Post_frequency' in train_balanced_clean.columns and 'Going_outside' in train_balanced_clean.columns:\n",
        "    train_balanced_clean['Digital_Social_Ratio'] = train_balanced_clean['Post_frequency'] / (train_balanced_clean['Going_outside'] + 1)\n",
        "    test['Digital_Social_Ratio'] = test['Post_frequency'] / (test['Going_outside'] + 1)\n",
        "\n",
        "# Social network size vs activity alignment\n",
        "if 'Friends_circle_size' in train_balanced_clean.columns and 'Social_event_attendance' in train_balanced_clean.columns:\n",
        "    train_balanced_clean['Friends_Activity_Ratio'] = train_balanced_clean['Friends_circle_size'] / (train_balanced_clean['Social_event_attendance'] + 1)\n",
        "    test['Friends_Activity_Ratio'] = test['Friends_circle_size'] / (test['Social_event_attendance'] + 1)\n",
        "\n",
        "print(f\"Features after enhanced engineering: {list(train_balanced_clean.columns)}\")\n",
        "print(f\"Shape after feature engineering: {train_balanced_clean.shape}\")\n",
        "\n",
        "# Feature selection with RFE (increased to capture more features)\n",
        "base_estimator = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "n_features_to_select = min(15, len(train_balanced_clean.columns)-1)  # Increased from 10 to 15\n",
        "rfe = RFE(estimator=base_estimator, n_features_to_select=n_features_to_select, step=1)\n",
        "rfe.fit(train_balanced_clean.drop('Personality', axis=1), train_balanced_clean['Personality'])\n",
        "selected_features = train_balanced_clean.columns.drop('Personality')[rfe.support_]\n",
        "print(f\"Selected features ({len(selected_features)}): {list(selected_features)}\")\n",
        "\n",
        "# Filter datasets to selected features\n",
        "train_optimized = train_balanced_clean[selected_features.tolist() + ['Personality']].copy()\n",
        "test_optimized = test[selected_features].copy()\n",
        "\n",
        "print(f\"Final optimized shape - Train: {train_optimized.shape}, Test: {test_optimized.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xslSv-8I_IY2",
        "outputId": "4f494e76-1e5e-4109-d20c-b2d1a2086b0e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features after enhanced engineering: ['Time_spent_Alone', 'Stage_fear', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency', 'Personality', 'Fear_Alone_Inter', 'Social_Activity_Score', 'Social_Fear_Ratio', 'Introversion_Score', 'Digital_Social_Ratio', 'Friends_Activity_Ratio']\n",
            "Shape after feature engineering: (20825, 14)\n",
            "Selected features (13): ['Time_spent_Alone', 'Stage_fear', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency', 'Fear_Alone_Inter', 'Social_Activity_Score', 'Social_Fear_Ratio', 'Introversion_Score', 'Digital_Social_Ratio', 'Friends_Activity_Ratio']\n",
            "Final optimized shape - Train: (20825, 14), Test: (6175, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Enhanced AutoGluon Training with Advanced Configuration\n",
        "# Create train/validation split for evaluation\n",
        "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
        "    train_optimized.drop('Personality', axis=1),\n",
        "    train_optimized['Personality'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_optimized['Personality']\n",
        ")\n",
        "\n",
        "# Create TabularDataset\n",
        "train_ag = TabularDataset(train_optimized)\n",
        "val_ag = TabularDataset(pd.concat([X_val_final, y_val_final], axis=1))\n",
        "\n",
        "# Enhanced configuration with more sophisticated models and hyperparameters\n",
        "fit_config = {\n",
        "    'time_limit': 14400,  # 4 hours for deeper search\n",
        "    'presets': 'best_quality',  # Upgraded from medium_quality\n",
        "    'hyperparameters': {\n",
        "        'XGB': [\n",
        "            {\n",
        "                'n_estimators': 500,\n",
        "                'max_depth': 8,\n",
        "                'learning_rate': 0.05,\n",
        "                'scale_pos_weight': class_weight_ratio,\n",
        "                'subsample': 0.8,\n",
        "                'colsample_bytree': 0.8,\n",
        "                'min_child_weight': 3\n",
        "            },\n",
        "            {\n",
        "                'n_estimators': 800,\n",
        "                'max_depth': 10,\n",
        "                'learning_rate': 0.03,\n",
        "                'scale_pos_weight': class_weight_ratio,\n",
        "                'subsample': 0.9,\n",
        "                'colsample_bytree': 0.9\n",
        "            }\n",
        "        ],\n",
        "        'RF': [\n",
        "            {'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt'},\n",
        "            {'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2'}\n",
        "        ],\n",
        "        'CAT': [\n",
        "            {\n",
        "                'iterations': 1000,\n",
        "                'learning_rate': 0.03,\n",
        "                'depth': 10,\n",
        "                'class_weights': [1, class_weight_ratio],\n",
        "                'border_count': 254\n",
        "            },\n",
        "            {\n",
        "                'iterations': 1500,\n",
        "                'learning_rate': 0.02,\n",
        "                'depth': 12,\n",
        "                'class_weights': [1, class_weight_ratio]\n",
        "            }\n",
        "        ],\n",
        "        'LR': [\n",
        "            {'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear'},\n",
        "            {'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs'},\n",
        "            {'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear'}\n",
        "        ],\n",
        "        'KNN': [\n",
        "            {'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski'},\n",
        "            {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'},\n",
        "            {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}\n",
        "        ],\n",
        "        'NN_TORCH': [\n",
        "            {'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2},\n",
        "            {'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3}\n",
        "        ]\n",
        "    },\n",
        "    'num_bag_folds': 8,   # Increased bagging\n",
        "    'num_bag_sets': 2,    # Multiple bag sets for diversity\n",
        "    'num_stack_levels': 3, # Deeper stacking\n",
        "    'ag_args_fit': {\n",
        "        'num_gpus': 0,\n",
        "        'verbosity': 3\n",
        "    },\n",
        "    'dynamic_stacking': True,\n",
        "    'auto_stack': True,\n",
        "    'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}  # Auto hyperparameter tuning\n",
        "}\n",
        "\n",
        "print(\"Starting Enhanced AutoGluon training...\")\n",
        "print(f\"Training on {len(train_optimized)} samples with {len(selected_features)} features\")\n",
        "\n",
        "predictor = TabularPredictor(label='Personality', eval_metric='accuracy', verbosity=3)\n",
        "\n",
        "try:\n",
        "    predictor.fit(train_ag, **fit_config)\n",
        "    print(\"Enhanced training completed successfully!\")\n",
        "\n",
        "    # Get detailed leaderboard\n",
        "    leaderboard = predictor.leaderboard(silent=True)\n",
        "    print(\"Enhanced Model Leaderboard:\")\n",
        "    print(leaderboard.head(10))\n",
        "\n",
        "    # Validate on holdout with detailed metrics\n",
        "    val_predictions = predictor.predict(val_ag.drop('Personality', axis=1))\n",
        "    val_probabilities = predictor.predict_proba(val_ag.drop('Personality', axis=1))\n",
        "    val_accuracy = accuracy_score(y_val_final, val_predictions)\n",
        "\n",
        "    print(f\"Enhanced Validation Accuracy: {val_accuracy:.6f}\")\n",
        "\n",
        "    # Check class distribution in predictions\n",
        "    pred_dist = pd.Series(val_predictions).value_counts()\n",
        "    actual_dist = pd.Series(y_val_final).value_counts()\n",
        "    print(\"Validation prediction vs actual distribution:\")\n",
        "    print(f\"Predictions: {pred_dist}\")\n",
        "    print(f\"Actual: {actual_dist}\")\n",
        "\n",
        "    # Feature importance from best model\n",
        "    feature_importance = predictor.feature_importance(train_ag)\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Enhanced training failed: {e}\")\n",
        "    print(\"Falling back to previous configuration...\")\n",
        "\n",
        "    # Fallback to previous working config\n",
        "    fallback_config = {\n",
        "        'time_limit': 7200,\n",
        "        'presets': 'medium_quality',\n",
        "        'hyperparameters': {\n",
        "            'RF': {'n_estimators': 100, 'class_weight': 'balanced'},\n",
        "            'XGB': {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1, 'scale_pos_weight': class_weight_ratio},\n",
        "            'LR': {'class_weight': 'balanced'},\n",
        "        },\n",
        "        'num_bag_folds': 5,\n",
        "        'num_bag_sets': 1,\n",
        "        'num_stack_levels': 2,\n",
        "        'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}\n",
        "    }\n",
        "\n",
        "    predictor = TabularPredictor(label='Personality', eval_metric='accuracy', verbosity=3)\n",
        "    predictor.fit(train_ag, **fallback_config)\n",
        "    val_predictions = predictor.predict(val_ag.drop('Personality', axis=1))\n",
        "    val_accuracy = accuracy_score(y_val_final, val_predictions)\n",
        "    print(f\"Fallback Validation Accuracy: {val_accuracy:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c39329dad7b446d8aaead940e47ad527",
            "ccc4b81f47774e5b966f524178711a89",
            "691a83e46ac14631a59f62d34cab9538",
            "d7d2862cab4d406c9c98b668e725d11a",
            "a65871abdd004b0c8e4535578472bfce",
            "8fb9e80d138147eba5078b8baf8aa46e",
            "931eba48a72941fca731cb4a29a96ead",
            "833162570fa54e11871f5449226b728d",
            "436a830b7bb34078858269d84c632993",
            "d52ee6b8066840cea6df064c96d9168e",
            "b5c51ad9b38244cea9b342ea86a8c4fb",
            "aba89cc0152e49c0b1332d515961edf0",
            "2e3c442806494855a66d18fa9eac94b9",
            "8329c23aa493436ca607db06b2b307a2",
            "03fdbec91d1c4436b5c3d6d08904e6a4",
            "355e929d0e9e4f569b2dcee78212b363",
            "428fe6abe1c041f5ba09d6ae853392a1",
            "f1b95b95cf1448cc81a9e187e6a1f3cf",
            "226e75ed61bc4cedb126209499dace48",
            "987100523af74c82b6e9aaae2459cde1",
            "a077ee00de194348b8a044c832a8a8d5",
            "3dcd7960457a4b568650355392b9c644",
            "d7da430355314dbe97830de8c1026616",
            "77bec4879e42421a9ac18484fddd23c3",
            "f694fafe03eb40f4800b18e1d993a6ba",
            "8cef777dab5a4bf6a3bf394f3e825616",
            "255fd2efbf5546ebba0d4ef2ea454093",
            "95596167d7fa48688becf315a723e34e",
            "a070319691954ae09e8ebcb8df856c66",
            "8bf117e1241349f8b8b6e5ad1d87dd53",
            "7507e2c3d9c1447eb1b7a74eaf2b28ee",
            "3c54156166674ac3850843c62b39d502",
            "b1db8b4a00e146529724efd6c1d355bc",
            "8785bd4e2b0c4e0eb80bccae934ee390",
            "18a4e9b288114a70bb82172ee4d97cd0",
            "cdbec4cc99f24521927f2d19f89c49f6",
            "a4f3309341b445aba7555670c146f072",
            "20132234b4054dc2b5556400ed824f79",
            "97926d148fbe4f0985d8ccdd62c7a384",
            "1d507362973c4b63a3f31f8a8914778c",
            "3d2bc64c5c6d429399961acea9542baf",
            "adf48420e12a49c0b6667a3495b77291",
            "ed9d664f299547a1873966436ee177f3",
            "f742f4d9db2d43748e71df1644e31ee0",
            "a84365e81f2245618baac99e60fb3f97",
            "03cccf2b05f14d7f9bbd147cad2ac3bf",
            "2e6a5830d38b4fb5bd7fb1a704b04582",
            "a0a964736d8544c1842ca8fba808d3e6",
            "66341af7d1974296a36cd4e9bc65d7b6",
            "017ecc2863904f22af06c01b672bc472",
            "5a45365565414fb38467d31cb656972f",
            "1c1fa754f1884d9f931de6060d84554d",
            "2b0fb24b5d4049c391d9677ec0c75c61",
            "02ab743576124b8991cf846d43d56ed4",
            "b222b125edcd49ecb1ff1b327f1dceef",
            "f481ce154a5246219b4f738caa73f800",
            "02f4f95143c34f5ca11391a6317dcf40",
            "2808e94f4d8d48e4a053818e4188c402",
            "91e69df7a9e8490cad9507cd9b66dcfe",
            "048f8b4d196e4c46a74309a65322e676",
            "2f199952bf664a618758b1cb2aab6f0f",
            "4c6a40cfafd84f6f9024ce11246e11d9",
            "cb3256755bab48cda6147ba83b0de81d",
            "28445be6c5e64f1b9b6eeb4444fabbe3",
            "59104cc94c684fbca96fe5519978a94d",
            "ac00cc733d0c4829b1362d32c8d2e594",
            "b962a6280593465e964f5c183f59d5eb",
            "b889aae98f784de39889cc5ce4f684d7",
            "47c6680c2e194894b3ac5347ca5ff8d7",
            "b03dc453e7b743d8a0ad62e6dba609df",
            "c6618df65c6543f7a33c9fc360919a97",
            "c0a98602e9de41dcad80d2669f85148d",
            "0bfac231533d44f6961d13a9c893de7e",
            "79625709ea734a0cb9a57bac065c021e",
            "2c4a446636f7412ca53fdc029cd50d50",
            "bc0ee7c7d2064b9595d4c69dc51ea2c9",
            "7c57e37bd8ae41d7bce9e9fa4c60f34a",
            "38dc98c7b6184e1d98a69393533b39fe",
            "1892a2c0c17549a6b723ad2a54c642be",
            "dc0b68caa7974ba7ac4e0becdfe7de49",
            "17580d9fecfd47e795b81c2786183f77",
            "102c6afe69184509a82462759d33ba9e",
            "159860a22fa1436893a0bbf8f2a578b8",
            "445561923e8f42ca85e4b6f40f717e9c",
            "203d247587b04924a400c1592ef4417e",
            "cb21db6c3b2d4ca3a21d6b5b6f000e13",
            "1e4091c02a4149b69502962743e3b73f",
            "dba96f4dddf44c708380175993358aa6",
            "7e417577cb2a4348b9abf18abef2d0a5",
            "a5a60e0feb4c493b81e179cc7bf45ff6",
            "8e669b9ec6d04113b93b8be16615b8a8",
            "f7899670b4e1499180a8ae47707f5d34",
            "737568be2b5f46c3a7d855a7efef1264",
            "98922b521f84463c947e35b662ed7328",
            "c16a6ca2bd1749e792400c4b3c51637d",
            "e7c698d0a5b6418ab7c992c2425eb71a",
            "2b82a5c59d454448a3aaa42dd7a24011",
            "d04d71c9b1b946fcbf5fcf70f82a2889",
            "12021108647a4497b9649850c02b01fb",
            "ca0cf9f606ad40c4a7114579124ac69c",
            "440d1124dcee4dd092602ee99f575de1",
            "5d080788644e4d11a6adec9419033465",
            "a1c6e3bd82764a8f80d0c8c3b69950c5",
            "b0afe170ac9849c2bb3e3fd2dd1c7934",
            "26c430c4b3b94f66bff1f37e71136c58",
            "a4e3df5b98d641d1b10d131795b27ad2",
            "04fdb179674b44ef94b72dc11f033a48",
            "a9ee39e662f54a148559d41e6959477b",
            "881cf0b64c5645008d8b0aac3539e87c",
            "661b9a57754b4a97805aa6e3651af97a",
            "05febd38b2f24a56bff8aa721bbfd670",
            "3266e99198854abe8e8ab6e9656a4d98",
            "ec67825488cb471b91e127f854d24769",
            "e92e5aa3da7345f5886f0c0492d1e650",
            "53fa2ce84424481ba97b0283f43eec8f",
            "c384b922eb624323ab64f8e58a21f0fc",
            "f65b5a4ccd384d039545456d314fed7a",
            "a22dc3d989da414d81f8e00513f5f7a8",
            "b55dbf3b6d444c2b9226065fd9bf40c9",
            "60b39ce4bfe5445a8db4673a98bd2e0f",
            "37aa925388be4739af4eabdd0a29c5ab",
            "c6c6fcc09805454e94d8d8661d228dbb",
            "1ed9783e32734901832c9caef8bb6d72",
            "e0a62cec56be4080a2d49264ba933789",
            "321d9bbadb354f6bad1aaf05e3d489a6",
            "672f4f2486ea4cfbbdef3074016e4227",
            "ac7663047b4a4e0faeddaf9d843c72a5",
            "ce770371a07a409b868df7d19c21c362",
            "d36cccf3096e4952a4d471b705dd4b68",
            "d615dbc43d8543d0a88f7ae961d1e4a4",
            "39d467c49f9d4c85a04f31b2ca4e4088",
            "7eda72381f2e4606a9905b810ef69734",
            "934d5975eb394fae9e4335ddedf40f2d",
            "8cc267492bc94d21b8fb50e12404ab67",
            "ea2626d75c694c6e9a681e61295985b4",
            "bb64b6b43c1d47f4a40a42f4d1d033db",
            "95485a544c80418cb73aaad5a01b5066",
            "4c13137b440544bc9069716da1c80cc4",
            "93d0fb8acdf04f75b567564972a07c06",
            "5fc3cdc8bd6a4e079481ba636de4649a",
            "e3c77fed5ff94e5799c1884e1a81c10b",
            "5d41ab3ce46444f485cd34e97cab87d1",
            "357360eed0624abba48d52a5508b3e8d",
            "fe46668f8f7c4d50857363ce18654093",
            "96cdaa6596184696a1b7a481cb5fb36e",
            "c70c9084d1a44c6eab74b202bdd782fb",
            "4fa1efe6019745fb89c1f0b9baed0179",
            "9aa82e400d9a435593981eae420563ef",
            "dd2275b9fd3e4e5daab1333e368ac704",
            "74375220f75e4190a18ff3c32b92a0ae",
            "f65272d8f79b4add8a0fe96ae3a92d29",
            "1d8addff75b54bd1afd0d947f3bc15e2",
            "4b8785256cc3484baddeabd562a81aa5",
            "8196229585aa4133a76869bb4717a37e",
            "9706b21aea72425c91d8ff50c7d4f581",
            "d4ed7941df77415cb2a6805bbc08df68",
            "21c6ae7b8b3549fbb0f8915d5788beed",
            "00f796491a9244de9de503e2e412c2ca",
            "2b4270802e5041b3a7e5b73785e93353",
            "850e15b9cd86478099023d0c9e615cf9",
            "44a16e2ab44b43dab477d3716e1b1106",
            "943a83a3b5664e0f8a884eea6e50ec19",
            "66186d2e697b4e7e8e9c4847447cc84e",
            "5a3d68c5022946c0a7df33c13146b5e6",
            "20364673c9ef4e8c82c0555693ac2825",
            "747224649c7b45ab9222ecc2ff976163",
            "df84d3ddbf01408789527670999667f2",
            "c0e324850cd34337846459f7610fdc96",
            "a7488a1d100e434da1814c653d5968a8",
            "231241568fa849fabbd15e385381dc47",
            "77870fe8c8b14e49ab67bfb2e0a71d5e",
            "a5c740e0435d4e5b9afc668e30258831",
            "79f0fdb25ebc497e8d08c03c50685f54",
            "b171b5fd8b2247258bd244f672a20e46",
            "8f3d14430d574f769fad4ea75a6d1228",
            "05536f07d153400a8265f77177ca0733",
            "fbd862de201946c5aa633c6364c4a34f",
            "10096f5c9d4740e49d01a5e468e1d8fa",
            "79962fcdd65e4a22b525e20bb9130e23",
            "b08f2cc9ee694ff695d4f2c5dafb0db5",
            "5b6fb4a2074749018b54961ab9a9cbb5",
            "8cc70c8f210b47fdb049b7d42107372b",
            "a9c4eeb61fcd468fa90ea82ffe66c1e0",
            "d117573eb4024e709f5a677fce175902",
            "be2be969804b4ebebe1c294e7645e4dd",
            "49b6c674f6e24befbc29bdee516eb133",
            "457ac74886614d1f9fdb7b2254d0b59d",
            "3c321d73b51044418b98d91a4941e829",
            "a8dc2154542f4e73b3d3fb070a11b565",
            "4ccb5634492f469a9cac686fed106a65",
            "81bb18401ac74ec6837931662b613e03",
            "a5978f8bcc70495f88b5b9fb3d0bacf0",
            "b17140ef83c74cbebfd7f2321d8b9f6a",
            "dcc0dabfb65a464ead0b2db617616d19",
            "eed042bb665947ff878aa08b6af96ee5",
            "54c5a720d65147e188821a63a839cf32",
            "bd6e2d55be104e86a24147be77ce716b",
            "91d9d8b1459a48b2bef9e53c2dac4264",
            "5c164e2a97ef40a4bb149976010177c5",
            "94cbfc78eb944966aac1a8860eded3eb",
            "e623584c6b6e4374ae6b39f3dcdb88f0",
            "6002061a3a29491d90b52bfcca9a8e78",
            "e6ca644803a74c6c9842112d03c080e3",
            "0a538457e19f430ea30b7cb39a1fac61",
            "2865d7e9bc6a4c98adfecc051f3aa2a0",
            "d73be076e7da4be89be4f18065d7e13e",
            "63ae9de0c59c4a7ab23e54144146e2ea",
            "d6258f14f5194df69df9c5c872cf5b56",
            "e4ac8c731b0f4f7685c764434ad85001",
            "7cc80fee0808478aa48247eb05a86f71",
            "e73d455ab5654221906f1fd7228ca931",
            "d0e0085db358426cbf8c058d299a8014",
            "cd5342342f6842d9ac07ff4efbf5de9f",
            "9ac2d16c7bfa4535b432c3b576392aaf",
            "958ac12efe324b6a81135dda767c2f6c",
            "8a947e638cac44dfa914db39a15a1971",
            "c39e64b0e4464ce8a07d463761449499",
            "54884faa0e8349aeab2510da8e9b90e8",
            "7208d8e95b9f4bf6b8f23045d1429864",
            "8d06137db6e943b883cd1ecab62160d7",
            "eaf8db7cb35a48b6a33cf6d803642a5d",
            "9faa469a1c78446a802d602daa7ae74f",
            "3b1b5b93fb9d4120a8ac52e11f934ed7",
            "6bb0377af2df477c9b15ff94847ee49b",
            "d75e6f1bacd545af8c4214bcf08c233c",
            "6a9f934ea769480686ff04fe7639a5cc",
            "cc539e7e85404b209cd088ae2344885d",
            "45ceb912cf0b4f56b574b0fcbd2a1308",
            "74dffe2b62c740adb6b1e84706aebf97",
            "b7bf2c6ff53f4db696bbadc8170281be",
            "aa0478bd3eab4adb89b32de3dd726010",
            "333f6cf829204adcbc0acaf9e7de0b7f",
            "0f2230b5358e48e2b19e5ff0d01ee882",
            "4cdb9fbd366f44f59bff731b71657a9b",
            "be41ff71f3a84616b4a02f4d33c37a70",
            "c60ac8d90a1e490ca8bfc502ec4150a7",
            "916c2862852949d6ba72009f020c556f",
            "ae6f07f4aed8415d9fba67e68ec6559f",
            "9f9a246c89a6472eafad8f3917a3719b",
            "da563084583d4c909f54192d49b6d4ab",
            "428d6ac2f1a3474eae157c4bf3d18388",
            "b528a5b8e48141009313ebaa2b9e8948",
            "b248bbb25c4c46a7a604b0ca73841f8b",
            "c9429aff0b2245b693af58ffcac80d0b",
            "70afb7003d5b4d4280ca718b5067e30c",
            "8788f10745bf4789ac5273a43545e18e",
            "79e046620875405086f63985968bda97",
            "8b7123f5ccb44d4a8486f5dd6158adad",
            "c3e9c7de8872490781b5e42cc38fe975",
            "b8cdc3532d8e44c38c90547fa69f932d",
            "975fcabf4058431baa337cc7f1f762c7",
            "bf5ff00b3e5e445681b576e0acff681c",
            "4da80c3539af44fda5edff788eeeff1f",
            "8fbddc0691cc4f608b948f64efca5f59",
            "e8a41efed16c45e684bdf844cf924984",
            "54f9cf3c0b1940f5b4a29754b17e1233",
            "a4dd863e5f574c2487f35dd43a0bba71",
            "6a4e87daa4034c8c843a171e01148d33",
            "959fa8ab120947129a5f989db10e2806",
            "78470110d53945368b247419d974f75f",
            "739adde51fe84fb1b9a96649a9d91a09",
            "b340000ea8834bb8984ce50fd7151470",
            "663e4e47ada940ac92e2c3a8b7cce39f",
            "931ca17eb62442ff88e31e91fcced62d",
            "1afcfa698de645988b06e90174c9b8dc",
            "a56a0a06258b464f8496fca9730990c2",
            "220d5468fdac40868f40f5a20f4c1422",
            "b0c607d9581c4510bbc4981a79a8694e",
            "505a5b6928b247cf9628ef7761bf7a8f",
            "ad6d1a0d44ee4b98873b2dd6693caae4",
            "0caba4bc02be42538ad27c3d43a703ad",
            "07bca64bef58431298ca593a5b352926",
            "efd82b4c8bc84a8ba5b2989955a77fa2",
            "89ef791835044c71841b3c22b394700e",
            "b6a2c3758e034482862fa7a10c98d3cb",
            "dbf65adf50364560b4261b555ccb5518",
            "b10297dfca644265aa69580bdc3a01d3",
            "99a88c5f7a7b4fb993d43ec2bbb0eb8f",
            "f62c7b64aad04f89b8be4e84f12b817e",
            "c760d887e0bd479fb3d7f3b19b636029",
            "a3395e7173cc46e6b227721cbce9d8ad",
            "818b8f66b39242139dafa2a9b12b8cde",
            "58344a6d00e24e4caaedd7c659b0c317",
            "d09e0b6dbfca4830a785e35135a527b8",
            "097e6b67a23448be9bd7afc74b3dcd1c",
            "ed28016fd2bb41788c40321d44600624",
            "173b8d49231a4ba3af1e54c334811373",
            "62dcb5a1e05546b9b8143fe3d9a4b17c",
            "97cf1eb4cc0e49e09cd49f92632f44ff",
            "de366c1089624ca79653b062abce629f",
            "1833875e60c74e06b08e7792723ed9cf",
            "888e75dcfd8c430fb1d399234667329e",
            "9a389c7f77a740f4916400ffbf569fe6",
            "9e9edd9a33224889a039e9ad74b4862c",
            "f3d27e22d23145e2be095fcf160fd155",
            "8932e93fc050499f95662b0f42bb236b",
            "fcf2ccc348394948add22f2c109d1c5b",
            "cad0109aabb647de94eac66232bfefc2",
            "b8e33e95f2634f7a96a9cf5fa7676a6e",
            "822d5f380ce84c07ad899610eafd0d91",
            "461ebbde0873480a985b60988bff8144",
            "be9c73765fd54210ae1ccb985a231528",
            "78eb32060ba540a0b70b369a2d8e6ef6",
            "2e3b6d811cdd449b91ab026528c7b6be",
            "0ba36ca9d8124383bd67b40169bcdd1a",
            "db662e29ab8c4297b5170cae7927b05c",
            "3d4ef02e604a4a869c82bb1313189d31",
            "e4ba8ada42094612b308c9b8fd1db2ac",
            "2d0e45eba4844082a3582fff061da0d5",
            "24334f22776f4165b2099f94cb6d2405",
            "373ae7e947f146d899b349245506fa9c",
            "6afb5e28fcfb46628b77e2ae6a6847b0",
            "82ca27cff2134a1989b5afbaff3d7473",
            "6ceaef0fde1f4958b11b111a4fc96c9b",
            "c28d1175a6ca4394b75a52f077957191",
            "f2861fb20f9f4971ba9a7694a5cc8910",
            "2caebbf1a8c14b7e8cb4a23950f7329f",
            "12d81b753f77406283ffab32cf2382e8",
            "a626c9dec48c4e4fb19f7c311124401f",
            "8dabbc522c844eb19d6c76b7e7d33b46",
            "7d9696e1f56e4e8b8b019c2c1eb761fc",
            "703bc09114104211af086dc22074527d",
            "a25a0aa7bf654a998bf33127fd5c2cb0",
            "712168d483304835b9710e75992ca4d6",
            "62115896810c414c9f7a6a53ec8456bf",
            "55cefdc386fe4c1dbb622263859868a1",
            "f7cbe57931774be2b07f33a31a36c1c6",
            "aae8b125847f4006a9f956ea181268a9",
            "e58d132deeb24173babb27041116e3ff",
            "4dc0a3e7c9824c0bb7355f621c4f5875",
            "e7ae15a9094f4a33aa2f217dc0f895ff",
            "e72b1184714b4b9cba7dc978521e8ff0",
            "b1d77685c9e2411e8c48892b451da6e4",
            "23cb88d9d8ab49198b621183fd80af9c",
            "d857c989ce0c4be7bbc0ea66c2f26e90",
            "e6c8090194d84bb4bd4673d3d8f819a8",
            "eb3acc1b122540908968c966823b47e1",
            "bba77098c3e64c2faf6132614b56ec5a",
            "4ffce6f5114a47049e13ad57e14ee8d6",
            "c2e1f4076dae434bb5d5b0c063dc9b59",
            "2a1def2981504936beaad81dc9e81aeb",
            "d3899a8dffd64393b29adf3cbd252f9d",
            "6e0161943ff84e1ba0ba6eb6aafba0b9",
            "972e5080014e41a39ca1f913370bad2f",
            "99bc63036f1d4e24a33583ea7b3ff87a",
            "2ed3bd4a382f44a9a626ab8eb79b6702",
            "13a772242d9e4c6bac453678a3fb4667",
            "3b19243bf36c4f46a17c5af9b9998b45",
            "9f0d86056a6a4e0c9bf36e7eeba8b0bf",
            "242dc808f539487987d6c2c22855ca92",
            "0b27369295f64f22ab978ac24536db5b",
            "c9b84e50804043b19da91d94504d272c",
            "c6a50d7cfa6045ad981bb3adc1f14703",
            "0758bf152f784ab38046bad02616cc27",
            "991563224088486d8acb4933688247d2",
            "eba279249ec74067913a079f7030fe13",
            "75a53cc9ac164af0923ff7f7387d82d5",
            "97c6f939774245b18634e1cc0196a8c9",
            "21885309c92848d997c25d0da7376be5",
            "d2c0f3610d024c19951927cc08a1f460",
            "0f7c88d63b094239808f72daa17086d9",
            "5b3c246f6b194de586b7b1494958e925",
            "d4dc21e9501d4f9497ec6441101d64e5",
            "b2e0f17512a8476da619c4b1feb3b5fa",
            "873079a0fb61466199de789a7d997399",
            "5895c5b723f348c6afbd996452528fd2",
            "489993851e9f40a296268cbd0999455b",
            "2d4dd6d970f44f30a5cd17d254fcc8c6",
            "720d6cdbb0e1408abfe9a62ab689cd01",
            "b866212ea6ab4d918ea1330bdc2b8b47",
            "60d32b2d94004eda9337498c7b067797",
            "d62a3b56170441baa5f8f1d43d2a3230",
            "f96e976734e94c3ca99452b07ac57cd0",
            "ceedbc4b057045239816bf8f909a8e0b",
            "3260b9ebec9b45f49d34c0a336702462",
            "0c4085548f3446e991350fee34325395",
            "a2cac5aa97a2427387ecb0a19416bdfc",
            "cb7af662a8364c1d9f30fdc0c56aaf9f",
            "77e65d7d1b59418684341aa03df5f1f2",
            "6bfbabba022c4cea9da15891d15e07c2",
            "aef034c95ad64f7290a22c8a57474435",
            "0a962087a3124878a70835806786b7a1",
            "5e14050c1edd461ba87b2b46661e4ad3",
            "731114b874484a7ba261233b410998d4",
            "ef7d8b62e47d43c5b1bbb02c310b2ebb",
            "4c4f8808a6844e3cbd88bb2403be889d",
            "384c1acff3894a61ba2ee93bf3a55ce4",
            "0c7d5515c00b4d3aa8a98d7375e6a510",
            "a6b9dafa9569455eb79c841551fb1315",
            "5222d11336e545e5b6eaea6e66692d04",
            "846dee0ce9cc4b51b7cf14245dfa2e2e",
            "641d053f5577417dbad4864e5bfe6fd4",
            "d41a05dec34645d08e6051e4576828d2",
            "248a17051e764df090cb9c3c4a13741e",
            "0431d74662cc4a71919c9d122e703f77",
            "7e5338203d2e45bc9060a9bb2cdb5127",
            "41bec731fdaf4bf29e9d1c3f98979b73",
            "5c62567c399941d7aa11222c1f16603d",
            "3f8c2fd64a15457385e58086fa1c01a7",
            "fdb8448a608f473a8813624af1f34a5e",
            "9697d19eea9f4f51bf5142d56298cd68",
            "c3cad4e06d2f441ca4abde191cc5b73c",
            "3fe733d1aa554ed8ad8705232c777e10",
            "10cbff6c15d54c8791f2a0d4a1aba6a3",
            "738f137e510b49d691a6ec40a88bbb6e",
            "9c703254497b4be48ad13eae86ee3a8b",
            "57daf4eb88a4466a83eefd67295aedeb",
            "cf94ab7c79f4432aa11359cfe5f0218a",
            "8d95c879188549e2aa48b5c3b4168a2f",
            "c319249e35684ef28d322dca574b515b",
            "f105c36a342347c8a464651ca5f80641",
            "669856cee8624777b2f702dc290d7988",
            "1984706069354065b4dc524059810a7a",
            "b895a6137f514a81a4f8920782ae4c28",
            "572e3fbb34054369adf2919b18e03f2b",
            "fa8c595faa594861a22ed024228391cd",
            "c0f80930a0d94f19940a0aef112dffc7",
            "c97e9ccc2f784d9c9eb01c24398f3b3a",
            "4c05c042ce224eaeaa1e6984df7fac74",
            "29782c72843f4a21880cc0061848eabe",
            "d6d3e69fa1a34777a362db781783dc83",
            "2a35af1c821e44e78c08802c44f5dffc",
            "c8d17263441446418ebadeb81ff6eb09",
            "76ce3e964d0e46cab7de38f4f5a0efe1",
            "e530c49341e44c04b52d6d95e8c47904",
            "5702774b58124eb2b64aa0071c99bcb7",
            "93de1918d29e47f9b4f6abcc3841569b",
            "0f183488d0df4af094dd37298f49948e",
            "2430b8defe394746b1e29353f50ac2b1",
            "5fb8f82ae83649bf9aad4ae308411608",
            "da5f0b829061407188a9a47119846ed6",
            "910f8720f03a4a01ad3007bb06931dfc",
            "c9d66ba5779646c98dc6169daa64e0c7",
            "5ea096b52f3c4ca886c970df9ba53e2f",
            "ef743d7a6b4144588d9e4d5f20528396",
            "502ecd4144b045d4b4c897c843c152ec",
            "c78a8ced9e5e4f78b43889a22a1f97b2",
            "7a900d34a73e42e09ad98e423b86ed22",
            "a05b5d91463a4655810e55d09be520dc",
            "46bfef67c3ee4e0ca6e34d542094df1e"
          ]
        },
        "id": "2s6diMa2_Lf6",
        "outputId": "73897e72-695f-4803-8bc4-ecc56e95dbcc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250721_125522\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       9.66 GB / 12.67 GB (76.2%)\n",
            "Disk Space Avail:   66.56 GB / 107.72 GB (61.8%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'ag_args_fit': {'num_gpus': 0, 'verbosity': 3},\n",
            " 'auto_stack': True,\n",
            " 'hyperparameter_tune_kwargs': {'num_trials': 30,\n",
            "                                'scheduler': 'local',\n",
            "                                'searcher': 'auto'},\n",
            " 'num_bag_folds': 8,\n",
            " 'num_bag_sets': 2,\n",
            " 'num_stack_levels': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3},\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': {'num_trials': 30,\n",
            "                                'scheduler': 'local',\n",
            "                                'searcher': 'auto'},\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': 8,\n",
            " 'num_bag_sets': 2,\n",
            " 'num_stack_levels': 3,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=8, num_bag_sets=2\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 3600s of the 14400s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho\"\n",
            "Running DyStack sub-fit ...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho\"\n",
            "Train Data Rows:    18511\n",
            "Train Data Columns: 13\n",
            "Label Column:       Personality\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = Introvert, class 0 = Extrovert\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Introvert) vs negative (Extrovert) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9892.41 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.67 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Enhanced AutoGluon training...\n",
            "Training on 20825 samples with 13 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('object', 'object') : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('object', []) : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t11 features in original data used to generate 11 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('object', 'object') : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('object', []) : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t('float64', 'float')     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('int8', 'int')          : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t0.3s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3}, {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
            "\t'RF': [{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt'}, {'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2'}],\n",
            "\t'CAT': [{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254}, {'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783]}],\n",
            "\t'LR': [{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear'}, {'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs'}, {'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear'}],\n",
            "\t'KNN': [{'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski'}, {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}, {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}],\n",
            "\t'NN_TORCH': [{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2}, {'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3}],\n",
            "}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
            "Model configs that will be trained (in order):\n",
            "\tKNeighbors_BAG_L1: \t{'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighbors_2_BAG_L1: \t{'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighbors_3_BAG_L1: \t{'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_BAG_L1: \t{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_2_BAG_L1: \t{'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tCatBoost_2_BAG_L1: \t{'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_BAG_L1: \t{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_2_BAG_L1: \t{'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_BAG_L1: \t{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_2_BAG_L1: \t{'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_3_BAG_L1: \t{'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_2_BAG_L1: \t{'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "Fitting 14 L1 models, fit_strategy=\"sequential\" ...\n",
            "Hyperparameter tuning model: KNeighbors_BAG_L1 ... Tuning model for up to 77.12s of the 3599.66s of remaining time.\n",
            "\tFitting KNeighbors_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/model_template.pkl\n",
            "\t0.03s \t= Train Time (Using 10000/18511 rows) (77.08s remaining time)\n",
            "\t0.04s \t= Train Time (Using 18511/18511 rows) (77.04s remaining time)\n",
            "\t0.94s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_BAG_L1 ...\n",
            "\t0.9477\t = Validation score   (accuracy)\n",
            "\t0.58s\t = Training   runtime\n",
            "\t0.47s\t = Validation runtime\n",
            "\t39669.9\t = Inference  throughput (rows/s | 18511 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: KNeighbors_2_BAG_L1 ... Tuning model for up to 77.12s of the 3599.04s of remaining time.\n",
            "\tFitting KNeighbors_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_2_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_2_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/model_template.pkl\n",
            "\t0.02s \t= Train Time (Using 10000/18511 rows) (77.09s remaining time)\n",
            "\t0.04s \t= Train Time (Using 18511/18511 rows) (77.04s remaining time)\n",
            "\t1.45s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_2_BAG_L1 ...\n",
            "\t0.9484\t = Validation score   (accuracy)\n",
            "\t1.09s\t = Training   runtime\n",
            "\t0.97s\t = Validation runtime\n",
            "\t19168.8\t = Inference  throughput (rows/s | 18511 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: KNeighbors_3_BAG_L1 ... Tuning model for up to 77.12s of the 3597.89s of remaining time.\n",
            "\tFitting KNeighbors_3_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_3_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_3_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/model_template.pkl\n",
            "\t0.02s \t= Train Time (Using 10000/18511 rows) (77.09s remaining time)\n",
            "\t0.03s \t= Train Time (Using 18511/18511 rows) (77.06s remaining time)\n",
            "\t0.95s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_3_BAG_L1 ...\n",
            "\t0.9484\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "\t24040.5\t = Inference  throughput (rows/s | 18511 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 77.12s of the 3596.99s of remaining time.\n",
            "\tFitting RandomForest_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/model_template.pkl\n",
            "\t4.78s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/model.pkl\n",
            "Fitted model: RandomForest_BAG_L1 ...\n",
            "\t0.9595\t = Validation score   (accuracy)\n",
            "\t6.87s\t = Training   runtime\n",
            "\t1.06s\t = Validation runtime\n",
            "\t17444.9\t = Inference  throughput (rows/s | 18511 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_2_BAG_L1 ... Tuning model for up to 77.12s of the 3590.08s of remaining time.\n",
            "\tFitting RandomForest_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_2_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_2_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/model_template.pkl\n",
            "\t5.9s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/model.pkl\n",
            "Fitted model: RandomForest_2_BAG_L1 ...\n",
            "\t0.9525\t = Validation score   (accuracy)\n",
            "\t11.13s\t = Training   runtime\n",
            "\t1.52s\t = Validation runtime\n",
            "\t12209.8\t = Inference  throughput (rows/s | 18511 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 77.12s of the 3578.89s of remaining time.\n",
            "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_BAG_L1 model...\n",
            "\tHyperparameter search space for CatBoost_BAG_L1: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c39329dad7b446d8aaead940e47ad527"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_BAG_L1 model HPO: 2.089388608932495\n",
            "Best hyperparameter configuration for CatBoost_BAG_L1 model: \n",
            "{'iterations': 1000, 'learning_rate': 0.03, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L1... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_2_BAG_L1 ... Tuning model for up to 77.12s of the 3576.78s of remaining time.\n",
            "\tFitting CatBoost_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_2_BAG_L1 model...\n",
            "\tHyperparameter search space for CatBoost_2_BAG_L1: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aba89cc0152e49c0b1332d515961edf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L1/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_2_BAG_L1 model HPO: 2.3660881519317627\n",
            "Best hyperparameter configuration for CatBoost_2_BAG_L1 model: \n",
            "{'iterations': 1500, 'learning_rate': 0.02, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_2_BAG_L1... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 77.12s of the 3574.4s of remaining time.\n",
            "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for XGBoost_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03646\n",
            "[50]\tvalidation_0-error:0.03646\n",
            "[100]\tvalidation_0-error:0.03619\n",
            "[150]\tvalidation_0-error:0.03592\n",
            "[200]\tvalidation_0-error:0.03646\n",
            "[250]\tvalidation_0-error:0.03700\n",
            "[300]\tvalidation_0-error:0.03700\n",
            "[350]\tvalidation_0-error:0.03754\n",
            "[364]\tvalidation_0-error:0.03754\n",
            "[0]\tvalidation_0-error:0.03755\n",
            "[50]\tvalidation_0-error:0.03728\n",
            "[100]\tvalidation_0-error:0.03728\n",
            "[150]\tvalidation_0-error:0.03674\n",
            "[200]\tvalidation_0-error:0.03782\n",
            "[250]\tvalidation_0-error:0.03917\n",
            "[281]\tvalidation_0-error:0.03998\n",
            "[0]\tvalidation_0-error:0.03728\n",
            "[50]\tvalidation_0-error:0.03647\n",
            "[100]\tvalidation_0-error:0.03701\n",
            "[150]\tvalidation_0-error:0.03782\n",
            "[200]\tvalidation_0-error:0.03890\n",
            "[207]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03701\n",
            "[50]\tvalidation_0-error:0.03755\n",
            "[100]\tvalidation_0-error:0.03728\n",
            "[150]\tvalidation_0-error:0.03755\n",
            "[200]\tvalidation_0-error:0.03755\n",
            "[202]\tvalidation_0-error:0.03755\n",
            "[0]\tvalidation_0-error:0.03431\n",
            "[50]\tvalidation_0-error:0.03539\n",
            "[100]\tvalidation_0-error:0.03458\n",
            "[150]\tvalidation_0-error:0.03566\n",
            "[200]\tvalidation_0-error:0.03566\n",
            "[203]\tvalidation_0-error:0.03620\n",
            "[0]\tvalidation_0-error:0.03322\n",
            "[50]\tvalidation_0-error:0.03430\n",
            "[100]\tvalidation_0-error:0.03430\n",
            "[150]\tvalidation_0-error:0.03430\n",
            "[200]\tvalidation_0-error:0.03430\n",
            "[202]\tvalidation_0-error:0.03430\n",
            "[0]\tvalidation_0-error:0.03782\n",
            "[50]\tvalidation_0-error:0.03674\n",
            "[100]\tvalidation_0-error:0.03647\n",
            "[150]\tvalidation_0-error:0.03620\n",
            "[200]\tvalidation_0-error:0.03647\n",
            "[250]\tvalidation_0-error:0.03728\n",
            "[300]\tvalidation_0-error:0.03809\n",
            "[332]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03998\n",
            "[50]\tvalidation_0-error:0.04025\n",
            "[100]\tvalidation_0-error:0.04025\n",
            "[150]\tvalidation_0-error:0.04079\n",
            "[200]\tvalidation_0-error:0.04187\n",
            "[205]\tvalidation_0-error:0.04187\n",
            "[0]\tvalidation_0-error:0.03350\n",
            "[50]\tvalidation_0-error:0.03241\n",
            "[100]\tvalidation_0-error:0.03241\n",
            "[150]\tvalidation_0-error:0.03269\n",
            "[200]\tvalidation_0-error:0.03296\n",
            "[213]\tvalidation_0-error:0.03296\n",
            "[0]\tvalidation_0-error:0.03809\n",
            "[50]\tvalidation_0-error:0.03836\n",
            "[100]\tvalidation_0-error:0.03836\n",
            "[150]\tvalidation_0-error:0.03863\n",
            "[200]\tvalidation_0-error:0.03836\n",
            "[203]\tvalidation_0-error:0.03863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/model.pkl\n",
            "Fitted model: XGBoost_BAG_L1 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t41.92s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "\t14366.2\t = Inference  throughput (rows/s | 3703 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_2_BAG_L1 ... Tuning model for up to 77.12s of the 3532.43s of remaining time.\n",
            "\tFitting XGBoost_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_2_BAG_L1 model...\n",
            "\tHyperparameter search space for XGBoost_2_BAG_L1: \n",
            "min_child_weight:   Int: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7da430355314dbe97830de8c1026616"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03630\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[191]\tvalidation_0-error:0.03717\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03976\n",
            "[100]\tvalidation_0-error:0.04062\n",
            "[150]\tvalidation_0-error:0.04062\n",
            "[188]\tvalidation_0-error:0.04062\n",
            "[0]\tvalidation_0-error:0.03544\n",
            "[50]\tvalidation_0-error:0.03544\n",
            "[100]\tvalidation_0-error:0.03414\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[200]\tvalidation_0-error:0.03414\n",
            "[250]\tvalidation_0-error:0.03457\n",
            "[255]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.03457\n",
            "[50]\tvalidation_0-error:0.03328\n",
            "[100]\tvalidation_0-error:0.03371\n",
            "[150]\tvalidation_0-error:0.03371\n",
            "[200]\tvalidation_0-error:0.03414\n",
            "[250]\tvalidation_0-error:0.03414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 256. Best iteration is: \t[104]\t0.03284356093344858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[255]\tvalidation_0-error:0.03414\n",
            "[0]\tvalidation_0-error:0.04408\n",
            "[50]\tvalidation_0-error:0.04278\n",
            "[100]\tvalidation_0-error:0.04235\n",
            "[150]\tvalidation_0-error:0.04278\n",
            "[200]\tvalidation_0-error:0.04322\n",
            "[250]\tvalidation_0-error:0.04322\n",
            "[251]\tvalidation_0-error:0.04322\n",
            "[0]\tvalidation_0-error:0.03673\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03587\n",
            "[150]\tvalidation_0-error:0.03587\n",
            "[189]\tvalidation_0-error:0.03673\n",
            "[0]\tvalidation_0-error:0.03025\n",
            "[50]\tvalidation_0-error:0.03068\n",
            "[100]\tvalidation_0-error:0.03111\n",
            "[150]\tvalidation_0-error:0.03068\n",
            "[184]\tvalidation_0-error:0.03068\n",
            "[0]\tvalidation_0-error:0.03761\n",
            "[50]\tvalidation_0-error:0.03761\n",
            "[100]\tvalidation_0-error:0.03718\n",
            "[150]\tvalidation_0-error:0.03718\n",
            "[185]\tvalidation_0-error:0.03718\n",
            "[0]\tvalidation_0-error:0.03544\n",
            "[50]\tvalidation_0-error:0.03544\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[186]\tvalidation_0-error:0.03630\n",
            "[0]\tvalidation_0-error:0.03198\n",
            "[50]\tvalidation_0-error:0.03198\n",
            "[100]\tvalidation_0-error:0.03198\n",
            "[150]\tvalidation_0-error:0.03155\n",
            "[200]\tvalidation_0-error:0.03155\n",
            "[250]\tvalidation_0-error:0.03241\n",
            "[300]\tvalidation_0-error:0.03328\n",
            "[324]\tvalidation_0-error:0.03414\n",
            "[0]\tvalidation_0-error:0.03587\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[184]\tvalidation_0-error:0.03630\n",
            "[0]\tvalidation_0-error:0.04365\n",
            "[50]\tvalidation_0-error:0.04322\n",
            "[100]\tvalidation_0-error:0.04278\n",
            "[150]\tvalidation_0-error:0.04235\n",
            "[200]\tvalidation_0-error:0.04235\n",
            "[250]\tvalidation_0-error:0.04278\n",
            "[300]\tvalidation_0-error:0.04408\n",
            "[308]\tvalidation_0-error:0.04408\n",
            "[0]\tvalidation_0-error:0.04105\n",
            "[50]\tvalidation_0-error:0.03717\n",
            "[100]\tvalidation_0-error:0.03673\n",
            "[150]\tvalidation_0-error:0.03717\n",
            "[200]\tvalidation_0-error:0.03760\n",
            "[244]\tvalidation_0-error:0.03717\n",
            "[0]\tvalidation_0-error:0.03241\n",
            "[50]\tvalidation_0-error:0.03241\n",
            "[100]\tvalidation_0-error:0.03198\n",
            "[150]\tvalidation_0-error:0.03198\n",
            "[187]\tvalidation_0-error:0.03241\n",
            "[0]\tvalidation_0-error:0.03500\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03371\n",
            "[150]\tvalidation_0-error:0.03371\n",
            "[200]\tvalidation_0-error:0.03414\n",
            "[250]\tvalidation_0-error:0.03457\n",
            "[285]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.04064\n",
            "[50]\tvalidation_0-error:0.04150\n",
            "[100]\tvalidation_0-error:0.04150\n",
            "[150]\tvalidation_0-error:0.04150\n",
            "[186]\tvalidation_0-error:0.04150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for XGBoost_2_BAG_L1 model HPO: 51.90469574928284\n",
            "Best hyperparameter configuration for XGBoost_2_BAG_L1 model: \n",
            "{'n_estimators': 800, 'learning_rate': 0.03, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'max_depth': 10, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 1}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T1 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t51.85s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "\t5958.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_BAG_L1 ... Tuning model for up to 77.12s of the 3480.5s of remaining time.\n",
            "\tFitting LinearModel_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8785bd4e2b0c4e0eb80bccae934ee390"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_BAG_L1 model HPO: 14.405663013458252\n",
            "Best hyperparameter configuration for LinearModel_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T1 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t3.68s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "\t5927.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T2 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t3.62s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t5779.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T3 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t3.94s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "\t6836.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T4 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t3.05s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "\t8427.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_2_BAG_L1 ... Tuning model for up to 77.12s of the 3466.05s of remaining time.\n",
            "\tFitting LinearModel_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_2_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_2_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a84365e81f2245618baac99e60fb3f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_2_BAG_L1 model HPO: 34.18801784515381\n",
            "Best hyperparameter configuration for LinearModel_2_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T1 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t11.2s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "\t4736.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T2 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t7.64s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "\t4740.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T3 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t7.16s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "\t6881.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T4 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t8.08s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "\t6557.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_3_BAG_L1 ... Tuning model for up to 77.12s of the 3431.82s of remaining time.\n",
            "\tFitting LinearModel_3_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_3_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_3_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f481ce154a5246219b4f738caa73f800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_3_BAG_L1 model HPO: 26.669235944747925\n",
            "Best hyperparameter configuration for LinearModel_3_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T1 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t6.41s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "\t5710.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T2 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t7.32s\t = Training   runtime\n",
            "\t0.48s\t = Validation runtime\n",
            "\t4841.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T3 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t6.04s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "\t8147.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T4 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t6.78s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "\t7354.5\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 77.12s of the 3405.09s of remaining time.\n",
            "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_BAG_L1 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_BAG_L1: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b962a6280593465e964f5c183f59d5eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1733, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1553, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1543, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1618, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1493, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1524, Val accuracy: 0.9646, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1498, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1489, Val accuracy: 0.965, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1704, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1562, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1498, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1471, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1489, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1463, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1455, Val accuracy: 0.9581, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9589455488331893\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.172, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1597, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.153, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1521, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.152, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1507, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1521, Val accuracy: 0.9654, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1764, Val accuracy: 0.9672, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1564, Val accuracy: 0.968, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1577, Val accuracy: 0.9676, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1562, Val accuracy: 0.9676, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.151, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1514, Val accuracy: 0.9676, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1558, Val accuracy: 0.968, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9680207433016422\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1728, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1552, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1531, Val accuracy: 0.9585, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.152, Val accuracy: 0.9581, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1487, Val accuracy: 0.9589, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1459, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1444, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1445, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1426, Val accuracy: 0.9576, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 5 (Update 630). Val accuracy: 0.9589455488331893\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1698, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1565, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1568, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1539, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1491, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1507, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1507, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1476, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1484, Val accuracy: 0.965, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1746, Val accuracy: 0.9706, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1588, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1608, Val accuracy: 0.9693, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1561, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1533, Val accuracy: 0.9689, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.152, Val accuracy: 0.9697, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9706136560069144\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1752, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1562, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1553, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1507, Val accuracy: 0.9637, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.151, Val accuracy: 0.9637, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1497, Val accuracy: 0.9641, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1489, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1461, Val accuracy: 0.9641, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9641158668396023\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1764, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1559, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.154, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1555, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1503, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1505, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1505, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1493, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1472, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1507, Val accuracy: 0.9641, Best Epoch: 2\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "Best model found on Epoch 2 (Update 252). Val accuracy: 0.9649956784788245\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1747, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1587, Val accuracy: 0.9685, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1584, Val accuracy: 0.9685, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1539, Val accuracy: 0.9685, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1519, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1529, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1502, Val accuracy: 0.9685, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopped on Update 987 (Epoch 7))\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1705, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1583, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1552, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1535, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1498, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1496, Val accuracy: 0.9641, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1495, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1481, Val accuracy: 0.9641, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1465, Val accuracy: 0.9641, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1466, Val accuracy: 0.9641, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopped on Update 1376 (Epoch 10))\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.174, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.153, Val accuracy: 0.9568, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.152, Val accuracy: 0.9572, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1508, Val accuracy: 0.9572, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1476, Val accuracy: 0.9576, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1542, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1471, Val accuracy: 0.9568, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.145, Val accuracy: 0.9572, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1422, Val accuracy: 0.9572, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1447, Val accuracy: 0.9572, Best Epoch: 6\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1442, Val accuracy: 0.9568, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9576490924805532\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1734, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1556, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.154, Val accuracy: 0.9633, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1537, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1518, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1505, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1485, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1461, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1465, Val accuracy: 0.9633, Best Epoch: 2\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 2 (Update 252). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1705, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1571, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1569, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1533, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1523, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1526, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1513, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1498, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1472, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.147, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1464, Val accuracy: 0.968, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1731, Val accuracy: 0.9667, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1554, Val accuracy: 0.9672, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1535, Val accuracy: 0.9676, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.152, Val accuracy: 0.9672, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1528, Val accuracy: 0.9672, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1497, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1541, Val accuracy: 0.9672, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.15, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1489, Val accuracy: 0.9676, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1476, Val accuracy: 0.9672, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1464, Val accuracy: 0.9663, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1449, Val accuracy: 0.9676, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1451, Val accuracy: 0.9667, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9675885911840968\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1715, Val accuracy: 0.9594, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1535, Val accuracy: 0.9602, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.152, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1508, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1482, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1494, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1462, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1463, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1456, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1466, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1431, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1436, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1435, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1427, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.143, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.141, Val accuracy: 0.9594, Best Epoch: 7\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1413, Val accuracy: 0.9598, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9606571552096844\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_BAG_L1 model HPO: 70.06754302978516\n",
            "Best hyperparameter configuration for NeuralNetTorch_BAG_L1 model: \n",
            "{'num_epochs': 300, 'epochs_wo_improve': None, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.01, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t70.0s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "\t4014.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_2_BAG_L1 ... Tuning model for up to 77.12s of the 3334.99s of remaining time.\n",
            "\tFitting NeuralNetTorch_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_2_BAG_L1 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_2_BAG_L1: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38dc98c7b6184e1d98a69393533b39fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1637, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1516, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1507, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1513, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1481, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1504, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1473, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1495, Val accuracy: 0.965, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1625, Val accuracy: 0.9594, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.149, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1479, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1453, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1462, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1452, Val accuracy: 0.9585, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9593777009507347\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1629, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1511, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1501, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1489, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.149, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1496, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1491, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1476, Val accuracy: 0.9654, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1664, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1528, Val accuracy: 0.968, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.152, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1517, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1501, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1494, Val accuracy: 0.968, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1499, Val accuracy: 0.968, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1493, Val accuracy: 0.968, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9680207433016422\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.163, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1482, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1477, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1486, Val accuracy: 0.9572, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1466, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1464, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.145, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1457, Val accuracy: 0.9576, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.958513396715644\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1607, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1522, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1511, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1503, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1478, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1484, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1506, Val accuracy: 0.965, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.166, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1536, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1531, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1551, Val accuracy: 0.9693, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1511, Val accuracy: 0.9689, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1503, Val accuracy: 0.9693, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.151, Val accuracy: 0.9706, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1492, Val accuracy: 0.9702, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1483, Val accuracy: 0.9706, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9706136560069144\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1649, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1503, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1507, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1494, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1495, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1491, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1479, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1478, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.148, Val accuracy: 0.9637, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9641158668396023\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1652, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1507, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1492, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1508, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1487, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1489, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1489, Val accuracy: 0.9641, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9645635263612792\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1659, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1532, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1536, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1522, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1501, Val accuracy: 0.9685, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1509, Val accuracy: 0.9685, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1503, Val accuracy: 0.9685, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1482, Val accuracy: 0.9676, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1497, Val accuracy: 0.9685, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.15, Val accuracy: 0.9676, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1614, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1525, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1509, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1497, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1478, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1474, Val accuracy: 0.9641, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1499, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1472, Val accuracy: 0.9641, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1484, Val accuracy: 0.9641, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1608, Val accuracy: 0.9568, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1482, Val accuracy: 0.9572, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1468, Val accuracy: 0.9572, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1484, Val accuracy: 0.9572, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1457, Val accuracy: 0.9559, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1486, Val accuracy: 0.9568, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1451, Val accuracy: 0.9572, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1454, Val accuracy: 0.9576, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9576490924805532\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1628, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1504, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.149, Val accuracy: 0.9607, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1522, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1495, Val accuracy: 0.9637, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1469, Val accuracy: 0.9637, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1473, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1448, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1476, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1446, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1469, Val accuracy: 0.962, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1652, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1516, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.153, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1502, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1513, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1501, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1498, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1486, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1494, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1496, Val accuracy: 0.9672, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1497, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1479, Val accuracy: 0.9676, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1637, Val accuracy: 0.9672, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1511, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1517, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1504, Val accuracy: 0.9672, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1507, Val accuracy: 0.9672, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.148, Val accuracy: 0.9672, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1507, Val accuracy: 0.9667, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1501, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1487, Val accuracy: 0.9663, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1472, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.15, Val accuracy: 0.9663, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9671564390665515\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=36, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1606, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1501, Val accuracy: 0.9611, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1469, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1478, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1466, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1474, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1462, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1452, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1467, Val accuracy: 0.9607, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1468, Val accuracy: 0.9611, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1435, Val accuracy: 0.9611, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1467, Val accuracy: 0.9598, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1431, Val accuracy: 0.9598, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1445, Val accuracy: 0.9611, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.145, Val accuracy: 0.9611, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1421, Val accuracy: 0.9576, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1449, Val accuracy: 0.9602, Best Epoch: 15\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1452, Val accuracy: 0.9607, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9610894941634242\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_2_BAG_L1 model HPO: 70.29582905769348\n",
            "Best hyperparameter configuration for NeuralNetTorch_2_BAG_L1 model: \n",
            "{'num_epochs': 500, 'epochs_wo_improve': None, 'activation': 'tanh', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3, 'optimizer': 'adam', 'learning_rate': 0.005, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L1/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t70.24s\t = Training   runtime\n",
            "\t0.65s\t = Validation runtime\n",
            "\t3535.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3264.63s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "\t0.03s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'NeuralNetTorch_2_BAG_L1/T1': 1.0}\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t0.54s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t3533.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tRandomForest_BAG_L2: \t{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_2_BAG_L2: \t{'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L2: \t{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tCatBoost_2_BAG_L2: \t{'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_BAG_L2: \t{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_2_BAG_L2: \t{'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_BAG_L2: \t{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_2_BAG_L2: \t{'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_3_BAG_L2: \t{'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_2_BAG_L2: \t{'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Hyperparameter tuning model: RandomForest_BAG_L2 ... Tuning model for up to 118.66s of the 3264.01s of remaining time.\n",
            "\tFitting RandomForest_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_BAG_L2 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/model_template.pkl\n",
            "\t4.06s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/model.pkl\n",
            "Fitted model: RandomForest_BAG_L2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t20.48s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "\t509.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_2_BAG_L2 ... Tuning model for up to 118.66s of the 3243.45s of remaining time.\n",
            "\tFitting RandomForest_2_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_2_BAG_L2 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_2_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/model_template.pkl\n",
            "\t6.34s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/model.pkl\n",
            "Fitted model: RandomForest_2_BAG_L2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t28.32s\t = Training   runtime\n",
            "\t1.35s\t = Validation runtime\n",
            "\t501.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 118.66s of the 3215.05s of remaining time.\n",
            "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_BAG_L2 model...\n",
            "\tHyperparameter search space for CatBoost_BAG_L2: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e417577cb2a4348b9abf18abef2d0a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_BAG_L2 model HPO: 3.1417288780212402\n",
            "Best hyperparameter configuration for CatBoost_BAG_L2 model: \n",
            "{'iterations': 1000, 'learning_rate': 0.03, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L2... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_2_BAG_L2 ... Tuning model for up to 118.66s of the 3211.85s of remaining time.\n",
            "\tFitting CatBoost_2_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_2_BAG_L2 model...\n",
            "\tHyperparameter search space for CatBoost_2_BAG_L2: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca0cf9f606ad40c4a7114579124ac69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L2/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_2_BAG_L2 model HPO: 3.323545455932617\n",
            "Best hyperparameter configuration for CatBoost_2_BAG_L2 model: \n",
            "{'iterations': 1500, 'learning_rate': 0.02, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_2_BAG_L2... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_BAG_L2 ... Tuning model for up to 118.66s of the 3208.48s of remaining time.\n",
            "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_BAG_L2 model...\n",
            "\tNo hyperparameter search space specified for XGBoost_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
            "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03457\n",
            "[50]\tvalidation_0-error:0.03403\n",
            "[100]\tvalidation_0-error:0.03403\n",
            "[150]\tvalidation_0-error:0.03403\n",
            "[200]\tvalidation_0-error:0.03403\n",
            "[204]\tvalidation_0-error:0.03403\n",
            "[0]\tvalidation_0-error:0.03863\n",
            "[50]\tvalidation_0-error:0.03836\n",
            "[100]\tvalidation_0-error:0.03836\n",
            "[150]\tvalidation_0-error:0.03836\n",
            "[200]\tvalidation_0-error:0.03836\n",
            "[207]\tvalidation_0-error:0.03836\n",
            "[0]\tvalidation_0-error:0.03998\n",
            "[50]\tvalidation_0-error:0.03782\n",
            "[100]\tvalidation_0-error:0.03782\n",
            "[150]\tvalidation_0-error:0.03782\n",
            "[200]\tvalidation_0-error:0.03782\n",
            "[204]\tvalidation_0-error:0.03782\n",
            "[0]\tvalidation_0-error:0.03620\n",
            "[50]\tvalidation_0-error:0.03647\n",
            "[100]\tvalidation_0-error:0.03620\n",
            "[150]\tvalidation_0-error:0.03620\n",
            "[200]\tvalidation_0-error:0.03620\n",
            "[206]\tvalidation_0-error:0.03620\n",
            "[0]\tvalidation_0-error:0.03431\n",
            "[50]\tvalidation_0-error:0.03296\n",
            "[100]\tvalidation_0-error:0.03323\n",
            "[150]\tvalidation_0-error:0.03323\n",
            "[200]\tvalidation_0-error:0.03323\n",
            "[207]\tvalidation_0-error:0.03296\n",
            "[0]\tvalidation_0-error:0.03511\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[200]\tvalidation_0-error:0.03457\n",
            "[203]\tvalidation_0-error:0.03430\n",
            "[0]\tvalidation_0-error:0.03404\n",
            "[50]\tvalidation_0-error:0.03377\n",
            "[100]\tvalidation_0-error:0.03377\n",
            "[150]\tvalidation_0-error:0.03377\n",
            "[200]\tvalidation_0-error:0.03377\n",
            "[205]\tvalidation_0-error:0.03377\n",
            "[0]\tvalidation_0-error:0.04268\n",
            "[50]\tvalidation_0-error:0.04079\n",
            "[100]\tvalidation_0-error:0.04079\n",
            "[150]\tvalidation_0-error:0.04106\n",
            "[200]\tvalidation_0-error:0.04133\n",
            "[245]\tvalidation_0-error:0.04106\n",
            "[0]\tvalidation_0-error:0.03296\n",
            "[50]\tvalidation_0-error:0.03269\n",
            "[100]\tvalidation_0-error:0.03241\n",
            "[150]\tvalidation_0-error:0.03241\n",
            "[200]\tvalidation_0-error:0.03241\n",
            "[232]\tvalidation_0-error:0.03241\n",
            "[0]\tvalidation_0-error:0.03971\n",
            "[50]\tvalidation_0-error:0.03755\n",
            "[100]\tvalidation_0-error:0.03728\n",
            "[150]\tvalidation_0-error:0.03701\n",
            "[200]\tvalidation_0-error:0.03701\n",
            "[250]\tvalidation_0-error:0.03728\n",
            "[277]\tvalidation_0-error:0.03728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/model.pkl\n",
            "Fitted model: XGBoost_BAG_L2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t50.88s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "\t505.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_2_BAG_L2 ... Tuning model for up to 118.66s of the 3157.52s of remaining time.\n",
            "\tFitting XGBoost_2_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_2_BAG_L2 model...\n",
            "\tHyperparameter search space for XGBoost_2_BAG_L2: \n",
            "min_child_weight:   Int: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05febd38b2f24a56bff8aa721bbfd670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.04019\n",
            "[50]\tvalidation_0-error:0.03889\n",
            "[100]\tvalidation_0-error:0.03846\n",
            "[150]\tvalidation_0-error:0.03846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 173. Best iteration is: \t[1]\t0.03802938634399308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[173]\tvalidation_0-error:0.03846\n",
            "[0]\tvalidation_0-error:0.03025\n",
            "[50]\tvalidation_0-error:0.02895\n",
            "[100]\tvalidation_0-error:0.02852\n",
            "[150]\tvalidation_0-error:0.02852\n",
            "[200]\tvalidation_0-error:0.02852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 225. Best iteration is: \t[90]\t0.02852203975799482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[224]\tvalidation_0-error:0.02852\n",
            "[0]\tvalidation_0-error:0.04365\n",
            "[50]\tvalidation_0-error:0.04192\n",
            "[100]\tvalidation_0-error:0.04149\n",
            "[150]\tvalidation_0-error:0.04192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 185. Best iteration is: \t[56]\t0.04148660328435609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[185]\tvalidation_0-error:0.04149\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.04062\n",
            "[100]\tvalidation_0-error:0.04019\n",
            "[150]\tvalidation_0-error:0.03976\n",
            "[200]\tvalidation_0-error:0.04019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 239. Best iteration is: \t[87]\t0.03975799481417459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[239]\tvalidation_0-error:0.03976\n",
            "[0]\tvalidation_0-error:0.03328\n",
            "[50]\tvalidation_0-error:0.03198\n",
            "[100]\tvalidation_0-error:0.03198\n",
            "[150]\tvalidation_0-error:0.03198\n",
            "[188]\tvalidation_0-error:0.03198\n",
            "[0]\tvalidation_0-error:0.03630\n",
            "[50]\tvalidation_0-error:0.03717\n",
            "[100]\tvalidation_0-error:0.03673\n",
            "[150]\tvalidation_0-error:0.03673\n",
            "[197]\tvalidation_0-error:0.03673\n",
            "[0]\tvalidation_0-error:0.03717\n",
            "[50]\tvalidation_0-error:0.03544\n",
            "[100]\tvalidation_0-error:0.03544\n",
            "[150]\tvalidation_0-error:0.03544\n",
            "[189]\tvalidation_0-error:0.03544\n",
            "[0]\tvalidation_0-error:0.03415\n",
            "[50]\tvalidation_0-error:0.03372\n",
            "[100]\tvalidation_0-error:0.03372\n",
            "[150]\tvalidation_0-error:0.03372\n",
            "[200]\tvalidation_0-error:0.03372\n",
            "[215]\tvalidation_0-error:0.03372\n",
            "[0]\tvalidation_0-error:0.03414\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[185]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.03284\n",
            "[50]\tvalidation_0-error:0.03241\n",
            "[100]\tvalidation_0-error:0.03241\n",
            "[150]\tvalidation_0-error:0.03241\n",
            "[186]\tvalidation_0-error:0.03241\n",
            "[0]\tvalidation_0-error:0.03760\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[189]\tvalidation_0-error:0.03630\n",
            "[0]\tvalidation_0-error:0.04235\n",
            "[50]\tvalidation_0-error:0.04192\n",
            "[100]\tvalidation_0-error:0.04192\n",
            "[150]\tvalidation_0-error:0.04149\n",
            "[186]\tvalidation_0-error:0.04149\n",
            "[0]\tvalidation_0-error:0.03803\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03587\n",
            "[200]\tvalidation_0-error:0.03587\n",
            "[250]\tvalidation_0-error:0.03587\n",
            "[288]\tvalidation_0-error:0.03587\n",
            "[0]\tvalidation_0-error:0.03630\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03587\n",
            "[150]\tvalidation_0-error:0.03587\n",
            "[186]\tvalidation_0-error:0.03587\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03803\n",
            "[100]\tvalidation_0-error:0.03760\n",
            "[150]\tvalidation_0-error:0.03760\n",
            "[186]\tvalidation_0-error:0.03760\n",
            "[0]\tvalidation_0-error:0.03718\n",
            "[50]\tvalidation_0-error:0.03372\n",
            "[100]\tvalidation_0-error:0.03415\n",
            "[150]\tvalidation_0-error:0.03415\n",
            "[196]\tvalidation_0-error:0.03415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for XGBoost_2_BAG_L2 model HPO: 91.05611658096313\n",
            "Best hyperparameter configuration for XGBoost_2_BAG_L2 model: \n",
            "{'n_estimators': 800, 'learning_rate': 0.03, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'max_depth': 10, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 1}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L2/T1 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t90.99s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "\t482.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_BAG_L2 ... Tuning model for up to 118.66s of the 3066.42s of remaining time.\n",
            "\tFitting LinearModel_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_BAG_L2 model...\n",
            "\tHyperparameter search space for LinearModel_BAG_L2: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6c6fcc09805454e94d8d8661d228dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_BAG_L2 model HPO: 29.20456027984619\n",
            "Best hyperparameter configuration for LinearModel_BAG_L2 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/model.pkl\n",
            "Fitted model: LinearModel_BAG_L2/T1 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t9.09s\t = Training   runtime\n",
            "\t0.93s\t = Validation runtime\n",
            "\t430.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/model.pkl\n",
            "Fitted model: LinearModel_BAG_L2/T2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t8.83s\t = Training   runtime\n",
            "\t0.93s\t = Validation runtime\n",
            "\t430.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/model.pkl\n",
            "Fitted model: LinearModel_BAG_L2/T3 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t5.35s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t485.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/model.pkl\n",
            "Fitted model: LinearModel_BAG_L2/T4 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t5.79s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "\t479.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_2_BAG_L2 ... Tuning model for up to 118.66s of the 3037.15s of remaining time.\n",
            "\tFitting LinearModel_2_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_2_BAG_L2 model...\n",
            "\tHyperparameter search space for LinearModel_2_BAG_L2: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "934d5975eb394fae9e4335ddedf40f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_2_BAG_L2 model HPO: 49.95323610305786\n",
            "Best hyperparameter configuration for LinearModel_2_BAG_L2 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L2/T1 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t18.1s\t = Training   runtime\n",
            "\t0.96s\t = Validation runtime\n",
            "\t428.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L2/T2 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t14.32s\t = Training   runtime\n",
            "\t0.91s\t = Validation runtime\n",
            "\t432.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L2/T3 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t8.98s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "\t481.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L2/T4 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t8.4s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t485.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_3_BAG_L2 ... Tuning model for up to 118.66s of the 2987.1s of remaining time.\n",
            "\tFitting LinearModel_3_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_3_BAG_L2 model...\n",
            "\tHyperparameter search space for LinearModel_3_BAG_L2: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe46668f8f7c4d50857363ce18654093"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_3_BAG_L2 model HPO: 63.619946002960205\n",
            "Best hyperparameter configuration for LinearModel_3_BAG_L2 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L2/T1 ...\n",
            "\t0.9638\t = Validation score   (accuracy)\n",
            "\t19.08s\t = Training   runtime\n",
            "\t0.89s\t = Validation runtime\n",
            "\t433.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L2/T2 ...\n",
            "\t0.9638\t = Validation score   (accuracy)\n",
            "\t18.35s\t = Training   runtime\n",
            "\t0.87s\t = Validation runtime\n",
            "\t435.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L2/T3 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t13.06s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t484.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L2/T4 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t13.0s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "\t482.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 118.66s of the 2923.42s of remaining time.\n",
            "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_BAG_L2 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_BAG_L2: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9706b21aea72425c91d8ff50c7d4f581"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1662, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1532, Val accuracy: 0.9607, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1509, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.151, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1463, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1485, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.147, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1457, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1438, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1433, Val accuracy: 0.9611, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9615384615384616\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1764, Val accuracy: 0.9715, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1602, Val accuracy: 0.9715, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1564, Val accuracy: 0.9715, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1552, Val accuracy: 0.9719, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1513, Val accuracy: 0.9719, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1515, Val accuracy: 0.9715, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1531, Val accuracy: 0.9719, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1492, Val accuracy: 0.9715, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1507, Val accuracy: 0.9715, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1467, Val accuracy: 0.9715, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1475, Val accuracy: 0.9715, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1442, Val accuracy: 0.971, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9719101123595506\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1715, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1534, Val accuracy: 0.9564, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1507, Val accuracy: 0.9581, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1496, Val accuracy: 0.9551, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1453, Val accuracy: 0.9576, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1447, Val accuracy: 0.9568, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.143, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1401, Val accuracy: 0.9581, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1436, Val accuracy: 0.9576, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.142, Val accuracy: 0.9581, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1401, Val accuracy: 0.9581, Best Epoch: 11\n",
            "\tRan out of time, stopping training early. (Stopped on Update 1503 (Epoch 11))\n",
            "Best model found on Epoch 11 (Update 1386). Val accuracy: 0.9580812445980985\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(32, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1685, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1532, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1528, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1516, Val accuracy: 0.9598, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1478, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1474, Val accuracy: 0.9598, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1443, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1444, Val accuracy: 0.9607, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.141, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1457, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1435, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1405, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.14, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1373, Val accuracy: 0.9602, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9606741573033708\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1715, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1559, Val accuracy: 0.9685, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1568, Val accuracy: 0.9689, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1561, Val accuracy: 0.9689, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1511, Val accuracy: 0.9685, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1502, Val accuracy: 0.9689, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1477, Val accuracy: 0.9685, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1495, Val accuracy: 0.9689, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1461, Val accuracy: 0.9689, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1508, Val accuracy: 0.9689, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1451, Val accuracy: 0.9676, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1453, Val accuracy: 0.9689, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1446, Val accuracy: 0.9672, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9688850475367329\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1681, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1524, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1533, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1493, Val accuracy: 0.9637, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1517, Val accuracy: 0.9637, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1484, Val accuracy: 0.9637, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.146, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1451, Val accuracy: 0.9641, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1428, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1439, Val accuracy: 0.9641, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1413, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1404, Val accuracy: 0.9637, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(52, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1714, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.155, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1537, Val accuracy: 0.9646, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1511, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1501, Val accuracy: 0.9646, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1493, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1473, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1469, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1472, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1434, Val accuracy: 0.9646, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1484, Val accuracy: 0.965, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.144, Val accuracy: 0.9654, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.9646, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopped on Update 1760 (Epoch 13))\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1718, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1585, Val accuracy: 0.9663, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1548, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1524, Val accuracy: 0.9667, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1548, Val accuracy: 0.9667, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1481, Val accuracy: 0.9667, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1483, Val accuracy: 0.9667, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.148, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1476, Val accuracy: 0.9667, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1474, Val accuracy: 0.9667, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1464, Val accuracy: 0.9667, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1445, Val accuracy: 0.9667, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1431, Val accuracy: 0.9667, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9667099005620406\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1727, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1569, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1501, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1507, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1475, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1478, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1479, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1463, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1469, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1415, Val accuracy: 0.9654, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1415, Val accuracy: 0.9646, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1466, Val accuracy: 0.9663, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1421, Val accuracy: 0.9646, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1389, Val accuracy: 0.9641, Best Epoch: 12\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1419, Val accuracy: 0.9654, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.173, Val accuracy: 0.9676, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1563, Val accuracy: 0.968, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1563, Val accuracy: 0.9685, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1534, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1556, Val accuracy: 0.9676, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1508, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1487, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1473, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1486, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1474, Val accuracy: 0.9676, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1476, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1433, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1432, Val accuracy: 0.968, Best Epoch: 3\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.143, Val accuracy: 0.968, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1686, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1556, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1506, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1524, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1502, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1494, Val accuracy: 0.9637, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1465, Val accuracy: 0.9633, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1469, Val accuracy: 0.9637, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.146, Val accuracy: 0.9641, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1424, Val accuracy: 0.9641, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1448, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1443, Val accuracy: 0.9633, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1414, Val accuracy: 0.9641, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1408, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1403, Val accuracy: 0.9641, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1729, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.154, Val accuracy: 0.9607, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1511, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.15, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1514, Val accuracy: 0.9607, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1472, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1487, Val accuracy: 0.9602, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1457, Val accuracy: 0.9615, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1434, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.144, Val accuracy: 0.9615, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1445, Val accuracy: 0.9615, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1406, Val accuracy: 0.9615, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1386, Val accuracy: 0.9602, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1396, Val accuracy: 0.9615, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1397, Val accuracy: 0.9615, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9615384615384616\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1756, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1549, Val accuracy: 0.9633, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1515, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1498, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1488, Val accuracy: 0.9628, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1475, Val accuracy: 0.9633, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1479, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1448, Val accuracy: 0.9628, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1433, Val accuracy: 0.9637, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.143, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.142, Val accuracy: 0.9637, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1398, Val accuracy: 0.9637, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1417, Val accuracy: 0.9628, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.138, Val accuracy: 0.9637, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1397, Val accuracy: 0.9624, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 14 (Update 1764). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1697, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1565, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1507, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1486, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1492, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1487, Val accuracy: 0.9641, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1483, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1473, Val accuracy: 0.9641, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1445, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1437, Val accuracy: 0.9641, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1453, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1447, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1417, Val accuracy: 0.9641, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1403, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1385, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1404, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1401, Val accuracy: 0.9646, Best Epoch: 17\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1378, Val accuracy: 0.9646, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.136, Val accuracy: 0.9646, Best Epoch: 19\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "Best model found on Epoch 19 (Update 2394). Val accuracy: 0.9645635263612792\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1753, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1549, Val accuracy: 0.9628, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1533, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1529, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1501, Val accuracy: 0.9628, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1496, Val accuracy: 0.9628, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1456, Val accuracy: 0.9628, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1448, Val accuracy: 0.9624, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1427, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1443, Val accuracy: 0.9628, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1432, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1415, Val accuracy: 0.9611, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1408, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1402, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1392, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1397, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1367, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1354, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1353, Val accuracy: 0.9611, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9628349178910977\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1746, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1553, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1531, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1525, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1516, Val accuracy: 0.9667, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1472, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1476, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1465, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1445, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1425, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1449, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1405, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1431, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1412, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.142, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1395, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.139, Val accuracy: 0.9645, Best Epoch: 5\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1386, Val accuracy: 0.9645, Best Epoch: 5\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1369, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1371, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1363, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.1396, Val accuracy: 0.9645, Best Epoch: 5\n",
            "Epoch 23 (Update 2898).\tTrain loss: 0.1392, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 24 (Update 3024).\tTrain loss: 0.135, Val accuracy: 0.9658, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 24)\n",
            "Best model found on Epoch 5 (Update 630). Val accuracy: 0.9667099005620406\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_BAG_L2 model HPO: 110.64757037162781\n",
            "Best hyperparameter configuration for NeuralNetTorch_BAG_L2 model: \n",
            "{'num_epochs': 300, 'epochs_wo_improve': None, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.01, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L2/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t110.57s\t = Training   runtime\n",
            "\t1.21s\t = Validation runtime\n",
            "\t409.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_2_BAG_L2 ... Tuning model for up to 118.66s of the 2812.71s of remaining time.\n",
            "\tFitting NeuralNetTorch_2_BAG_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_2_BAG_L2 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_2_BAG_L2: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "747224649c7b45ab9222ecc2ff976163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1598, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.148, Val accuracy: 0.9598, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1458, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1482, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1447, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1459, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1456, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1431, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1461, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1453, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1424, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1443, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1425, Val accuracy: 0.9607, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9615384615384616\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1631, Val accuracy: 0.9715, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1515, Val accuracy: 0.9715, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.153, Val accuracy: 0.9715, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1528, Val accuracy: 0.9715, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1504, Val accuracy: 0.9715, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.151, Val accuracy: 0.9715, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1518, Val accuracy: 0.9715, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1482, Val accuracy: 0.9715, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1505, Val accuracy: 0.9719, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1483, Val accuracy: 0.9715, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9719101123595506\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1606, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1458, Val accuracy: 0.9572, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1462, Val accuracy: 0.9576, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1469, Val accuracy: 0.9572, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1442, Val accuracy: 0.9568, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1435, Val accuracy: 0.9581, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1426, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1448, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1419, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.145, Val accuracy: 0.9572, Best Epoch: 6\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1414, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1401, Val accuracy: 0.9564, Best Epoch: 6\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1399, Val accuracy: 0.9568, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9580812445980985\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(32, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1588, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1488, Val accuracy: 0.9602, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.148, Val accuracy: 0.9607, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1456, Val accuracy: 0.9564, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1463, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1467, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1456, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1456, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1437, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1455, Val accuracy: 0.9585, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1418, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1438, Val accuracy: 0.9598, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.141, Val accuracy: 0.9602, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9606741573033708\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1611, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1508, Val accuracy: 0.9685, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1538, Val accuracy: 0.9685, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.153, Val accuracy: 0.9685, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.149, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1498, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.149, Val accuracy: 0.9676, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1494, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1459, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1485, Val accuracy: 0.968, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1459, Val accuracy: 0.9685, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1464, Val accuracy: 0.9685, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1465, Val accuracy: 0.9672, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1582, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1479, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.147, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1463, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1511, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1465, Val accuracy: 0.9637, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1472, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1488, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1448, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1447, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1437, Val accuracy: 0.9628, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1431, Val accuracy: 0.9628, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1421, Val accuracy: 0.9624, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(52, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.159, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1511, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1515, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1486, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1494, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1485, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1491, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1473, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.148, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1444, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.15, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1457, Val accuracy: 0.9646, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1595, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1525, Val accuracy: 0.9663, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1489, Val accuracy: 0.9671, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1503, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1507, Val accuracy: 0.9663, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1475, Val accuracy: 0.9663, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1477, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.147, Val accuracy: 0.9663, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1493, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1467, Val accuracy: 0.9663, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1456, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1457, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1461, Val accuracy: 0.9671, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.143, Val accuracy: 0.9654, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1429, Val accuracy: 0.9654, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9671422395157804\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.164, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1498, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1491, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1488, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1462, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1462, Val accuracy: 0.9646, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1496, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1475, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.146, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1466, Val accuracy: 0.9654, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1447, Val accuracy: 0.965, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1453, Val accuracy: 0.965, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1639, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1512, Val accuracy: 0.9685, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1506, Val accuracy: 0.968, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1506, Val accuracy: 0.968, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.151, Val accuracy: 0.9685, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1513, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1498, Val accuracy: 0.9676, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1485, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1488, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1477, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1466, Val accuracy: 0.9672, Best Epoch: 5\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1467, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1471, Val accuracy: 0.968, Best Epoch: 5\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1458, Val accuracy: 0.9676, Best Epoch: 5\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.146, Val accuracy: 0.9685, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1446, Val accuracy: 0.9676, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2139 (Epoch 16))\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9684528954191876\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1592, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1483, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1487, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1474, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1477, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1482, Val accuracy: 0.9637, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.147, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1464, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1467, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1432, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1436, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1443, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1444, Val accuracy: 0.9637, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1583, Val accuracy: 0.9598, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1494, Val accuracy: 0.9607, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1476, Val accuracy: 0.9594, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1474, Val accuracy: 0.9607, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1451, Val accuracy: 0.9602, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1461, Val accuracy: 0.9589, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1463, Val accuracy: 0.9589, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9606741573033708\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1619, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1495, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1466, Val accuracy: 0.9637, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1594, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.15, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1477, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1473, Val accuracy: 0.9641, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1486, Val accuracy: 0.9641, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1453, Val accuracy: 0.9641, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1465, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1459, Val accuracy: 0.9646, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1458, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1452, Val accuracy: 0.9646, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "Best model found on Epoch 10 (Update 1260). Val accuracy: 0.9645635263612792\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.159, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1486, Val accuracy: 0.9628, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1479, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1482, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1468, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1499, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1452, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1468, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1436, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1465, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1433, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1428, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.142, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1432, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1416, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1425, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1386, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1401, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1393, Val accuracy: 0.9607, Best Epoch: 9\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1392, Val accuracy: 0.9611, Best Epoch: 9\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1367, Val accuracy: 0.9624, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9628349178910977\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L1\",\n",
            "        \"XGBoost_2_BAG_L1/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"KNeighbors_BAG_L1\",\n",
            "        \"KNeighbors_2_BAG_L1\",\n",
            "        \"KNeighbors_3_BAG_L1\",\n",
            "        \"RandomForest_BAG_L1\",\n",
            "        \"RandomForest_2_BAG_L1\",\n",
            "        \"LinearModel_2_BAG_L1/T1\",\n",
            "        \"LinearModel_2_BAG_L1/T2\",\n",
            "        \"LinearModel_2_BAG_L1/T3\",\n",
            "        \"LinearModel_2_BAG_L1/T4\",\n",
            "        \"LinearModel_3_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_BAG_L1/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L1/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 27 features (25 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1638, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1513, Val accuracy: 0.9658, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.15, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1506, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.15, Val accuracy: 0.9663, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1477, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1501, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1473, Val accuracy: 0.9663, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1487, Val accuracy: 0.9658, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1456, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1456, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1455, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1459, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1454, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1454, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1436, Val accuracy: 0.9615, Best Epoch: 8\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1433, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1419, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1439, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1411, Val accuracy: 0.9667, Best Epoch: 20\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1422, Val accuracy: 0.9654, Best Epoch: 20\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.1409, Val accuracy: 0.9658, Best Epoch: 20\n",
            "Epoch 23 (Update 2898).\tTrain loss: 0.1402, Val accuracy: 0.9658, Best Epoch: 20\n",
            "Epoch 24 (Update 3024).\tTrain loss: 0.1407, Val accuracy: 0.9654, Best Epoch: 20\n",
            "Epoch 25 (Update 3150).\tTrain loss: 0.139, Val accuracy: 0.9654, Best Epoch: 20\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 25)\n",
            "Best model found on Epoch 20 (Update 2520). Val accuracy: 0.9667099005620406\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_2_BAG_L2 model HPO: 110.80711340904236\n",
            "Best hyperparameter configuration for NeuralNetTorch_2_BAG_L2 model: \n",
            "{'num_epochs': 500, 'epochs_wo_improve': None, 'activation': 'tanh', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3, 'optimizer': 'adam', 'learning_rate': 0.005, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L2/T1 ...\n",
            "\t0.9644\t = Validation score   (accuracy)\n",
            "\t110.74s\t = Training   runtime\n",
            "\t1.67s\t = Validation runtime\n",
            "\t378.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2701.84s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 4\n",
            "Ensemble weights: \n",
            "[0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.75 0.  ]\n",
            "\t0.05s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'NeuralNetTorch_BAG_L2/T1': 0.75, 'XGBoost_BAG_L2': 0.25}\n",
            "\t0.9647\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t399.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tRandomForest_BAG_L3: \t{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_2_BAG_L3: \t{'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L3: \t{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tCatBoost_2_BAG_L3: \t{'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_BAG_L3: \t{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_2_BAG_L3: \t{'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_BAG_L3: \t{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_2_BAG_L3: \t{'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_3_BAG_L3: \t{'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_BAG_L3: \t{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_2_BAG_L3: \t{'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "Fitting 11 L3 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/oof.pkl\n",
            "Hyperparameter tuning model: RandomForest_BAG_L3 ... Tuning model for up to 147.31s of the 2701.35s of remaining time.\n",
            "\tFitting RandomForest_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_BAG_L3 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/model_template.pkl\n",
            "\t4.44s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/model.pkl\n",
            "Fitted model: RandomForest_BAG_L3 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t18.32s\t = Training   runtime\n",
            "\t1.07s\t = Validation runtime\n",
            "\t233.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_2_BAG_L3 ... Tuning model for up to 147.31s of the 2682.94s of remaining time.\n",
            "\tFitting RandomForest_2_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_2_BAG_L3 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_2_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/model_template.pkl\n",
            "\t7.86s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/model.pkl\n",
            "Fitted model: RandomForest_2_BAG_L3 ...\n",
            "\t0.9644\t = Validation score   (accuracy)\n",
            "\t29.49s\t = Training   runtime\n",
            "\t1.4s\t = Validation runtime\n",
            "\t232.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_BAG_L3 ... Tuning model for up to 147.31s of the 2653.37s of remaining time.\n",
            "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_BAG_L3 model...\n",
            "\tHyperparameter search space for CatBoost_BAG_L3: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbd862de201946c5aa633c6364c4a34f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L3/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_BAG_L3 model HPO: 3.0105178356170654\n",
            "Best hyperparameter configuration for CatBoost_BAG_L3 model: \n",
            "{'iterations': 1000, 'learning_rate': 0.03, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L3... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_2_BAG_L3 ... Tuning model for up to 147.31s of the 2650.32s of remaining time.\n",
            "\tFitting CatBoost_2_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_2_BAG_L3 model...\n",
            "\tHyperparameter search space for CatBoost_2_BAG_L3: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c321d73b51044418b98d91a4941e829"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L3/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_2_BAG_L3 model HPO: 2.9394307136535645\n",
            "Best hyperparameter configuration for CatBoost_2_BAG_L3 model: \n",
            "{'iterations': 1500, 'learning_rate': 0.02, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_2_BAG_L3... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_BAG_L3 ... Tuning model for up to 147.31s of the 2647.33s of remaining time.\n",
            "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_BAG_L3 model...\n",
            "\tNo hyperparameter search space specified for XGBoost_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
            "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.04267\n",
            "[50]\tvalidation_0-error:0.03592\n",
            "[100]\tvalidation_0-error:0.03592\n",
            "[150]\tvalidation_0-error:0.03565\n",
            "[200]\tvalidation_0-error:0.03592\n",
            "[226]\tvalidation_0-error:0.03592\n",
            "[0]\tvalidation_0-error:0.03323\n",
            "[50]\tvalidation_0-error:0.03241\n",
            "[100]\tvalidation_0-error:0.03241\n",
            "[150]\tvalidation_0-error:0.03241\n",
            "[200]\tvalidation_0-error:0.03241\n",
            "[205]\tvalidation_0-error:0.03241\n",
            "[0]\tvalidation_0-error:0.03728\n",
            "[50]\tvalidation_0-error:0.03350\n",
            "[100]\tvalidation_0-error:0.03377\n",
            "[150]\tvalidation_0-error:0.03377\n",
            "[200]\tvalidation_0-error:0.03404\n",
            "[250]\tvalidation_0-error:0.03404\n",
            "[258]\tvalidation_0-error:0.03404\n",
            "[0]\tvalidation_0-error:0.03917\n",
            "[50]\tvalidation_0-error:0.03674\n",
            "[100]\tvalidation_0-error:0.03647\n",
            "[150]\tvalidation_0-error:0.03647\n",
            "[200]\tvalidation_0-error:0.03647\n",
            "[203]\tvalidation_0-error:0.03647\n",
            "[0]\tvalidation_0-error:0.04079\n",
            "[50]\tvalidation_0-error:0.04025\n",
            "[100]\tvalidation_0-error:0.03998\n",
            "[150]\tvalidation_0-error:0.03998\n",
            "[200]\tvalidation_0-error:0.04025\n",
            "[203]\tvalidation_0-error:0.04025\n",
            "[0]\tvalidation_0-error:0.03592\n",
            "[50]\tvalidation_0-error:0.03538\n",
            "[100]\tvalidation_0-error:0.03565\n",
            "[150]\tvalidation_0-error:0.03565\n",
            "[200]\tvalidation_0-error:0.03565\n",
            "[206]\tvalidation_0-error:0.03565\n",
            "[0]\tvalidation_0-error:0.03836\n",
            "[50]\tvalidation_0-error:0.03809\n",
            "[100]\tvalidation_0-error:0.03836\n",
            "[150]\tvalidation_0-error:0.03836\n",
            "[200]\tvalidation_0-error:0.03836\n",
            "[204]\tvalidation_0-error:0.03836\n",
            "[0]\tvalidation_0-error:0.03944\n",
            "[50]\tvalidation_0-error:0.03593\n",
            "[100]\tvalidation_0-error:0.03593\n",
            "[150]\tvalidation_0-error:0.03593\n",
            "[200]\tvalidation_0-error:0.03593\n",
            "[206]\tvalidation_0-error:0.03593\n",
            "[0]\tvalidation_0-error:0.03593\n",
            "[50]\tvalidation_0-error:0.03647\n",
            "[100]\tvalidation_0-error:0.03647\n",
            "[150]\tvalidation_0-error:0.03647\n",
            "[200]\tvalidation_0-error:0.03593\n",
            "[250]\tvalidation_0-error:0.03593\n",
            "[264]\tvalidation_0-error:0.03593\n",
            "[0]\tvalidation_0-error:0.03674\n",
            "[50]\tvalidation_0-error:0.03377\n",
            "[100]\tvalidation_0-error:0.03377\n",
            "[150]\tvalidation_0-error:0.03404\n",
            "[200]\tvalidation_0-error:0.03404\n",
            "[210]\tvalidation_0-error:0.03404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/model.pkl\n",
            "Fitted model: XGBoost_BAG_L3 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t48.28s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "\t233.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_2_BAG_L3 ... Tuning model for up to 147.31s of the 2598.99s of remaining time.\n",
            "\tFitting XGBoost_2_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_2_BAG_L3 model...\n",
            "\tHyperparameter search space for XGBoost_2_BAG_L3: \n",
            "min_child_weight:   Int: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c164e2a97ef40a4bb149976010177c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03111\n",
            "[50]\tvalidation_0-error:0.03198\n",
            "[100]\tvalidation_0-error:0.03068\n",
            "[150]\tvalidation_0-error:0.03111\n",
            "[191]\tvalidation_0-error:0.03111\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03717\n",
            "[100]\tvalidation_0-error:0.03673\n",
            "[150]\tvalidation_0-error:0.03760\n",
            "[195]\tvalidation_0-error:0.03760\n",
            "[0]\tvalidation_0-error:0.03673\n",
            "[50]\tvalidation_0-error:0.03414\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[200]\tvalidation_0-error:0.03457\n",
            "[210]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.04408\n",
            "[50]\tvalidation_0-error:0.03544\n",
            "[100]\tvalidation_0-error:0.03544\n",
            "[150]\tvalidation_0-error:0.03544\n",
            "[195]\tvalidation_0-error:0.03587\n",
            "[0]\tvalidation_0-error:0.03198\n",
            "[50]\tvalidation_0-error:0.02982\n",
            "[100]\tvalidation_0-error:0.02982\n",
            "[150]\tvalidation_0-error:0.02982\n",
            "[189]\tvalidation_0-error:0.02982\n",
            "[0]\tvalidation_0-error:0.04365\n",
            "[50]\tvalidation_0-error:0.03889\n",
            "[100]\tvalidation_0-error:0.03933\n",
            "[150]\tvalidation_0-error:0.03889\n",
            "[186]\tvalidation_0-error:0.03889\n",
            "[0]\tvalidation_0-error:0.04494\n",
            "[50]\tvalidation_0-error:0.04105\n",
            "[100]\tvalidation_0-error:0.04149\n",
            "[150]\tvalidation_0-error:0.04149\n",
            "[185]\tvalidation_0-error:0.04149\n",
            "[0]\tvalidation_0-error:0.04280\n",
            "[50]\tvalidation_0-error:0.03848\n",
            "[100]\tvalidation_0-error:0.03848\n",
            "[150]\tvalidation_0-error:0.03805\n",
            "[200]\tvalidation_0-error:0.03805\n",
            "[250]\tvalidation_0-error:0.03805\n",
            "[300]\tvalidation_0-error:0.03805\n",
            "[328]\tvalidation_0-error:0.03805\n",
            "[0]\tvalidation_0-error:0.03889\n",
            "[50]\tvalidation_0-error:0.03673\n",
            "[100]\tvalidation_0-error:0.03673\n",
            "[150]\tvalidation_0-error:0.03673\n",
            "[186]\tvalidation_0-error:0.03673\n",
            "[0]\tvalidation_0-error:0.04019\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03500\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[187]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.03846\n",
            "[50]\tvalidation_0-error:0.03846\n",
            "[100]\tvalidation_0-error:0.03760\n",
            "[150]\tvalidation_0-error:0.03760\n",
            "[186]\tvalidation_0-error:0.03760\n",
            "[0]\tvalidation_0-error:0.03976\n",
            "[50]\tvalidation_0-error:0.03673\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[200]\tvalidation_0-error:0.03544\n",
            "[250]\tvalidation_0-error:0.03544\n",
            "[300]\tvalidation_0-error:0.03544\n",
            "[350]\tvalidation_0-error:0.03544\n",
            "[0]\tvalidation_0-error:0.03933\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[189]\tvalidation_0-error:0.03630\n",
            "[0]\tvalidation_0-error:0.03457\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03500\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[185]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.04062\n",
            "[50]\tvalidation_0-error:0.03846\n",
            "[100]\tvalidation_0-error:0.03933\n",
            "[150]\tvalidation_0-error:0.03933\n",
            "[194]\tvalidation_0-error:0.03933\n",
            "[0]\tvalidation_0-error:0.03588\n",
            "[50]\tvalidation_0-error:0.03113\n",
            "[100]\tvalidation_0-error:0.03070\n",
            "[150]\tvalidation_0-error:0.03113\n",
            "[200]\tvalidation_0-error:0.03156\n",
            "[211]\tvalidation_0-error:0.03156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for XGBoost_2_BAG_L3 model HPO: 89.91815567016602\n",
            "Best hyperparameter configuration for XGBoost_2_BAG_L3 model: \n",
            "{'n_estimators': 800, 'learning_rate': 0.03, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'max_depth': 10, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 1}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L3/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t89.85s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "\t227.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_BAG_L3 ... Tuning model for up to 147.31s of the 2509.02s of remaining time.\n",
            "\tFitting LinearModel_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_BAG_L3 model...\n",
            "\tHyperparameter search space for LinearModel_BAG_L3: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cc80fee0808478aa48247eb05a86f71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_BAG_L3 model HPO: 24.544328927993774\n",
            "Best hyperparameter configuration for LinearModel_BAG_L3 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/model.pkl\n",
            "Fitted model: LinearModel_BAG_L3/T1 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t6.58s\t = Training   runtime\n",
            "\t0.76s\t = Validation runtime\n",
            "\t219.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/model.pkl\n",
            "Fitted model: LinearModel_BAG_L3/T2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t7.32s\t = Training   runtime\n",
            "\t0.81s\t = Validation runtime\n",
            "\t218.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/model.pkl\n",
            "Fitted model: LinearModel_BAG_L3/T3 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t4.87s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "\t229.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/model.pkl\n",
            "Fitted model: LinearModel_BAG_L3/T4 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t5.65s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "\t228.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_2_BAG_L3 ... Tuning model for up to 147.31s of the 2484.4s of remaining time.\n",
            "\tFitting LinearModel_2_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_2_BAG_L3 model...\n",
            "\tHyperparameter search space for LinearModel_2_BAG_L3: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaf8db7cb35a48b6a33cf6d803642a5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_2_BAG_L3 model HPO: 40.70367622375488\n",
            "Best hyperparameter configuration for LinearModel_2_BAG_L3 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L3/T1 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t14.09s\t = Training   runtime\n",
            "\t0.85s\t = Validation runtime\n",
            "\t217.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L3/T2 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t9.81s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "\t219.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L3/T3 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t8.43s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t229.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L3/T4 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t8.23s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "\t229.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_3_BAG_L3 ... Tuning model for up to 147.31s of the 2443.61s of remaining time.\n",
            "\tFitting LinearModel_3_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_3_BAG_L3 model...\n",
            "\tHyperparameter search space for LinearModel_3_BAG_L3: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "333f6cf829204adcbc0acaf9e7de0b7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_3_BAG_L3 model HPO: 52.565855264663696\n",
            "Best hyperparameter configuration for LinearModel_3_BAG_L3 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L3/T1 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t14.77s\t = Training   runtime\n",
            "\t0.8s\t = Validation runtime\n",
            "\t218.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L3/T2 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t14.63s\t = Training   runtime\n",
            "\t0.78s\t = Validation runtime\n",
            "\t219.5\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L3/T3 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t11.41s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t229.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L3/T4 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t11.62s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "\t229.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 147.31s of the 2390.97s of remaining time.\n",
            "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_BAG_L3 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_BAG_L3: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b248bbb25c4c46a7a604b0ca73841f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1687, Val accuracy: 0.9689, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1584, Val accuracy: 0.968, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.153, Val accuracy: 0.9693, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1521, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1513, Val accuracy: 0.9693, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1492, Val accuracy: 0.9693, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1512, Val accuracy: 0.9693, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1489, Val accuracy: 0.9689, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1481, Val accuracy: 0.9693, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1463, Val accuracy: 0.9689, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1478, Val accuracy: 0.9693, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.146, Val accuracy: 0.9693, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1446, Val accuracy: 0.9693, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1448, Val accuracy: 0.9689, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1449, Val accuracy: 0.9689, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1421, Val accuracy: 0.9693, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 16 (Update 2016). Val accuracy: 0.9693171996542783\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1622, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1514, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1503, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1485, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1508, Val accuracy: 0.9633, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1466, Val accuracy: 0.9628, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1474, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1451, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1447, Val accuracy: 0.9628, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1437, Val accuracy: 0.9633, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1436, Val accuracy: 0.9628, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1442, Val accuracy: 0.9615, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1409, Val accuracy: 0.9633, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.141, Val accuracy: 0.9628, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1419, Val accuracy: 0.9628, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9632670700086431\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1651, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1519, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1527, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1561, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1495, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1479, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1512, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1455, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1437, Val accuracy: 0.9646, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1443, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1455, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1437, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1437, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1437, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1413, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1424, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1415, Val accuracy: 0.9654, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1635, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1543, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1517, Val accuracy: 0.9646, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1509, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1523, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1491, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1462, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1483, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1466, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1445, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1462, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1447, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.9646, Best Epoch: 8\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1423, Val accuracy: 0.9654, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1421, Val accuracy: 0.9654, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1423, Val accuracy: 0.965, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1435, Val accuracy: 0.9654, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 17 (Update 2142). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.174, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1571, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1524, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1517, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1517, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1508, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1482, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1468, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1473, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1459, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1461, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1434, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1448, Val accuracy: 0.9702, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1446, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1427, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1451, Val accuracy: 0.9702, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1434, Val accuracy: 0.9697, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 16 (Update 2016). Val accuracy: 0.9701815038893691\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1653, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1547, Val accuracy: 0.9611, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1498, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1488, Val accuracy: 0.9615, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1461, Val accuracy: 0.9611, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1475, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.147, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1463, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1443, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1454, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1422, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1413, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.143, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1429, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1404, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1414, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1395, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1405, Val accuracy: 0.9607, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9619706136560069\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1593, Val accuracy: 0.9594, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1491, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1493, Val accuracy: 0.9576, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1473, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1479, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1463, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1464, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1443, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1435, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.144, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1417, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1426, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1405, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1395, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1381, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1376, Val accuracy: 0.9589, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9593777009507347\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1617, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.151, Val accuracy: 0.9611, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1502, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.148, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1473, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1437, Val accuracy: 0.9602, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1455, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1454, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1426, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1429, Val accuracy: 0.9615, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1421, Val accuracy: 0.9607, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.142, Val accuracy: 0.9615, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.962, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1397, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1424, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1396, Val accuracy: 0.9615, Best Epoch: 13\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1379, Val accuracy: 0.9607, Best Epoch: 13\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1387, Val accuracy: 0.9615, Best Epoch: 13\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1402, Val accuracy: 0.9611, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9619541720709036\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1626, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1518, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1548, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1496, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.148, Val accuracy: 0.9633, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1476, Val accuracy: 0.9628, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1473, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1465, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1458, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.145, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1451, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1437, Val accuracy: 0.9637, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1416, Val accuracy: 0.9624, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1417, Val accuracy: 0.9624, Best Epoch: 12\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1407, Val accuracy: 0.9628, Best Epoch: 12\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1403, Val accuracy: 0.9637, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1402, Val accuracy: 0.9628, Best Epoch: 16\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.14, Val accuracy: 0.9637, Best Epoch: 18\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 18 (Update 2268). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1716, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1543, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1585, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1496, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1511, Val accuracy: 0.9659, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1499, Val accuracy: 0.9663, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1495, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1464, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.147, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.146, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1422, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1424, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1422, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1442, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1414, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1423, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.141, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1388, Val accuracy: 0.9646, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2394 (Epoch 18))\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1629, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1544, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1509, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1493, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.148, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1485, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1481, Val accuracy: 0.9624, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1457, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1444, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1454, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1426, Val accuracy: 0.9611, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1462, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.141, Val accuracy: 0.9611, Best Epoch: 9\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.143, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1401, Val accuracy: 0.9607, Best Epoch: 9\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1377, Val accuracy: 0.9615, Best Epoch: 9\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1384, Val accuracy: 0.9615, Best Epoch: 9\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1397, Val accuracy: 0.9615, Best Epoch: 9\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1398, Val accuracy: 0.9611, Best Epoch: 9\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1351, Val accuracy: 0.9615, Best Epoch: 9\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1358, Val accuracy: 0.9611, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2762 (Epoch 21))\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9624027657735523\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1638, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1511, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1522, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1515, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1505, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1469, Val accuracy: 0.9637, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1438, Val accuracy: 0.9633, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1458, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1435, Val accuracy: 0.9637, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1437, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1429, Val accuracy: 0.9637, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1428, Val accuracy: 0.9637, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1418, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1412, Val accuracy: 0.9637, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1401, Val accuracy: 0.9637, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1395, Val accuracy: 0.9633, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1402, Val accuracy: 0.9633, Best Epoch: 15\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1414, Val accuracy: 0.9624, Best Epoch: 15\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1436, Val accuracy: 0.9637, Best Epoch: 19\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1414, Val accuracy: 0.9637, Best Epoch: 20\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "Best model found on Epoch 20 (Update 2520). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1706, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.152, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1545, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1486, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1472, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.148, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1464, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1461, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1451, Val accuracy: 0.9628, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1461, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1436, Val accuracy: 0.9637, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1419, Val accuracy: 0.9633, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1411, Val accuracy: 0.9628, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1425, Val accuracy: 0.9633, Best Epoch: 11\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1389, Val accuracy: 0.9633, Best Epoch: 11\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1389, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.138, Val accuracy: 0.9637, Best Epoch: 17\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1363, Val accuracy: 0.9637, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1365, Val accuracy: 0.9633, Best Epoch: 18\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1369, Val accuracy: 0.9633, Best Epoch: 18\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1386, Val accuracy: 0.9633, Best Epoch: 18\n",
            "Best model found on Epoch 18 (Update 2268). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1641, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1565, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1548, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1504, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1499, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1468, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1492, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1452, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1478, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1492, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1431, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1434, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1435, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1458, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1424, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1422, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1423, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1445, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1416, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1403, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1392, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1609, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1554, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1523, Val accuracy: 0.9611, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1478, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1462, Val accuracy: 0.9615, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1441, Val accuracy: 0.9607, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1449, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1448, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1458, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1447, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1429, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1433, Val accuracy: 0.9594, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1418, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1411, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1422, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1393, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1411, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1409, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1378, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1374, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1371, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.1357, Val accuracy: 0.9607, Best Epoch: 7\n",
            "Epoch 23 (Update 2898).\tTrain loss: 0.1368, Val accuracy: 0.9602, Best Epoch: 7\n",
            "Epoch 24 (Update 3024).\tTrain loss: 0.137, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 25 (Update 3150).\tTrain loss: 0.1355, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Epoch 26 (Update 3276).\tTrain loss: 0.1352, Val accuracy: 0.9611, Best Epoch: 7\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9619706136560069\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1716, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1577, Val accuracy: 0.9702, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1544, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1539, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1501, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1501, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1509, Val accuracy: 0.9702, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1482, Val accuracy: 0.9697, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.148, Val accuracy: 0.9697, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.146, Val accuracy: 0.9702, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1462, Val accuracy: 0.9697, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1475, Val accuracy: 0.9697, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1441, Val accuracy: 0.9702, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1446, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1456, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1456, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1439, Val accuracy: 0.9689, Best Epoch: 13\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1433, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.142, Val accuracy: 0.9697, Best Epoch: 13\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1441, Val accuracy: 0.9693, Best Epoch: 13\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1439, Val accuracy: 0.9702, Best Epoch: 21\n",
            "Best model found on Epoch 21 (Update 2646). Val accuracy: 0.9701686121919585\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_BAG_L3 model HPO: 132.63748693466187\n",
            "Best hyperparameter configuration for NeuralNetTorch_BAG_L3 model: \n",
            "{'num_epochs': 300, 'epochs_wo_improve': None, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.01, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L3/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t132.55s\t = Training   runtime\n",
            "\t1.01s\t = Validation runtime\n",
            "\t214.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_2_BAG_L3 ... Tuning model for up to 147.31s of the 2258.28s of remaining time.\n",
            "\tFitting NeuralNetTorch_2_BAG_L3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_2_BAG_L3 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_2_BAG_L3: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbddc0691cc4f608b948f64efca5f59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1611, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1511, Val accuracy: 0.9693, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1488, Val accuracy: 0.9689, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1489, Val accuracy: 0.9702, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1478, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.147, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1502, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1485, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1463, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.148, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1483, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1474, Val accuracy: 0.9689, Best Epoch: 4\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1466, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1463, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1451, Val accuracy: 0.9685, Best Epoch: 4\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1466, Val accuracy: 0.9697, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9701815038893691\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.154, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1469, Val accuracy: 0.9633, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1445, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1449, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1472, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1449, Val accuracy: 0.9633, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1458, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.9628, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1435, Val accuracy: 0.9628, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1442, Val accuracy: 0.9633, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1443, Val accuracy: 0.9633, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1469, Val accuracy: 0.9633, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1427, Val accuracy: 0.9633, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1448, Val accuracy: 0.9633, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1431, Val accuracy: 0.9633, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9632670700086431\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1576, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1478, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1473, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1488, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1458, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1458, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1464, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.144, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1472, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1442, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1442, Val accuracy: 0.9659, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1459, Val accuracy: 0.9654, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1449, Val accuracy: 0.9654, Best Epoch: 12\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1427, Val accuracy: 0.965, Best Epoch: 12\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1436, Val accuracy: 0.965, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1549, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1472, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1466, Val accuracy: 0.9646, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1458, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1484, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1465, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1463, Val accuracy: 0.9646, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1445, Val accuracy: 0.9646, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1489, Val accuracy: 0.9646, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1446, Val accuracy: 0.9637, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1452, Val accuracy: 0.965, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1435, Val accuracy: 0.9646, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1448, Val accuracy: 0.9641, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1431, Val accuracy: 0.965, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1424, Val accuracy: 0.9654, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1409, Val accuracy: 0.9646, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1423, Val accuracy: 0.9637, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1618, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1497, Val accuracy: 0.9702, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1495, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1483, Val accuracy: 0.9702, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1491, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1482, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1483, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1459, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1467, Val accuracy: 0.9702, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1456, Val accuracy: 0.9702, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1468, Val accuracy: 0.9702, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1465, Val accuracy: 0.9702, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1467, Val accuracy: 0.9702, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1448, Val accuracy: 0.9702, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.147, Val accuracy: 0.9697, Best Epoch: 14\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1448, Val accuracy: 0.9697, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 14 (Update 1764). Val accuracy: 0.9701815038893691\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1582, Val accuracy: 0.9611, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1472, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.146, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1441, Val accuracy: 0.9615, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1439, Val accuracy: 0.9611, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1452, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1454, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1433, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1444, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1452, Val accuracy: 0.9615, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1436, Val accuracy: 0.9615, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1435, Val accuracy: 0.9615, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1428, Val accuracy: 0.9615, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1449, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1421, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1415, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1434, Val accuracy: 0.9611, Best Epoch: 13\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1428, Val accuracy: 0.9607, Best Epoch: 13\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1431, Val accuracy: 0.9598, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9615384615384616\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1527, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.144, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1441, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1425, Val accuracy: 0.9589, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.145, Val accuracy: 0.9585, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1429, Val accuracy: 0.9589, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1425, Val accuracy: 0.9594, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1429, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1422, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1407, Val accuracy: 0.9589, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1396, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1395, Val accuracy: 0.9589, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1409, Val accuracy: 0.9572, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1404, Val accuracy: 0.9594, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.141, Val accuracy: 0.9576, Best Epoch: 14\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1391, Val accuracy: 0.9594, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 16 (Update 2016). Val accuracy: 0.9593777009507347\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1547, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1455, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1463, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1455, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1439, Val accuracy: 0.9624, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1416, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1449, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1437, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1412, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1419, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1443, Val accuracy: 0.9611, Best Epoch: 5\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1441, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1436, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1407, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1438, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1422, Val accuracy: 0.9615, Best Epoch: 5\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1426, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1418, Val accuracy: 0.9624, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.14, Val accuracy: 0.9615, Best Epoch: 18\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1405, Val accuracy: 0.9624, Best Epoch: 20\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "Best model found on Epoch 20 (Update 2520). Val accuracy: 0.9623865110246433\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1548, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1482, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1461, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1475, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1454, Val accuracy: 0.9633, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1455, Val accuracy: 0.9611, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1468, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1444, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1451, Val accuracy: 0.9637, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1444, Val accuracy: 0.9633, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1454, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.144, Val accuracy: 0.9633, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1453, Val accuracy: 0.9633, Best Epoch: 9\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1429, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1435, Val accuracy: 0.9637, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1416, Val accuracy: 0.9633, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1421, Val accuracy: 0.9624, Best Epoch: 15\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1433, Val accuracy: 0.9633, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1578, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1487, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.149, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1492, Val accuracy: 0.9663, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1464, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.147, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1452, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1462, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1459, Val accuracy: 0.9663, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1469, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.144, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1443, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1441, Val accuracy: 0.9659, Best Epoch: 9\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1452, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1446, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1453, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1429, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1429, Val accuracy: 0.9654, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 9 (Update 1134). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1541, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1483, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1464, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1441, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1438, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1449, Val accuracy: 0.9602, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1459, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1437, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1451, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1427, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1435, Val accuracy: 0.9615, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1445, Val accuracy: 0.9624, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1441, Val accuracy: 0.9624, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1422, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1409, Val accuracy: 0.9624, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1422, Val accuracy: 0.962, Best Epoch: 15\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1418, Val accuracy: 0.9611, Best Epoch: 15\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1434, Val accuracy: 0.9624, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1448, Val accuracy: 0.962, Best Epoch: 18\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1399, Val accuracy: 0.9615, Best Epoch: 18\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1399, Val accuracy: 0.962, Best Epoch: 18\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.14, Val accuracy: 0.9615, Best Epoch: 18\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 22)\n",
            "Best model found on Epoch 18 (Update 2268). Val accuracy: 0.9624027657735523\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1559, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1456, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1475, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1476, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1456, Val accuracy: 0.9633, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1439, Val accuracy: 0.9633, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1428, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.9637, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1435, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1432, Val accuracy: 0.9628, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.142, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1432, Val accuracy: 0.9633, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1428, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1428, Val accuracy: 0.9637, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1435, Val accuracy: 0.9637, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1439, Val accuracy: 0.9637, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1422, Val accuracy: 0.9637, Best Epoch: 17\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.143, Val accuracy: 0.9637, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1431, Val accuracy: 0.9633, Best Epoch: 18\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1433, Val accuracy: 0.9637, Best Epoch: 20\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1406, Val accuracy: 0.9624, Best Epoch: 20\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 21)\n",
            "Best model found on Epoch 20 (Update 2520). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1603, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1468, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1484, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1456, Val accuracy: 0.9637, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1454, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1447, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.144, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1445, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1457, Val accuracy: 0.9628, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1428, Val accuracy: 0.9637, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1429, Val accuracy: 0.9633, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1413, Val accuracy: 0.9633, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1429, Val accuracy: 0.9637, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1432, Val accuracy: 0.9633, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1402, Val accuracy: 0.9628, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1408, Val accuracy: 0.9637, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1415, Val accuracy: 0.9637, Best Epoch: 17\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1416, Val accuracy: 0.9633, Best Epoch: 17\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1401, Val accuracy: 0.9628, Best Epoch: 17\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1412, Val accuracy: 0.9633, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "Best model found on Epoch 17 (Update 2142). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1576, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1492, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1489, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1471, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1475, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1443, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1466, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.145, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1476, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1429, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1434, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1451, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1453, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1436, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1425, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1441, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1472, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.143, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1413, Val accuracy: 0.9637, Best Epoch: 1\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1426, Val accuracy: 0.965, Best Epoch: 1\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1555, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1485, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1465, Val accuracy: 0.9611, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1456, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1444, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1433, Val accuracy: 0.962, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1432, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1428, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1435, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1417, Val accuracy: 0.9607, Best Epoch: 6\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1412, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1421, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1441, Val accuracy: 0.9602, Best Epoch: 6\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.143, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.143, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1419, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1419, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1409, Val accuracy: 0.9607, Best Epoch: 6\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1406, Val accuracy: 0.9611, Best Epoch: 6\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1406, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1421, Val accuracy: 0.9607, Best Epoch: 6\n",
            "Best model found on Epoch 6 (Update 756). Val accuracy: 0.9619706136560069\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L2\",\n",
            "        \"XGBoost_2_BAG_L2/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L2\",\n",
            "        \"RandomForest_2_BAG_L2\",\n",
            "        \"LinearModel_BAG_L2/T3\",\n",
            "        \"LinearModel_BAG_L2/T4\",\n",
            "        \"LinearModel_2_BAG_L2/T3\",\n",
            "        \"LinearModel_2_BAG_L2/T4\",\n",
            "        \"LinearModel_3_BAG_L2/T3\",\n",
            "        \"NeuralNetTorch_BAG_L2/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L2/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1613, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1495, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.149, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1492, Val accuracy: 0.9693, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1485, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.147, Val accuracy: 0.9702, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.149, Val accuracy: 0.9693, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.147, Val accuracy: 0.9702, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1492, Val accuracy: 0.9702, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1472, Val accuracy: 0.9697, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1482, Val accuracy: 0.9693, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1466, Val accuracy: 0.9697, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1449, Val accuracy: 0.9702, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1452, Val accuracy: 0.9702, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1453, Val accuracy: 0.9693, Best Epoch: 14\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1479, Val accuracy: 0.9697, Best Epoch: 14\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1457, Val accuracy: 0.9693, Best Epoch: 14\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1459, Val accuracy: 0.9697, Best Epoch: 14\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1471, Val accuracy: 0.9702, Best Epoch: 19\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.147, Val accuracy: 0.9697, Best Epoch: 19\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1442, Val accuracy: 0.9702, Best Epoch: 21\n",
            "Best model found on Epoch 21 (Update 2646). Val accuracy: 0.9701686121919585\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_2_BAG_L3 model HPO: 135.64806866645813\n",
            "Best hyperparameter configuration for NeuralNetTorch_2_BAG_L3 model: \n",
            "{'num_epochs': 500, 'epochs_wo_improve': None, 'activation': 'tanh', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3, 'optimizer': 'adam', 'learning_rate': 0.005, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L3/T1 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t135.57s\t = Training   runtime\n",
            "\t1.15s\t = Validation runtime\n",
            "\t212.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L4: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 2122.55s of remaining time.\n",
            "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
            "Ensemble size: 2\n",
            "Ensemble weights: \n",
            "[0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.5 0. ]\n",
            "\t0.06s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L4/model.pkl\n",
            "\tEnsemble Weights: {'RandomForest_2_BAG_L3': 0.5, 'NeuralNetTorch_BAG_L3/T1': 0.5}\n",
            "\t0.9647\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t211.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tRandomForest_BAG_L4: \t{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_2_BAG_L4: \t{'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L4: \t{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tCatBoost_2_BAG_L4: \t{'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_BAG_L4: \t{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_2_BAG_L4: \t{'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_BAG_L4: \t{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_2_BAG_L4: \t{'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_3_BAG_L4: \t{'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_BAG_L4: \t{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_2_BAG_L4: \t{'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "Fitting 11 L4 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/oof.pkl\n",
            "Hyperparameter tuning model: RandomForest_BAG_L4 ... Tuning model for up to 173.63s of the 2122.04s of remaining time.\n",
            "\tFitting RandomForest_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_BAG_L4 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_BAG_L4. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/utils/model_template.pkl\n",
            "\t3.62s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/model.pkl\n",
            "Fitted model: RandomForest_BAG_L4 ...\n",
            "\t0.9648\t = Validation score   (accuracy)\n",
            "\t18.17s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "\t145.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_2_BAG_L4 ... Tuning model for up to 173.63s of the 2103.79s of remaining time.\n",
            "\tFitting RandomForest_2_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_2_BAG_L4 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_2_BAG_L4. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/utils/model_template.pkl\n",
            "\t8.14s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/model.pkl\n",
            "Fitted model: RandomForest_2_BAG_L4 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t31.73s\t = Training   runtime\n",
            "\t1.42s\t = Validation runtime\n",
            "\t144.2\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_BAG_L4 ... Tuning model for up to 173.63s of the 2071.98s of remaining time.\n",
            "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_BAG_L4 model...\n",
            "\tHyperparameter search space for CatBoost_BAG_L4: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1afcfa698de645988b06e90174c9b8dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L4/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_BAG_L4 model HPO: 2.933859348297119\n",
            "Best hyperparameter configuration for CatBoost_BAG_L4 model: \n",
            "{'iterations': 1000, 'learning_rate': 0.03, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L4... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_2_BAG_L4 ... Tuning model for up to 173.63s of the 2069.01s of remaining time.\n",
            "\tFitting CatBoost_2_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_2_BAG_L4 model...\n",
            "\tHyperparameter search space for CatBoost_2_BAG_L4: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbf65adf50364560b4261b555ccb5518"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/CatBoost_2_BAG_L4/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_2_BAG_L4 model HPO: 2.9568076133728027\n",
            "Best hyperparameter configuration for CatBoost_2_BAG_L4 model: \n",
            "{'iterations': 1500, 'learning_rate': 0.02, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_2_BAG_L4... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_BAG_L4 ... Tuning model for up to 173.63s of the 2066.02s of remaining time.\n",
            "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_BAG_L4 model...\n",
            "\tNo hyperparameter search space specified for XGBoost_BAG_L4. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
            "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03268\n",
            "[50]\tvalidation_0-error:0.03052\n",
            "[100]\tvalidation_0-error:0.03133\n",
            "[150]\tvalidation_0-error:0.03133\n",
            "[200]\tvalidation_0-error:0.03160\n",
            "[228]\tvalidation_0-error:0.03160\n",
            "[0]\tvalidation_0-error:0.04214\n",
            "[50]\tvalidation_0-error:0.04160\n",
            "[100]\tvalidation_0-error:0.04187\n",
            "[150]\tvalidation_0-error:0.04187\n",
            "[200]\tvalidation_0-error:0.04160\n",
            "[213]\tvalidation_0-error:0.04160\n",
            "[0]\tvalidation_0-error:0.03863\n",
            "[50]\tvalidation_0-error:0.03728\n",
            "[100]\tvalidation_0-error:0.03701\n",
            "[150]\tvalidation_0-error:0.03701\n",
            "[200]\tvalidation_0-error:0.03755\n",
            "[250]\tvalidation_0-error:0.03728\n",
            "[285]\tvalidation_0-error:0.03728\n",
            "[0]\tvalidation_0-error:0.03809\n",
            "[50]\tvalidation_0-error:0.03674\n",
            "[100]\tvalidation_0-error:0.03728\n",
            "[150]\tvalidation_0-error:0.03755\n",
            "[200]\tvalidation_0-error:0.03728\n",
            "[214]\tvalidation_0-error:0.03755\n",
            "[0]\tvalidation_0-error:0.03404\n",
            "[50]\tvalidation_0-error:0.03269\n",
            "[100]\tvalidation_0-error:0.03241\n",
            "[150]\tvalidation_0-error:0.03241\n",
            "[200]\tvalidation_0-error:0.03241\n",
            "[234]\tvalidation_0-error:0.03241\n",
            "[0]\tvalidation_0-error:0.03862\n",
            "[50]\tvalidation_0-error:0.03511\n",
            "[100]\tvalidation_0-error:0.03538\n",
            "[150]\tvalidation_0-error:0.03511\n",
            "[200]\tvalidation_0-error:0.03565\n",
            "[212]\tvalidation_0-error:0.03538\n",
            "[0]\tvalidation_0-error:0.03647\n",
            "[50]\tvalidation_0-error:0.03512\n",
            "[100]\tvalidation_0-error:0.03512\n",
            "[150]\tvalidation_0-error:0.03512\n",
            "[200]\tvalidation_0-error:0.03512\n",
            "[225]\tvalidation_0-error:0.03512\n",
            "[0]\tvalidation_0-error:0.03620\n",
            "[50]\tvalidation_0-error:0.03593\n",
            "[100]\tvalidation_0-error:0.03566\n",
            "[150]\tvalidation_0-error:0.03566\n",
            "[200]\tvalidation_0-error:0.03566\n",
            "[222]\tvalidation_0-error:0.03566\n",
            "[0]\tvalidation_0-error:0.03620\n",
            "[50]\tvalidation_0-error:0.03566\n",
            "[100]\tvalidation_0-error:0.03566\n",
            "[150]\tvalidation_0-error:0.03566\n",
            "[200]\tvalidation_0-error:0.03566\n",
            "[208]\tvalidation_0-error:0.03566\n",
            "[0]\tvalidation_0-error:0.03836\n",
            "[50]\tvalidation_0-error:0.03566\n",
            "[100]\tvalidation_0-error:0.03566\n",
            "[150]\tvalidation_0-error:0.03566\n",
            "[200]\tvalidation_0-error:0.03593\n",
            "[212]\tvalidation_0-error:0.03593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/model.pkl\n",
            "Fitted model: XGBoost_BAG_L4 ...\n",
            "\t0.9644\t = Validation score   (accuracy)\n",
            "\t55.93s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "\t144.4\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_2_BAG_L4 ... Tuning model for up to 173.63s of the 2010.02s of remaining time.\n",
            "\tFitting XGBoost_2_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_2_BAG_L4 model...\n",
            "\tHyperparameter search space for XGBoost_2_BAG_L4: \n",
            "min_child_weight:   Int: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "173b8d49231a4ba3af1e54c334811373"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03198\n",
            "[50]\tvalidation_0-error:0.02982\n",
            "[100]\tvalidation_0-error:0.02939\n",
            "[150]\tvalidation_0-error:0.02895\n",
            "[194]\tvalidation_0-error:0.02895\n",
            "[0]\tvalidation_0-error:0.03673\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03500\n",
            "[150]\tvalidation_0-error:0.03544\n",
            "[191]\tvalidation_0-error:0.03544\n",
            "[0]\tvalidation_0-error:0.04494\n",
            "[50]\tvalidation_0-error:0.04494\n",
            "[100]\tvalidation_0-error:0.04494\n",
            "[150]\tvalidation_0-error:0.04494\n",
            "[189]\tvalidation_0-error:0.04494\n",
            "[0]\tvalidation_0-error:0.03846\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03587\n",
            "[150]\tvalidation_0-error:0.03673\n",
            "[190]\tvalidation_0-error:0.03673\n",
            "[0]\tvalidation_0-error:0.03889\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[194]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.04494\n",
            "[50]\tvalidation_0-error:0.04322\n",
            "[100]\tvalidation_0-error:0.04365\n",
            "[150]\tvalidation_0-error:0.04365\n",
            "[200]\tvalidation_0-error:0.04365\n",
            "[204]\tvalidation_0-error:0.04365\n",
            "[0]\tvalidation_0-error:0.03111\n",
            "[50]\tvalidation_0-error:0.03025\n",
            "[100]\tvalidation_0-error:0.03068\n",
            "[150]\tvalidation_0-error:0.03025\n",
            "[200]\tvalidation_0-error:0.03025\n",
            "[202]\tvalidation_0-error:0.03025\n",
            "[0]\tvalidation_0-error:0.03415\n",
            "[50]\tvalidation_0-error:0.03286\n",
            "[100]\tvalidation_0-error:0.03329\n",
            "[150]\tvalidation_0-error:0.03372\n",
            "[200]\tvalidation_0-error:0.03372\n",
            "[229]\tvalidation_0-error:0.03372\n",
            "[0]\tvalidation_0-error:0.03803\n",
            "[50]\tvalidation_0-error:0.03630\n",
            "[100]\tvalidation_0-error:0.03630\n",
            "[150]\tvalidation_0-error:0.03630\n",
            "[187]\tvalidation_0-error:0.03630\n",
            "[0]\tvalidation_0-error:0.03587\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03587\n",
            "[150]\tvalidation_0-error:0.03544\n",
            "[190]\tvalidation_0-error:0.03544\n",
            "[0]\tvalidation_0-error:0.03803\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03500\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[185]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.03630\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[193]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03803\n",
            "[100]\tvalidation_0-error:0.03846\n",
            "[150]\tvalidation_0-error:0.03803\n",
            "[200]\tvalidation_0-error:0.03846\n",
            "[234]\tvalidation_0-error:0.03846\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03760\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03803\n",
            "[192]\tvalidation_0-error:0.03846\n",
            "[0]\tvalidation_0-error:0.03760\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[187]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.03805\n",
            "[50]\tvalidation_0-error:0.03459\n",
            "[100]\tvalidation_0-error:0.03415\n",
            "[150]\tvalidation_0-error:0.03415\n",
            "[190]\tvalidation_0-error:0.03415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.02982\n",
            "[50]\tvalidation_0-error:0.02939\n",
            "[100]\tvalidation_0-error:0.02939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ran out of time, early stopping on iteration 128. Best iteration is: \t[6]\t0.02895419187554019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[128]\tvalidation_0-error:0.02939\n",
            "[0]\tvalidation_0-error:0.03414\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03500\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[185]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.04408\n",
            "[50]\tvalidation_0-error:0.04451\n",
            "[100]\tvalidation_0-error:0.04494\n",
            "[150]\tvalidation_0-error:0.04451\n",
            "[186]\tvalidation_0-error:0.04494\n",
            "[0]\tvalidation_0-error:0.03673\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03587\n",
            "[150]\tvalidation_0-error:0.03587\n",
            "[194]\tvalidation_0-error:0.03587\n",
            "[0]\tvalidation_0-error:0.03846\n",
            "[50]\tvalidation_0-error:0.03414\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03500\n",
            "[191]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.04451\n",
            "[50]\tvalidation_0-error:0.04278\n",
            "[100]\tvalidation_0-error:0.04322\n",
            "[150]\tvalidation_0-error:0.04408\n",
            "[188]\tvalidation_0-error:0.04365\n",
            "[0]\tvalidation_0-error:0.03068\n",
            "[50]\tvalidation_0-error:0.02982\n",
            "[100]\tvalidation_0-error:0.02982\n",
            "[150]\tvalidation_0-error:0.02982\n",
            "[186]\tvalidation_0-error:0.03025\n",
            "[0]\tvalidation_0-error:0.03459\n",
            "[50]\tvalidation_0-error:0.03415\n",
            "[100]\tvalidation_0-error:0.03415\n",
            "[150]\tvalidation_0-error:0.03372\n",
            "[187]\tvalidation_0-error:0.03415\n",
            "[0]\tvalidation_0-error:0.03587\n",
            "[50]\tvalidation_0-error:0.03673\n",
            "[100]\tvalidation_0-error:0.03673\n",
            "[150]\tvalidation_0-error:0.03673\n",
            "[185]\tvalidation_0-error:0.03673\n",
            "[0]\tvalidation_0-error:0.03630\n",
            "[50]\tvalidation_0-error:0.03587\n",
            "[100]\tvalidation_0-error:0.03544\n",
            "[150]\tvalidation_0-error:0.03544\n",
            "[185]\tvalidation_0-error:0.03500\n",
            "[0]\tvalidation_0-error:0.03544\n",
            "[50]\tvalidation_0-error:0.03500\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[187]\tvalidation_0-error:0.03457\n",
            "[0]\tvalidation_0-error:0.03457\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03414\n",
            "[150]\tvalidation_0-error:0.03414\n",
            "[200]\tvalidation_0-error:0.03414\n",
            "[250]\tvalidation_0-error:0.03414\n",
            "[251]\tvalidation_0-error:0.03414\n",
            "[0]\tvalidation_0-error:0.04235\n",
            "[50]\tvalidation_0-error:0.03846\n",
            "[100]\tvalidation_0-error:0.03846\n",
            "[150]\tvalidation_0-error:0.03846\n",
            "[200]\tvalidation_0-error:0.03846\n",
            "[214]\tvalidation_0-error:0.03846\n",
            "[0]\tvalidation_0-error:0.03933\n",
            "[50]\tvalidation_0-error:0.03803\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03846\n",
            "[190]\tvalidation_0-error:0.03846\n",
            "[0]\tvalidation_0-error:0.03717\n",
            "[50]\tvalidation_0-error:0.03414\n",
            "[100]\tvalidation_0-error:0.03457\n",
            "[150]\tvalidation_0-error:0.03457\n",
            "[200]\tvalidation_0-error:0.03371\n",
            "[250]\tvalidation_0-error:0.03414\n",
            "[300]\tvalidation_0-error:0.03371\n",
            "[350]\tvalidation_0-error:0.03371\n",
            "[370]\tvalidation_0-error:0.03371\n",
            "[0]\tvalidation_0-error:0.03545\n",
            "[50]\tvalidation_0-error:0.03459\n",
            "[100]\tvalidation_0-error:0.03459\n",
            "[150]\tvalidation_0-error:0.03459\n",
            "[200]\tvalidation_0-error:0.03459\n",
            "[203]\tvalidation_0-error:0.03459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for XGBoost_2_BAG_L4 model HPO: 142.27964615821838\n",
            "Best hyperparameter configuration for XGBoost_2_BAG_L4 model: \n",
            "{'n_estimators': 800, 'learning_rate': 0.03, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'max_depth': 10, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 5}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L4/T1 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t79.31s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "\t143.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L4/T2 ...\n",
            "\t0.9647\t = Validation score   (accuracy)\n",
            "\t62.88s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t142.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_BAG_L4 ... Tuning model for up to 173.63s of the 1867.69s of remaining time.\n",
            "\tFitting LinearModel_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_BAG_L4 model...\n",
            "\tHyperparameter search space for LinearModel_BAG_L4: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cad0109aabb647de94eac66232bfefc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_BAG_L4 model HPO: 24.074187517166138\n",
            "Best hyperparameter configuration for LinearModel_BAG_L4 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/model.pkl\n",
            "Fitted model: LinearModel_BAG_L4/T1 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t7.34s\t = Training   runtime\n",
            "\t0.75s\t = Validation runtime\n",
            "\t139.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/model.pkl\n",
            "Fitted model: LinearModel_BAG_L4/T2 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t6.11s\t = Training   runtime\n",
            "\t0.63s\t = Validation runtime\n",
            "\t140.3\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/model.pkl\n",
            "Fitted model: LinearModel_BAG_L4/T3 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t5.59s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "\t142.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/model.pkl\n",
            "Fitted model: LinearModel_BAG_L4/T4 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t4.89s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "\t143.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_2_BAG_L4 ... Tuning model for up to 173.63s of the 1843.53s of remaining time.\n",
            "\tFitting LinearModel_2_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_2_BAG_L4 model...\n",
            "\tHyperparameter search space for LinearModel_2_BAG_L4: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d0e45eba4844082a3582fff061da0d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_2_BAG_L4 model HPO: 40.51854181289673\n",
            "Best hyperparameter configuration for LinearModel_2_BAG_L4 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L4/T1 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t13.75s\t = Training   runtime\n",
            "\t0.71s\t = Validation runtime\n",
            "\t139.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L4/T2 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t10.0s\t = Training   runtime\n",
            "\t0.71s\t = Validation runtime\n",
            "\t139.6\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L4/T3 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t8.24s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t142.9\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L4/T4 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t8.36s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t143.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_3_BAG_L4 ... Tuning model for up to 173.63s of the 1802.93s of remaining time.\n",
            "\tFitting LinearModel_3_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_3_BAG_L4 model...\n",
            "\tHyperparameter search space for LinearModel_3_BAG_L4: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dabbc522c844eb19d6c76b7e7d33b46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_3_BAG_L4 model HPO: 60.06768441200256\n",
            "Best hyperparameter configuration for LinearModel_3_BAG_L4 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L4/T1 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t15.12s\t = Training   runtime\n",
            "\t0.68s\t = Validation runtime\n",
            "\t139.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L4/T2 ...\n",
            "\t0.9641\t = Validation score   (accuracy)\n",
            "\t16.01s\t = Training   runtime\n",
            "\t0.81s\t = Validation runtime\n",
            "\t138.8\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L4/T3 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t12.0s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "\t143.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L4/T4 ...\n",
            "\t0.964\t = Validation score   (accuracy)\n",
            "\t16.79s\t = Training   runtime\n",
            "\t0.46s\t = Validation runtime\n",
            "\t141.7\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L4 ... Tuning model for up to 173.63s of the 1742.76s of remaining time.\n",
            "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_BAG_L4 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_BAG_L4: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ae15a9094f4a33aa2f217dc0f895ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1718, Val accuracy: 0.971, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1555, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1555, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1514, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1553, Val accuracy: 0.9706, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1509, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1507, Val accuracy: 0.9693, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1512, Val accuracy: 0.9702, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1478, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1499, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1496, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1479, Val accuracy: 0.9702, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 1 (Update 126). Val accuracy: 0.9710458081244598\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.166, Val accuracy: 0.9667, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1543, Val accuracy: 0.9667, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1523, Val accuracy: 0.9667, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1539, Val accuracy: 0.9667, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1485, Val accuracy: 0.9667, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1483, Val accuracy: 0.9663, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1493, Val accuracy: 0.9667, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1481, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1456, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1453, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1468, Val accuracy: 0.9663, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.966724286949006\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1625, Val accuracy: 0.9564, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1499, Val accuracy: 0.9564, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1463, Val accuracy: 0.9559, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1467, Val accuracy: 0.9559, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1432, Val accuracy: 0.9564, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1444, Val accuracy: 0.9564, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.143, Val accuracy: 0.9559, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1418, Val accuracy: 0.9564, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1406, Val accuracy: 0.9559, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1419, Val accuracy: 0.9559, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1426, Val accuracy: 0.9559, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1396, Val accuracy: 0.9564, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.956352636127917\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1649, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1571, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1523, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1512, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1469, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1474, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1486, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1471, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1464, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1472, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1444, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1434, Val accuracy: 0.9637, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9641313742437337\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1658, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1555, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1524, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1504, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1491, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1492, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1478, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1472, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1457, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1467, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.147, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1466, Val accuracy: 0.965, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 5 (Update 630). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1621, Val accuracy: 0.9568, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1512, Val accuracy: 0.9572, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1472, Val accuracy: 0.9572, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1481, Val accuracy: 0.9572, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1485, Val accuracy: 0.9576, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1448, Val accuracy: 0.9576, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1455, Val accuracy: 0.9576, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1463, Val accuracy: 0.9576, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1425, Val accuracy: 0.9576, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1441, Val accuracy: 0.9576, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1413, Val accuracy: 0.9572, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1434, Val accuracy: 0.9576, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1409, Val accuracy: 0.9576, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1421, Val accuracy: 0.9576, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopped on Update 1865 (Epoch 14))\n",
            "Best model found on Epoch 14 (Update 1764). Val accuracy: 0.9576490924805532\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1652, Val accuracy: 0.9685, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.155, Val accuracy: 0.9706, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.153, Val accuracy: 0.9693, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1524, Val accuracy: 0.9693, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1519, Val accuracy: 0.9706, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1498, Val accuracy: 0.9702, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1502, Val accuracy: 0.9706, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1504, Val accuracy: 0.9697, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1485, Val accuracy: 0.9697, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1478, Val accuracy: 0.9697, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1488, Val accuracy: 0.9702, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1463, Val accuracy: 0.9702, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1472, Val accuracy: 0.9693, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1473, Val accuracy: 0.9702, Best Epoch: 7\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1467, Val accuracy: 0.9697, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9706136560069144\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1644, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1547, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1514, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1506, Val accuracy: 0.9658, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1499, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1514, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1522, Val accuracy: 0.9658, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1496, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1483, Val accuracy: 0.9658, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1492, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1458, Val accuracy: 0.9663, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1455, Val accuracy: 0.9658, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1487, Val accuracy: 0.9658, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1433, Val accuracy: 0.9654, Best Epoch: 11\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1437, Val accuracy: 0.9654, Best Epoch: 11\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 11 (Update 1386). Val accuracy: 0.9662775616083009\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.167, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1528, Val accuracy: 0.9628, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1534, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1524, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1477, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1472, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1485, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1484, Val accuracy: 0.9624, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1474, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1458, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1452, Val accuracy: 0.9641, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1447, Val accuracy: 0.9628, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1458, Val accuracy: 0.9633, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1449, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.143, Val accuracy: 0.9646, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1448, Val accuracy: 0.9641, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9645635263612792\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1604, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1552, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1501, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1501, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1474, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.148, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1478, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1443, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1464, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1443, Val accuracy: 0.965, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1452, Val accuracy: 0.9646, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1455, Val accuracy: 0.965, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1428, Val accuracy: 0.9646, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1437, Val accuracy: 0.9646, Best Epoch: 12\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1418, Val accuracy: 0.965, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1422, Val accuracy: 0.965, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2135 (Epoch 16))\n",
            "Best model found on Epoch 16 (Update 2016). Val accuracy: 0.9649956784788245\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1665, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1544, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1498, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1499, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1486, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1475, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1481, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1467, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1481, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1454, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1473, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1451, Val accuracy: 0.9654, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1465, Val accuracy: 0.965, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1453, Val accuracy: 0.965, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1683, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1541, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1513, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1566, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1494, Val accuracy: 0.9659, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1492, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1501, Val accuracy: 0.9659, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1483, Val accuracy: 0.9659, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1516, Val accuracy: 0.9659, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.148, Val accuracy: 0.9659, Best Epoch: 10\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1442, Val accuracy: 0.965, Best Epoch: 10\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1463, Val accuracy: 0.965, Best Epoch: 10\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1437, Val accuracy: 0.9654, Best Epoch: 10\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1434, Val accuracy: 0.9654, Best Epoch: 10\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1436, Val accuracy: 0.9659, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 15 (Update 1890). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1627, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1519, Val accuracy: 0.9615, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1503, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1511, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1469, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1487, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1463, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1465, Val accuracy: 0.9615, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1441, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1437, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1459, Val accuracy: 0.9602, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1421, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1433, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1421, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1407, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.14, Val accuracy: 0.9611, Best Epoch: 3\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1399, Val accuracy: 0.9611, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9619706136560069\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(32, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1719, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1536, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1507, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1526, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1513, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1486, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1489, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1472, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.146, Val accuracy: 0.9633, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1452, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1461, Val accuracy: 0.9624, Best Epoch: 9\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1445, Val accuracy: 0.9628, Best Epoch: 9\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.9633, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1436, Val accuracy: 0.9633, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1424, Val accuracy: 0.9633, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1424, Val accuracy: 0.9633, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1429, Val accuracy: 0.9633, Best Epoch: 17\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1421, Val accuracy: 0.9633, Best Epoch: 18\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1421, Val accuracy: 0.9637, Best Epoch: 19\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1407, Val accuracy: 0.9633, Best Epoch: 19\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 20)\n",
            "Best model found on Epoch 19 (Update 2394). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1646, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1537, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1533, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1516, Val accuracy: 0.9663, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1514, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1496, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1484, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1476, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1473, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1479, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1464, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1481, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1467, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1476, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1467, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1466, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1466, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1454, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.143, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1428, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1408, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.1414, Val accuracy: 0.9659, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 22)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9662921348314607\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1651, Val accuracy: 0.9645, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1536, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1501, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1509, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1477, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1481, Val accuracy: 0.9645, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1481, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.146, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1454, Val accuracy: 0.9645, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1462, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1439, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1444, Val accuracy: 0.9641, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.9654, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1426, Val accuracy: 0.9641, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1417, Val accuracy: 0.9645, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1427, Val accuracy: 0.9658, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1417, Val accuracy: 0.9654, Best Epoch: 16\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1415, Val accuracy: 0.9654, Best Epoch: 16\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1389, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1394, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1393, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.1397, Val accuracy: 0.9645, Best Epoch: 16\n",
            "Epoch 23 (Update 2898).\tTrain loss: 0.1389, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 24 (Update 3024).\tTrain loss: 0.1391, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 25 (Update 3150).\tTrain loss: 0.1376, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 26 (Update 3276).\tTrain loss: 0.137, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 27 (Update 3402).\tTrain loss: 0.1377, Val accuracy: 0.9641, Best Epoch: 16\n",
            "Epoch 28 (Update 3528).\tTrain loss: 0.1357, Val accuracy: 0.9641, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 28)\n",
            "Best model found on Epoch 16 (Update 2016). Val accuracy: 0.9658452226545612\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_BAG_L4 model HPO: 164.4847812652588\n",
            "Best hyperparameter configuration for NeuralNetTorch_BAG_L4 model: \n",
            "{'num_epochs': 300, 'epochs_wo_improve': None, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.01, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L4/T1 ...\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t164.36s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "\t135.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_2_BAG_L4 ... Tuning model for up to 173.63s of the 1578.19s of remaining time.\n",
            "\tFitting NeuralNetTorch_2_BAG_L4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_2_BAG_L4 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_2_BAG_L4: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3899a8dffd64393b29adf3cbd252f9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1609, Val accuracy: 0.9706, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1498, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1522, Val accuracy: 0.971, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1497, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1508, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1494, Val accuracy: 0.9697, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1484, Val accuracy: 0.9689, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1501, Val accuracy: 0.9697, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1477, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1495, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.15, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.149, Val accuracy: 0.9697, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1484, Val accuracy: 0.9702, Best Epoch: 3\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1498, Val accuracy: 0.9697, Best Epoch: 3\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9710458081244598\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1586, Val accuracy: 0.9663, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1483, Val accuracy: 0.9667, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1486, Val accuracy: 0.9663, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1505, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1466, Val accuracy: 0.9667, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1447, Val accuracy: 0.9667, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1458, Val accuracy: 0.9667, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.148, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1459, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1456, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1468, Val accuracy: 0.9663, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.145, Val accuracy: 0.9659, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.144, Val accuracy: 0.9646, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1468, Val accuracy: 0.9654, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.966724286949006\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1551, Val accuracy: 0.9564, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1427, Val accuracy: 0.9559, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1433, Val accuracy: 0.9559, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1425, Val accuracy: 0.9559, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1423, Val accuracy: 0.9564, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1428, Val accuracy: 0.9559, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1414, Val accuracy: 0.9555, Best Epoch: 5\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1416, Val accuracy: 0.9559, Best Epoch: 5\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1407, Val accuracy: 0.9559, Best Epoch: 5\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1416, Val accuracy: 0.9555, Best Epoch: 5\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.141, Val accuracy: 0.9555, Best Epoch: 5\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1394, Val accuracy: 0.9555, Best Epoch: 5\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1404, Val accuracy: 0.9555, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 13)\n",
            "Best model found on Epoch 5 (Update 630). Val accuracy: 0.956352636127917\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1586, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1472, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1475, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1479, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1455, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1455, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1472, Val accuracy: 0.9633, Best Epoch: 2\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1469, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1455, Val accuracy: 0.9637, Best Epoch: 2\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1441, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1461, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1428, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1437, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1444, Val accuracy: 0.9637, Best Epoch: 2\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 2 (Update 252). Val accuracy: 0.9645635263612792\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1571, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1492, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1474, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1473, Val accuracy: 0.9646, Best Epoch: 2\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1463, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1478, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1488, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1474, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1465, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1449, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1461, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1443, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1461, Val accuracy: 0.9654, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1438, Val accuracy: 0.965, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1536, Val accuracy: 0.9572, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1452, Val accuracy: 0.9568, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1444, Val accuracy: 0.9572, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1443, Val accuracy: 0.9568, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1446, Val accuracy: 0.9568, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.143, Val accuracy: 0.9572, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1447, Val accuracy: 0.9568, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1436, Val accuracy: 0.9576, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1415, Val accuracy: 0.9572, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1426, Val accuracy: 0.9568, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1426, Val accuracy: 0.9572, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1421, Val accuracy: 0.9572, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 12)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9576490924805532\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1584, Val accuracy: 0.9689, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1498, Val accuracy: 0.9697, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.149, Val accuracy: 0.9693, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1479, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1503, Val accuracy: 0.9693, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1487, Val accuracy: 0.9702, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1483, Val accuracy: 0.9689, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1482, Val accuracy: 0.9706, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1475, Val accuracy: 0.9697, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1476, Val accuracy: 0.9663, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1491, Val accuracy: 0.9697, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.146, Val accuracy: 0.9706, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1462, Val accuracy: 0.9706, Best Epoch: 13\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1468, Val accuracy: 0.9693, Best Epoch: 13\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1474, Val accuracy: 0.9693, Best Epoch: 13\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1462, Val accuracy: 0.9697, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
            "Best model found on Epoch 13 (Update 1638). Val accuracy: 0.9706136560069144\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1572, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1495, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1467, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1485, Val accuracy: 0.9658, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1478, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1484, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1479, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1479, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.146, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1491, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1457, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1468, Val accuracy: 0.9667, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1467, Val accuracy: 0.9658, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1454, Val accuracy: 0.9663, Best Epoch: 12\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1461, Val accuracy: 0.9654, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 12 (Update 1512). Val accuracy: 0.9667099005620406\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1607, Val accuracy: 0.9633, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1466, Val accuracy: 0.9633, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1484, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1471, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1471, Val accuracy: 0.9628, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1446, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1471, Val accuracy: 0.9637, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1467, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1465, Val accuracy: 0.9628, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1452, Val accuracy: 0.9633, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1452, Val accuracy: 0.9637, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1464, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1456, Val accuracy: 0.9628, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1452, Val accuracy: 0.9633, Best Epoch: 11\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 11 (Update 1386). Val accuracy: 0.9636992221261884\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1552, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1473, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1461, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1464, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1457, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1461, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1453, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1446, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1471, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1453, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1461, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1449, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1458, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1478, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1446, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1456, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1437, Val accuracy: 0.965, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 7 (Update 882). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1581, Val accuracy: 0.9646, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1482, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1471, Val accuracy: 0.9641, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1482, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1458, Val accuracy: 0.9646, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1463, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1466, Val accuracy: 0.9646, Best Epoch: 6\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1474, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1471, Val accuracy: 0.9646, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1467, Val accuracy: 0.9646, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1457, Val accuracy: 0.9641, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1453, Val accuracy: 0.9654, Best Epoch: 12\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.147, Val accuracy: 0.965, Best Epoch: 12\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1458, Val accuracy: 0.9654, Best Epoch: 14\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1464, Val accuracy: 0.9654, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1433, Val accuracy: 0.9654, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1453, Val accuracy: 0.9654, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 17 (Update 2142). Val accuracy: 0.9654278305963699\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(53, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1588, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1479, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1476, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1499, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1467, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1476, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1491, Val accuracy: 0.9659, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1461, Val accuracy: 0.9659, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1483, Val accuracy: 0.9659, Best Epoch: 9\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1472, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1453, Val accuracy: 0.9659, Best Epoch: 11\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1469, Val accuracy: 0.9654, Best Epoch: 11\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1456, Val accuracy: 0.9654, Best Epoch: 11\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1467, Val accuracy: 0.9654, Best Epoch: 11\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.145, Val accuracy: 0.9659, Best Epoch: 15\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1443, Val accuracy: 0.9659, Best Epoch: 16\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1445, Val accuracy: 0.9659, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 17 (Update 2142). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1549, Val accuracy: 0.9615, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.146, Val accuracy: 0.9611, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1467, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1449, Val accuracy: 0.9611, Best Epoch: 1\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1442, Val accuracy: 0.9607, Best Epoch: 1\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1462, Val accuracy: 0.9615, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1442, Val accuracy: 0.9615, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1459, Val accuracy: 0.9615, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1436, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1452, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1429, Val accuracy: 0.9607, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1421, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1444, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1425, Val accuracy: 0.9602, Best Epoch: 8\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.144, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1425, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1427, Val accuracy: 0.9611, Best Epoch: 8\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1426, Val accuracy: 0.9594, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 8 (Update 1008). Val accuracy: 0.9615384615384616\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(32, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1595, Val accuracy: 0.9628, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1468, Val accuracy: 0.9628, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1462, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.146, Val accuracy: 0.9633, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1475, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1484, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1473, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1436, Val accuracy: 0.9615, Best Epoch: 4\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1456, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1447, Val accuracy: 0.9615, Best Epoch: 4\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1448, Val accuracy: 0.962, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "Best model found on Epoch 4 (Update 504). Val accuracy: 0.9632670700086431\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16197 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1585, Val accuracy: 0.9659, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.149, Val accuracy: 0.9659, Best Epoch: 2\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1478, Val accuracy: 0.9659, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1482, Val accuracy: 0.9659, Best Epoch: 4\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1485, Val accuracy: 0.9659, Best Epoch: 5\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1478, Val accuracy: 0.9659, Best Epoch: 6\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1469, Val accuracy: 0.9659, Best Epoch: 7\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.147, Val accuracy: 0.9659, Best Epoch: 8\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1466, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1471, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1462, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1462, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1454, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1473, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1469, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1463, Val accuracy: 0.965, Best Epoch: 8\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.147, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1453, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1459, Val accuracy: 0.9659, Best Epoch: 19\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.1463, Val accuracy: 0.9659, Best Epoch: 20\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1447, Val accuracy: 0.9654, Best Epoch: 20\n",
            "Best model found on Epoch 20 (Update 2520). Val accuracy: 0.9658599827139153\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"XGBoost_BAG_L3\",\n",
            "        \"XGBoost_2_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T1\",\n",
            "        \"LinearModel_BAG_L3/T2\",\n",
            "        \"LinearModel_2_BAG_L3/T1\",\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"RandomForest_BAG_L3\",\n",
            "        \"RandomForest_2_BAG_L3\",\n",
            "        \"LinearModel_BAG_L3/T3\",\n",
            "        \"LinearModel_BAG_L3/T4\",\n",
            "        \"NeuralNetTorch_BAG_L3/T1\",\n",
            "        \"NeuralNetTorch_2_BAG_L3/T1\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 16198 examples, 24 features (22 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(54, 14)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=47, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 126).\tTrain loss: 0.1571, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 252).\tTrain loss: 0.1484, Val accuracy: 0.9641, Best Epoch: 1\n",
            "Epoch 3 (Update 378).\tTrain loss: 0.1468, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 504).\tTrain loss: 0.1476, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 5 (Update 630).\tTrain loss: 0.1458, Val accuracy: 0.9645, Best Epoch: 3\n",
            "Epoch 6 (Update 756).\tTrain loss: 0.1464, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 7 (Update 882).\tTrain loss: 0.1455, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 8 (Update 1008).\tTrain loss: 0.1454, Val accuracy: 0.9645, Best Epoch: 3\n",
            "Epoch 9 (Update 1134).\tTrain loss: 0.1452, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 10 (Update 1260).\tTrain loss: 0.1447, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 11 (Update 1386).\tTrain loss: 0.1444, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 12 (Update 1512).\tTrain loss: 0.1446, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 13 (Update 1638).\tTrain loss: 0.1451, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 14 (Update 1764).\tTrain loss: 0.1445, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 15 (Update 1890).\tTrain loss: 0.1444, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 16 (Update 2016).\tTrain loss: 0.1463, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 17 (Update 2142).\tTrain loss: 0.1448, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 18 (Update 2268).\tTrain loss: 0.1446, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 19 (Update 2394).\tTrain loss: 0.1432, Val accuracy: 0.9641, Best Epoch: 3\n",
            "Epoch 20 (Update 2520).\tTrain loss: 0.144, Val accuracy: 0.9633, Best Epoch: 3\n",
            "Epoch 21 (Update 2646).\tTrain loss: 0.1447, Val accuracy: 0.9637, Best Epoch: 3\n",
            "Epoch 22 (Update 2772).\tTrain loss: 0.144, Val accuracy: 0.9628, Best Epoch: 3\n",
            "Epoch 23 (Update 2898).\tTrain loss: 0.1431, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 24 (Update 3024).\tTrain loss: 0.1437, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Best model found on Epoch 3 (Update 378). Val accuracy: 0.9654128837008215\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_2_BAG_L4 model HPO: 162.03231835365295\n",
            "Best hyperparameter configuration for NeuralNetTorch_2_BAG_L4 model: \n",
            "{'num_epochs': 500, 'epochs_wo_improve': None, 'activation': 'tanh', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3, 'optimizer': 'adam', 'learning_rate': 0.005, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L4/T1 ...\n",
            "\t0.9645\t = Validation score   (accuracy)\n",
            "\t161.94s\t = Training   runtime\n",
            "\t1.39s\t = Validation runtime\n",
            "\t134.1\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L5: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.00s of the 1415.94s of remaining time.\n",
            "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
            "Ensemble size: 6\n",
            "Ensemble weights: \n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.16666667 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.16666667\n",
            " 0.66666667 0.         0.         0.         0.        ]\n",
            "\t0.09s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/model.pkl\n",
            "\tEnsemble Weights: {'RandomForest_BAG_L4': 0.667, 'LinearModel_BAG_L2/T3': 0.167, 'NeuralNetTorch_BAG_L3/T1': 0.167}\n",
            "\t0.9649\t = Validation score   (accuracy)\n",
            "\t1.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t145.0\t = Inference  throughput (rows/s | 2314 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 2185.2s ... Best model: WeightedEnsemble_L5 | Estimated inference throughput: 145.0 rows/s (2314 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/utils/oof.pkl\n",
            "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
            "\tthreshold: 0.500\t| val: 0.9649\t| NEW BEST\n",
            "\tthreshold: 0.480\t| val: 0.9648\n",
            "\tthreshold: 0.520\t| val: 0.9647\n",
            "\tthreshold: 0.460\t| val: 0.9647\n",
            "\tthreshold: 0.540\t| val: 0.9647\n",
            "\tthreshold: 0.440\t| val: 0.9647\n",
            "\tthreshold: 0.560\t| val: 0.9647\n",
            "\tthreshold: 0.420\t| val: 0.9645\n",
            "\tthreshold: 0.580\t| val: 0.9648\n",
            "\tthreshold: 0.400\t| val: 0.9645\n",
            "\tthreshold: 0.600\t| val: 0.9648\n",
            "\tthreshold: 0.380\t| val: 0.9646\n",
            "\tthreshold: 0.620\t| val: 0.9648\n",
            "\tthreshold: 0.360\t| val: 0.9645\n",
            "\tthreshold: 0.640\t| val: 0.9645\n",
            "\tthreshold: 0.340\t| val: 0.9643\n",
            "\tthreshold: 0.660\t| val: 0.9642\n",
            "\tthreshold: 0.320\t| val: 0.9641\n",
            "\tthreshold: 0.680\t| val: 0.9640\n",
            "\tthreshold: 0.300\t| val: 0.9640\n",
            "\tthreshold: 0.700\t| val: 0.9639\n",
            "\tthreshold: 0.280\t| val: 0.9641\n",
            "\tthreshold: 0.720\t| val: 0.9636\n",
            "\tthreshold: 0.260\t| val: 0.9639\n",
            "\tthreshold: 0.740\t| val: 0.9635\n",
            "\tthreshold: 0.240\t| val: 0.9637\n",
            "\tthreshold: 0.760\t| val: 0.9632\n",
            "\tthreshold: 0.220\t| val: 0.9635\n",
            "\tthreshold: 0.780\t| val: 0.9629\n",
            "\tthreshold: 0.200\t| val: 0.9631\n",
            "\tthreshold: 0.800\t| val: 0.9625\n",
            "\tthreshold: 0.180\t| val: 0.9627\n",
            "\tthreshold: 0.820\t| val: 0.9614\n",
            "\tthreshold: 0.160\t| val: 0.9619\n",
            "\tthreshold: 0.840\t| val: 0.9594\n",
            "\tthreshold: 0.140\t| val: 0.9603\n",
            "\tthreshold: 0.860\t| val: 0.9566\n",
            "\tthreshold: 0.120\t| val: 0.9578\n",
            "\tthreshold: 0.880\t| val: 0.9520\n",
            "\tthreshold: 0.100\t| val: 0.9484\n",
            "\tthreshold: 0.900\t| val: 0.9426\n",
            "\tthreshold: 0.080\t| val: 0.9243\n",
            "\tthreshold: 0.920\t| val: 0.9249\n",
            "\tthreshold: 0.060\t| val: 0.8671\n",
            "\tthreshold: 0.940\t| val: 0.8938\n",
            "\tthreshold: 0.040\t| val: 0.7499\n",
            "\tthreshold: 0.960\t| val: 0.8425\n",
            "\tthreshold: 0.020\t| val: 0.5325\n",
            "\tthreshold: 0.980\t| val: 0.7750\n",
            "\tthreshold: 0.000\t| val: 0.2746\n",
            "\tthreshold: 1.000\t| val: 0.7254\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tthreshold: 0.501\t| val: 0.9649\n",
            "\tthreshold: 0.502\t| val: 0.9649\n",
            "\tthreshold: 0.503\t| val: 0.9649\n",
            "\tthreshold: 0.504\t| val: 0.9649\n",
            "\tthreshold: 0.505\t| val: 0.9649\n",
            "\tthreshold: 0.506\t| val: 0.9649\n",
            "\tthreshold: 0.507\t| val: 0.9649\n",
            "\tthreshold: 0.508\t| val: 0.9649\n",
            "\tthreshold: 0.509\t| val: 0.9649\n",
            "\tthreshold: 0.510\t| val: 0.9649\n",
            "\tthreshold: 0.511\t| val: 0.9649\n",
            "\tthreshold: 0.512\t| val: 0.9649\n",
            "\tthreshold: 0.513\t| val: 0.9649\n",
            "\tthreshold: 0.514\t| val: 0.9649\n",
            "\tthreshold: 0.515\t| val: 0.9649\n",
            "\tthreshold: 0.516\t| val: 0.9648\n",
            "\tthreshold: 0.517\t| val: 0.9648\n",
            "\tthreshold: 0.518\t| val: 0.9647\n",
            "\tthreshold: 0.519\t| val: 0.9647\n",
            "\tthreshold: 0.499\t| val: 0.9649\n",
            "\tthreshold: 0.498\t| val: 0.9649\n",
            "\tthreshold: 0.497\t| val: 0.9649\n",
            "\tthreshold: 0.496\t| val: 0.9648\n",
            "\tthreshold: 0.495\t| val: 0.9648\n",
            "\tthreshold: 0.494\t| val: 0.9648\n",
            "\tthreshold: 0.493\t| val: 0.9648\n",
            "\tthreshold: 0.492\t| val: 0.9648\n",
            "\tthreshold: 0.491\t| val: 0.9648\n",
            "\tthreshold: 0.490\t| val: 0.9648\n",
            "\tthreshold: 0.489\t| val: 0.9648\n",
            "\tthreshold: 0.488\t| val: 0.9648\n",
            "\tthreshold: 0.487\t| val: 0.9648\n",
            "\tthreshold: 0.486\t| val: 0.9648\n",
            "\tthreshold: 0.485\t| val: 0.9648\n",
            "\tthreshold: 0.484\t| val: 0.9648\n",
            "\tthreshold: 0.483\t| val: 0.9648\n",
            "\tthreshold: 0.482\t| val: 0.9648\n",
            "\tthreshold: 0.481\t| val: 0.9648\n",
            "\tBase Threshold: 0.500\t| val: 0.9649\n",
            "\tBest Threshold: 0.500\t| val: 0.9649\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.3.1\"\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho\")\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/KNeighbors_3_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L1/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L1/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L1/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L2/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L2/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L2/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L2/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L3/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L3/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L3/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L3/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/RandomForest_2_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/XGBoost_2_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_BAG_L4/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_2_BAG_L4/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/LinearModel_3_BAG_L4/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_2_BAG_L4/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L5/model.pkl\n",
            "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                         model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0          XGBoost_2_BAG_L4/T1       0.961971   0.964292    accuracy       19.642513      24.558087  1320.471983                 0.557135                0.247814          79.307652            4       True         64\n",
            "1     NeuralNetTorch_BAG_L1/T1       0.961538   0.964562    accuracy        0.705072       0.576422    70.004988                 0.705072                0.576422          70.004988            1       True         20\n",
            "2   NeuralNetTorch_2_BAG_L1/T1       0.961538   0.964616    accuracy        0.770798       0.654492    70.237494                 0.770798                0.654492          70.237494            1       True         21\n",
            "3          WeightedEnsemble_L2       0.961538   0.964616    accuracy        0.782306       0.657197    70.777529                 0.011508                0.002705           0.540035            2       True         22\n",
            "4          XGBoost_2_BAG_L2/T1       0.961538   0.964292    accuracy        8.245047       9.070275   386.026010                 0.663425                0.342677          90.991945            2       True         26\n",
            "5          WeightedEnsemble_L5       0.961538   0.964940    accuracy       19.312969      25.082335  1260.409896                 0.013181                0.003467           1.072590            5       True         80\n",
            "6        RandomForest_2_BAG_L4       0.961538   0.964616    accuracy       19.464607      25.731280  1272.893133                 0.379228                1.421006          31.728802            4       True         62\n",
            "7        LinearModel_BAG_L1/T1       0.961106   0.963859    accuracy        0.435820       0.390406     3.675186                 0.435820                0.390406           3.675186            1       True          8\n",
            "8        LinearModel_BAG_L1/T2       0.961106   0.963859    accuracy        0.461486       0.400366     3.617026                 0.461486                0.400366           3.617026            1       True          9\n",
            "9      LinearModel_2_BAG_L2/T4       0.961106   0.964508    accuracy        7.846730       9.047099   303.432002                 0.265108                0.319501           8.397937            2       True         34\n",
            "10     LinearModel_2_BAG_L2/T3       0.961106   0.964508    accuracy        7.848924       9.086776   304.018999                 0.267303                0.359178           8.984934            2       True         33\n",
            "11       LinearModel_BAG_L2/T4       0.961106   0.964508    accuracy        7.855775       9.101962   300.823542                 0.274153                0.374364           5.789477            2       True         30\n",
            "12     LinearModel_3_BAG_L2/T3       0.961106   0.964346    accuracy        7.864381       9.053939   308.097564                 0.282759                0.326341          13.063498            2       True         37\n",
            "13       LinearModel_BAG_L2/T3       0.961106   0.964508    accuracy        7.868527       9.047626   300.386927                 0.286905                0.320028           5.352862            2       True         29\n",
            "14     LinearModel_3_BAG_L2/T4       0.961106   0.964346    accuracy        7.889911       9.073767   308.034155                 0.308289                0.346169          13.000089            2       True         38\n",
            "15              XGBoost_BAG_L2       0.961106   0.964183    accuracy        7.945483       8.935185   345.912291                 0.363862                0.207587          50.878226            2       True         25\n",
            "16         RandomForest_BAG_L2       0.961106   0.964183    accuracy        7.992460       9.499178   315.513417                 0.410838                0.771580          20.479352            2       True         23\n",
            "17       LinearModel_BAG_L2/T2       0.961106   0.964237    accuracy        8.189302       9.658598   303.867844                 0.607681                0.931000           8.833779            2       True         28\n",
            "18       RandomForest_2_BAG_L2       0.961106   0.964237    accuracy        8.243375      10.075926   323.356252                 0.661753                1.348328          28.322186            2       True         24\n",
            "19       LinearModel_BAG_L2/T1       0.961106   0.964237    accuracy        8.247744       9.655325   304.120375                 0.666123                0.927728           9.086310            2       True         27\n",
            "20    NeuralNetTorch_BAG_L2/T1       0.961106   0.964616    accuracy        8.321636       9.936997   405.603194                 0.740014                1.209400         110.569129            2       True         39\n",
            "21  NeuralNetTorch_2_BAG_L2/T1       0.961106   0.964400    accuracy        8.345369      10.398539   405.770840                 0.763748                1.670941         110.736775            2       True         40\n",
            "22         WeightedEnsemble_L3       0.961106   0.964724    accuracy        8.692239      10.147547   456.886937                 0.006741                0.002962           0.405517            3       True         41\n",
            "23              XGBoost_BAG_L3       0.961106   0.964508    accuracy       12.899857      16.186086   796.876864                 0.338367                0.208562          48.276479            3       True         44\n",
            "24         XGBoost_2_BAG_L3/T1       0.961106   0.964562    accuracy       13.208513      16.385802   838.447995                 0.647023                0.408278          89.847610            3       True         45\n",
            "25     LinearModel_2_BAG_L3/T1       0.961106   0.964021    accuracy       13.313175      16.831251   762.689560                 0.751685                0.853727          14.089176            3       True         50\n",
            "26  NeuralNetTorch_2_BAG_L3/T1       0.961106   0.964508    accuracy       13.316542      17.126026   884.172817                 0.755052                1.148502         135.572432            3       True         59\n",
            "27     LinearModel_2_BAG_L3/T2       0.961106   0.964021    accuracy       13.330669      16.745640   758.409625                 0.769179                0.768116           9.809240            3       True         51\n",
            "28    NeuralNetTorch_BAG_L3/T1       0.961106   0.964616    accuracy       13.870313      16.991054   881.150437                 1.308823                1.013530         132.550053            3       True         58\n",
            "29         WeightedEnsemble_L4       0.961106   0.964670    accuracy       14.272904      18.391965   911.071901                 0.005685                0.003214           0.428169            4       True         60\n",
            "30       LinearModel_BAG_L4/T3       0.961106   0.964129    accuracy       19.364918      24.659655  1246.751364                 0.279539                0.349382           5.587033            4       True         68\n",
            "31       LinearModel_BAG_L4/T4       0.961106   0.964129    accuracy       19.367322      24.612415  1246.056612                 0.281944                0.302142           4.892281            4       True         69\n",
            "32              XGBoost_BAG_L4       0.961106   0.964400    accuracy       19.423430      24.568912  1297.091982                 0.338052                0.258639          55.927651            4       True         63\n",
            "33     LinearModel_3_BAG_L4/T4       0.961106   0.963967    accuracy       19.509792      24.770462  1257.956442                 0.424414                0.460188          16.792112            4       True         77\n",
            "34     LinearModel_3_BAG_L4/T3       0.961106   0.963967    accuracy       19.530335      24.622140  1253.162924                 0.444957                0.311867          11.998593            4       True         76\n",
            "35       LinearModel_BAG_L4/T2       0.961106   0.964075    accuracy       19.547022      24.944884  1247.269771                 0.461644                0.634611           6.105440            4       True         67\n",
            "36     LinearModel_2_BAG_L4/T1       0.961106   0.964075    accuracy       19.550113      25.022796  1254.917666                 0.464735                0.712522          13.753335            4       True         70\n",
            "37     LinearModel_3_BAG_L4/T1       0.961106   0.964129    accuracy       19.551728      24.995162  1256.284380                 0.466350                0.684889          15.120049            4       True         74\n",
            "38     LinearModel_2_BAG_L4/T2       0.961106   0.964075    accuracy       19.554853      25.017998  1251.162731                 0.469475                0.707724           9.998400            4       True         71\n",
            "39       LinearModel_BAG_L4/T1       0.961106   0.964075    accuracy       19.568467      25.061575  1248.508148                 0.483089                0.751301           7.343817            4       True         66\n",
            "40     LinearModel_3_BAG_L4/T2       0.961106   0.964129    accuracy       19.619766      25.118249  1257.173560                 0.534388                0.807976          16.009229            4       True         75\n",
            "41    NeuralNetTorch_BAG_L4/T1       0.961106   0.964616    accuracy       19.949556      25.574236  1405.523058                 0.864178                1.263963         164.358728            4       True         78\n",
            "42  NeuralNetTorch_2_BAG_L4/T1       0.961106   0.964508    accuracy       20.075357      25.699833  1403.106234                 0.989979                1.389560         161.941903            4       True         79\n",
            "43       LinearModel_BAG_L1/T4       0.960674   0.963859    accuracy        0.274683       0.274571     3.048543                 0.274683                0.274571           3.048543            1       True         11\n",
            "44       LinearModel_BAG_L1/T3       0.960674   0.963859    accuracy        0.315378       0.338503     3.944415                 0.315378                0.338503           3.944415            1       True         10\n",
            "45              XGBoost_BAG_L1       0.960674   0.964292    accuracy        0.574506       0.257758    41.921303                 0.574506                0.257758          41.921303            1       True          6\n",
            "46         XGBoost_2_BAG_L1/T1       0.960674   0.963967    accuracy        0.998021       0.388378    51.846009                 0.998021                0.388378          51.846009            1       True          7\n",
            "47     LinearModel_2_BAG_L2/T1       0.960674   0.964075    accuracy        8.165847       9.685310   313.133695                 0.584226                0.957712          18.099630            2       True         31\n",
            "48     LinearModel_2_BAG_L2/T2       0.960674   0.963967    accuracy        8.174865       9.634541   309.352657                 0.593243                0.906944          14.318592            2       True         32\n",
            "49     LinearModel_2_BAG_L3/T4       0.960674   0.964021    accuracy       12.861917      16.315466   756.827992                 0.300427                0.337942           8.227607            3       True         53\n",
            "50       LinearModel_BAG_L3/T3       0.960674   0.964183    accuracy       12.930307      16.281417   753.466690                 0.368817                0.303893           4.866305            3       True         48\n",
            "51     LinearModel_2_BAG_L3/T3       0.960674   0.964021    accuracy       12.937424      16.300799   757.026431                 0.375934                0.323275           8.426047            3       True         52\n",
            "52       LinearModel_BAG_L3/T4       0.960674   0.964183    accuracy       12.981063      16.332512   754.253750                 0.419573                0.354988           5.653365            3       True         49\n",
            "53       LinearModel_BAG_L3/T1       0.960674   0.964237    accuracy       13.097724      16.740023   755.178206                 0.536234                0.762499           6.577821            3       True         46\n",
            "54       LinearModel_BAG_L3/T2       0.960674   0.964237    accuracy       13.335672      16.792021   755.915801                 0.774182                0.814497           7.315416            3       True         47\n",
            "55         RandomForest_BAG_L4       0.960674   0.964832    accuracy       19.299788      25.078868  1259.337306                 0.214409                0.768595          18.172975            4       True         61\n",
            "56     LinearModel_2_BAG_L4/T4       0.960674   0.963967    accuracy       19.340841      24.633404  1249.524921                 0.255463                0.323131           8.360590            4       True         73\n",
            "57     LinearModel_2_BAG_L4/T3       0.960674   0.963967    accuracy       19.386966      24.639481  1249.403609                 0.301588                0.329207           8.239278            4       True         72\n",
            "58         XGBoost_2_BAG_L4/T2       0.960674   0.964724    accuracy       19.588680      24.639183  1304.043712                 0.503302                0.328910          62.879382            4       True         65\n",
            "59     LinearModel_3_BAG_L1/T1       0.960242   0.963913    accuracy        0.310197       0.405254     6.409419                 0.310197                0.405254           6.409419            1       True         16\n",
            "60     LinearModel_2_BAG_L1/T1       0.960242   0.963967    accuracy        0.313630       0.488503    11.196249                 0.313630                0.488503          11.196249            1       True         12\n",
            "61     LinearModel_3_BAG_L1/T2       0.960242   0.963913    accuracy        0.334766       0.478003     7.321459                 0.334766                0.478003           7.321459            1       True         17\n",
            "62     LinearModel_2_BAG_L1/T2       0.960242   0.964021    accuracy        0.338369       0.488155     7.642685                 0.338369                0.488155           7.642685            1       True         13\n",
            "63     LinearModel_3_BAG_L2/T1       0.960242   0.963805    accuracy        8.151740       9.619988   314.112332                 0.570118                0.892391          19.078267            2       True         35\n",
            "64     LinearModel_3_BAG_L2/T2       0.960242   0.963805    accuracy        8.167112       9.594792   313.382405                 0.585490                0.867195          18.348340            2       True         36\n",
            "65         RandomForest_BAG_L3       0.960242   0.964454    accuracy       12.788715      17.044100   766.922380                 0.227225                1.066576          18.321995            3       True         42\n",
            "66     LinearModel_3_BAG_L3/T3       0.960242   0.963859    accuracy       12.832032      16.308740   760.013828                 0.270542                0.331216          11.413443            3       True         56\n",
            "67     LinearModel_3_BAG_L3/T4       0.960242   0.963859    accuracy       12.841112      16.291174   760.218664                 0.279622                0.313650          11.618279            3       True         57\n",
            "68       RandomForest_2_BAG_L3       0.960242   0.964400    accuracy       12.958397      17.375221   778.093678                 0.396907                1.397697          29.493294            3       True         43\n",
            "69     LinearModel_3_BAG_L3/T1       0.960242   0.963643    accuracy       13.106755      16.780330   763.374567                 0.545264                0.802806          14.774182            3       True         54\n",
            "70     LinearModel_3_BAG_L3/T2       0.960242   0.963643    accuracy       13.115388      16.755131   763.234431                 0.553898                0.777607          14.634046            3       True         55\n",
            "71     LinearModel_2_BAG_L1/T4       0.959810   0.963913    accuracy        0.229761       0.352885     8.080004                 0.229761                0.352885           8.080004            1       True         15\n",
            "72     LinearModel_2_BAG_L1/T3       0.959810   0.963913    accuracy        0.235352       0.336267     7.160618                 0.235352                0.336267           7.160618            1       True         14\n",
            "73     LinearModel_3_BAG_L1/T4       0.959378   0.963913    accuracy        0.359482       0.314636     6.780876                 0.359482                0.314636           6.780876            1       True         19\n",
            "74     LinearModel_3_BAG_L1/T3       0.959378   0.963913    accuracy        0.381812       0.284032     6.044301                 0.381812                0.284032           6.044301            1       True         18\n",
            "75         RandomForest_BAG_L1       0.958081   0.959484    accuracy        0.885061       1.061110     6.868574                 0.885061                1.061110           6.868574            1       True          4\n",
            "76       RandomForest_2_BAG_L1       0.953328   0.952461    accuracy        1.515970       1.516075    11.126023                 1.515970                1.516075          11.126023            1       True          5\n",
            "77           KNeighbors_BAG_L1       0.948574   0.947707    accuracy        0.177714       0.466626     0.580944                 0.177714                0.466626           0.580944            1       True          1\n",
            "78         KNeighbors_3_BAG_L1       0.948142   0.948355    accuracy        0.245782       0.769991     0.865159                 0.245782                0.769991           0.865159            1       True          3\n",
            "79         KNeighbors_2_BAG_L1       0.948142   0.948355    accuracy        0.281389       0.965682     1.094598                 0.281389                0.965682           1.094598            1       True          2\n",
            "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
            "\t2224s\t = DyStack   runtime |\t12176s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=0.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/learner.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 12176s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250721_125522\"\n",
            "Train Data Rows:    20825\n",
            "Train Data Columns: 13\n",
            "Label Column:       Personality\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = Introvert, class 0 = Extrovert\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Introvert) vs negative (Extrovert) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9877.38 MB\n",
            "\tTrain Data (Original)  Memory Usage: 4.13 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('object', 'object') : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('object', []) : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t\t('object', [])    : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t11 features in original data used to generate 11 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('object', 'object') : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('object', []) : 4 | ['Stage_fear', 'Drained_after_socializing', 'Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t('float64', 'float')     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('int8', 'int')          : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 2 | ['Fear_Alone_Inter', 'Social_Fear_Ratio']\n",
            "\t\t('float', [])     : 9 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
            "\t0.3s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.51 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.39s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3}, {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
            "\t'RF': [{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt'}, {'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2'}],\n",
            "\t'CAT': [{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254}, {'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783]}],\n",
            "\t'LR': [{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear'}, {'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs'}, {'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear'}],\n",
            "\t'KNN': [{'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski'}, {'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan'}, {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}],\n",
            "\t'NN_TORCH': [{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2}, {'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3}],\n",
            "}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/utils/data/X.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/utils/data/y.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tKNeighbors_BAG_L1: \t{'n_neighbors': 7, 'weights': 'distance', 'metric': 'minkowski', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighbors_2_BAG_L1: \t{'n_neighbors': 12, 'weights': 'distance', 'metric': 'manhattan', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighbors_3_BAG_L1: \t{'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'valid_stacker': False, 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_BAG_L1: \t{'n_estimators': 300, 'max_depth': 20, 'class_weight': 'balanced', 'max_features': 'sqrt', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_2_BAG_L1: \t{'n_estimators': 500, 'max_depth': 25, 'class_weight': 'balanced', 'max_features': 'log2', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tCatBoost_2_BAG_L1: \t{'iterations': 1500, 'learning_rate': 0.02, 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_BAG_L1: \t{'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.05, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tXGBoost_2_BAG_L1: \t{'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.03, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_BAG_L1: \t{'class_weight': 'balanced', 'C': 0.1, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_2_BAG_L1: \t{'class_weight': 'balanced', 'C': 1, 'solver': 'lbfgs', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tLinearModel_3_BAG_L1: \t{'class_weight': 'balanced', 'C': 10, 'solver': 'liblinear', 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.lr.lr_model.LinearModel'>, 'priority': 30}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'num_epochs': 300, 'learning_rate': 0.01, 'activation': 'relu', 'dropout_prob': 0.2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "\tNeuralNetTorch_2_BAG_L1: \t{'num_epochs': 500, 'learning_rate': 0.005, 'activation': 'tanh', 'dropout_prob': 0.3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'hyperparameter_tune_kwargs': {'num_trials': 30, 'scheduler': 'local', 'searcher': 'auto'}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 0, 'verbosity': 3}}\n",
            "Fitting 14 L1 models, fit_strategy=\"sequential\" ...\n",
            "Hyperparameter tuning model: KNeighbors_BAG_L1 ... Tuning model for up to 782.72s of the 12175.66s of remaining time.\n",
            "\tFitting KNeighbors_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/utils/model_template.pkl\n",
            "\t0.03s \t= Train Time (Using 10000/20825 rows) (782.67s remaining time)\n",
            "\t0.05s \t= Train Time (Using 20825/20825 rows) (782.62s remaining time)\n",
            "\t2.4s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_BAG_L1 ...\n",
            "\t0.9467\t = Validation score   (accuracy)\n",
            "\t1.33s\t = Training   runtime\n",
            "\t1.15s\t = Validation runtime\n",
            "\t18118.5\t = Inference  throughput (rows/s | 20825 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: KNeighbors_2_BAG_L1 ... Tuning model for up to 782.72s of the 12174.27s of remaining time.\n",
            "\tFitting KNeighbors_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_2_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_2_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/utils/model_template.pkl\n",
            "\t0.04s \t= Train Time (Using 10000/20825 rows) (782.67s remaining time)\n",
            "\t0.06s \t= Train Time (Using 20825/20825 rows) (782.61s remaining time)\n",
            "\t2.84s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_2_BAG_L1 ...\n",
            "\t0.9472\t = Validation score   (accuracy)\n",
            "\t2.71s\t = Training   runtime\n",
            "\t2.51s\t = Validation runtime\n",
            "\t8287.9\t = Inference  throughput (rows/s | 20825 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: KNeighbors_3_BAG_L1 ... Tuning model for up to 782.72s of the 12171.49s of remaining time.\n",
            "\tFitting KNeighbors_3_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for KNeighbors_3_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for KNeighbors_3_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/utils/model_template.pkl\n",
            "\t0.04s \t= Train Time (Using 10000/20825 rows) (782.67s remaining time)\n",
            "\t0.07s \t= Train Time (Using 20825/20825 rows) (782.6s remaining time)\n",
            "\t3.0s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/model.pkl\n",
            "Fitted model: KNeighbors_3_BAG_L1 ...\n",
            "\t0.9475\t = Validation score   (accuracy)\n",
            "\t1.94s\t = Training   runtime\n",
            "\t1.73s\t = Validation runtime\n",
            "\t12040.6\t = Inference  throughput (rows/s | 20825 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_BAG_L1 ... Tuning model for up to 782.72s of the 12169.5s of remaining time.\n",
            "\tFitting RandomForest_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/utils/model_template.pkl\n",
            "\t5.91s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/model.pkl\n",
            "Fitted model: RandomForest_BAG_L1 ...\n",
            "\t0.9598\t = Validation score   (accuracy)\n",
            "\t10.4s\t = Training   runtime\n",
            "\t1.12s\t = Validation runtime\n",
            "\t18615.9\t = Inference  throughput (rows/s | 20825 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: RandomForest_2_BAG_L1 ... Tuning model for up to 782.72s of the 12159.06s of remaining time.\n",
            "\tFitting RandomForest_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for RandomForest_2_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for RandomForest_2_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/utils/model_template.pkl\n",
            "\t7.52s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/model.pkl\n",
            "Fitted model: RandomForest_2_BAG_L1 ...\n",
            "\t0.9521\t = Validation score   (accuracy)\n",
            "\t15.38s\t = Training   runtime\n",
            "\t1.76s\t = Validation runtime\n",
            "\t11856.4\t = Inference  throughput (rows/s | 20825 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 782.72s of the 12143.6s of remaining time.\n",
            "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_BAG_L1 model...\n",
            "\tHyperparameter search space for CatBoost_BAG_L1: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6a50d7cfa6045ad981bb3adc1f14703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_BAG_L1/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_BAG_L1 model HPO: 2.659534215927124\n",
            "Best hyperparameter configuration for CatBoost_BAG_L1 model: \n",
            "{'iterations': 1000, 'learning_rate': 0.03, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 10, 'class_weights': [1, 2.5533783783783783], 'border_count': 254, 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_BAG_L1... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: CatBoost_2_BAG_L1 ... Tuning model for up to 782.72s of the 12140.9s of remaining time.\n",
            "\tFitting CatBoost_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for CatBoost_2_BAG_L1 model...\n",
            "\tHyperparameter search space for CatBoost_2_BAG_L1: \n",
            "l2_leaf_reg:   Real: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2e0f17512a8476da619c4b1feb3b5fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T6/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T6/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T7/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T7/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T8/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T8/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T9/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T9/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T10/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T10/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T11/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T11/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T12/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T12/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T13/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T13/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T14/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T14/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T15/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T15/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T16/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T16/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T17/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T17/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T18/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T18/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T19/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T19/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T20/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T20/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T21/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T21/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T22/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T22/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T23/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T23/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T24/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T24/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T25/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T25/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T26/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T26/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T27/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T27/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T28/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T28/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T29/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T29/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T30/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/CatBoost_2_BAG_L1/T30/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 68, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
            "    model = fit_and_save_model(\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
            "    model.fit(**fit_args, time_limit=time_left)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
            "    fold_fitting_strategy.after_all_folds_scheduled()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 317, in after_all_folds_scheduled\n",
            "    self._fit_fold_model(job)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 322, in _fit_fold_model\n",
            "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 358, in _fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 124, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/common/utils/try_import.py\", line 77, in try_import_catboost\n",
            "    raise ImportError(\n",
            "ImportError: `import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.3.1`.\n",
            "Time for CatBoost_2_BAG_L1 model HPO: 2.5706446170806885\n",
            "Best hyperparameter configuration for CatBoost_2_BAG_L1 model: \n",
            "{'iterations': 1500, 'learning_rate': 0.02, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Accuracy', 'depth': 12, 'class_weights': [1, 2.5533783783783783], 'l2_leaf_reg': 3}\n",
            "No model was trained during hyperparameter tuning CatBoost_2_BAG_L1... Skipping this model.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 782.72s of the 12138.3s of remaining time.\n",
            "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_BAG_L1 model...\n",
            "\tNo hyperparameter search space specified for XGBoost_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03866\n",
            "[50]\tvalidation_0-error:0.03818\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03818\n",
            "[200]\tvalidation_0-error:0.03818\n",
            "[237]\tvalidation_0-error:0.03842\n",
            "[0]\tvalidation_0-error:0.03577\n",
            "[50]\tvalidation_0-error:0.03457\n",
            "[100]\tvalidation_0-error:0.03481\n",
            "[150]\tvalidation_0-error:0.03433\n",
            "[200]\tvalidation_0-error:0.03601\n",
            "[209]\tvalidation_0-error:0.03577\n",
            "[0]\tvalidation_0-error:0.03770\n",
            "[50]\tvalidation_0-error:0.03649\n",
            "[100]\tvalidation_0-error:0.03697\n",
            "[150]\tvalidation_0-error:0.03721\n",
            "[200]\tvalidation_0-error:0.03745\n",
            "[211]\tvalidation_0-error:0.03770\n",
            "[0]\tvalidation_0-error:0.03721\n",
            "[50]\tvalidation_0-error:0.03673\n",
            "[100]\tvalidation_0-error:0.03697\n",
            "[150]\tvalidation_0-error:0.03721\n",
            "[180]\tvalidation_0-error:0.03794\n",
            "[0]\tvalidation_0-error:0.03914\n",
            "[50]\tvalidation_0-error:0.03697\n",
            "[100]\tvalidation_0-error:0.03721\n",
            "[150]\tvalidation_0-error:0.03770\n",
            "[200]\tvalidation_0-error:0.03794\n",
            "[228]\tvalidation_0-error:0.03818\n",
            "[0]\tvalidation_0-error:0.03818\n",
            "[50]\tvalidation_0-error:0.03601\n",
            "[100]\tvalidation_0-error:0.03529\n",
            "[150]\tvalidation_0-error:0.03601\n",
            "[200]\tvalidation_0-error:0.03601\n",
            "[250]\tvalidation_0-error:0.03625\n",
            "[266]\tvalidation_0-error:0.03649\n",
            "[0]\tvalidation_0-error:0.03745\n",
            "[50]\tvalidation_0-error:0.03601\n",
            "[100]\tvalidation_0-error:0.03649\n",
            "[150]\tvalidation_0-error:0.03649\n",
            "[200]\tvalidation_0-error:0.03745\n",
            "[211]\tvalidation_0-error:0.03745\n",
            "[0]\tvalidation_0-error:0.03577\n",
            "[50]\tvalidation_0-error:0.03481\n",
            "[100]\tvalidation_0-error:0.03481\n",
            "[150]\tvalidation_0-error:0.03505\n",
            "[196]\tvalidation_0-error:0.03529\n",
            "[0]\tvalidation_0-error:0.03601\n",
            "[50]\tvalidation_0-error:0.03577\n",
            "[100]\tvalidation_0-error:0.03649\n",
            "[150]\tvalidation_0-error:0.03673\n",
            "[200]\tvalidation_0-error:0.03625\n",
            "[205]\tvalidation_0-error:0.03649\n",
            "[0]\tvalidation_0-error:0.03986\n",
            "[50]\tvalidation_0-error:0.04010\n",
            "[100]\tvalidation_0-error:0.03962\n",
            "[150]\tvalidation_0-error:0.04010\n",
            "[195]\tvalidation_0-error:0.04010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/model.pkl\n",
            "Fitted model: XGBoost_BAG_L1 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t52.46s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t12531.8\t = Inference  throughput (rows/s | 4165 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: XGBoost_2_BAG_L1 ... Tuning model for up to 782.72s of the 12085.79s of remaining time.\n",
            "\tFitting XGBoost_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for XGBoost_2_BAG_L1 model...\n",
            "\tHyperparameter search space for XGBoost_2_BAG_L1: \n",
            "min_child_weight:   Int: lower=1, upper=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3260b9ebec9b45f49d34c0a336702462"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03840\n",
            "[50]\tvalidation_0-error:0.03994\n",
            "[100]\tvalidation_0-error:0.03955\n",
            "[150]\tvalidation_0-error:0.03917\n",
            "[165]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03957\n",
            "[50]\tvalidation_0-error:0.03803\n",
            "[100]\tvalidation_0-error:0.03765\n",
            "[150]\tvalidation_0-error:0.03765\n",
            "[200]\tvalidation_0-error:0.03688\n",
            "[250]\tvalidation_0-error:0.03726\n",
            "[300]\tvalidation_0-error:0.03726\n",
            "[350]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.03189\n",
            "[50]\tvalidation_0-error:0.03035\n",
            "[100]\tvalidation_0-error:0.03035\n",
            "[150]\tvalidation_0-error:0.02997\n",
            "[200]\tvalidation_0-error:0.03035\n",
            "[250]\tvalidation_0-error:0.03073\n",
            "[296]\tvalidation_0-error:0.03150\n",
            "[0]\tvalidation_0-error:0.03611\n",
            "[50]\tvalidation_0-error:0.03496\n",
            "[100]\tvalidation_0-error:0.03496\n",
            "[150]\tvalidation_0-error:0.03496\n",
            "[200]\tvalidation_0-error:0.03458\n",
            "[250]\tvalidation_0-error:0.03573\n",
            "[283]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.04341\n",
            "[50]\tvalidation_0-error:0.04111\n",
            "[100]\tvalidation_0-error:0.04111\n",
            "[150]\tvalidation_0-error:0.04111\n",
            "[200]\tvalidation_0-error:0.04226\n",
            "[204]\tvalidation_0-error:0.04226\n",
            "[0]\tvalidation_0-error:0.03573\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03650\n",
            "[150]\tvalidation_0-error:0.03611\n",
            "[178]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.03803\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03842\n",
            "[178]\tvalidation_0-error:0.03803\n",
            "[0]\tvalidation_0-error:0.03688\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03650\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[177]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.03802\n",
            "[50]\tvalidation_0-error:0.03648\n",
            "[100]\tvalidation_0-error:0.03648\n",
            "[150]\tvalidation_0-error:0.03687\n",
            "[168]\tvalidation_0-error:0.03687\n",
            "[0]\tvalidation_0-error:0.03957\n",
            "[50]\tvalidation_0-error:0.03957\n",
            "[100]\tvalidation_0-error:0.03765\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[200]\tvalidation_0-error:0.03765\n",
            "[250]\tvalidation_0-error:0.03842\n",
            "[283]\tvalidation_0-error:0.03880\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03573\n",
            "[150]\tvalidation_0-error:0.03650\n",
            "[167]\tvalidation_0-error:0.03688\n",
            "[0]\tvalidation_0-error:0.03342\n",
            "[50]\tvalidation_0-error:0.03342\n",
            "[100]\tvalidation_0-error:0.03304\n",
            "[150]\tvalidation_0-error:0.03304\n",
            "[200]\tvalidation_0-error:0.03381\n",
            "[250]\tvalidation_0-error:0.03342\n",
            "[297]\tvalidation_0-error:0.03381\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03573\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[174]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.04034\n",
            "[50]\tvalidation_0-error:0.04034\n",
            "[100]\tvalidation_0-error:0.03995\n",
            "[150]\tvalidation_0-error:0.04034\n",
            "[166]\tvalidation_0-error:0.03995\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03765\n",
            "[150]\tvalidation_0-error:0.03650\n",
            "[165]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.04111\n",
            "[50]\tvalidation_0-error:0.03995\n",
            "[100]\tvalidation_0-error:0.03995\n",
            "[150]\tvalidation_0-error:0.03995\n",
            "[177]\tvalidation_0-error:0.03995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03840\n",
            "[50]\tvalidation_0-error:0.03917\n",
            "[100]\tvalidation_0-error:0.03917\n",
            "[150]\tvalidation_0-error:0.03955\n",
            "[166]\tvalidation_0-error:0.03955\n",
            "[0]\tvalidation_0-error:0.03842\n",
            "[50]\tvalidation_0-error:0.03688\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[190]\tvalidation_0-error:0.03688\n",
            "[0]\tvalidation_0-error:0.03112\n",
            "[50]\tvalidation_0-error:0.03073\n",
            "[100]\tvalidation_0-error:0.03073\n",
            "[150]\tvalidation_0-error:0.02997\n",
            "[200]\tvalidation_0-error:0.03035\n",
            "[250]\tvalidation_0-error:0.03073\n",
            "[269]\tvalidation_0-error:0.03073\n",
            "[0]\tvalidation_0-error:0.03458\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03573\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[164]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.04264\n",
            "[50]\tvalidation_0-error:0.04072\n",
            "[100]\tvalidation_0-error:0.04034\n",
            "[150]\tvalidation_0-error:0.04034\n",
            "[200]\tvalidation_0-error:0.04072\n",
            "[243]\tvalidation_0-error:0.04072\n",
            "[0]\tvalidation_0-error:0.03611\n",
            "[50]\tvalidation_0-error:0.03650\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[170]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.04149\n",
            "[50]\tvalidation_0-error:0.03650\n",
            "[100]\tvalidation_0-error:0.03726\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[200]\tvalidation_0-error:0.03688\n",
            "[0]\tvalidation_0-error:0.03688\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03611\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[200]\tvalidation_0-error:0.03534\n",
            "[250]\tvalidation_0-error:0.03534\n",
            "[300]\tvalidation_0-error:0.03611\n",
            "[320]\tvalidation_0-error:0.03611\n",
            "[0]\tvalidation_0-error:0.03725\n",
            "[50]\tvalidation_0-error:0.03610\n",
            "[100]\tvalidation_0-error:0.03648\n",
            "[150]\tvalidation_0-error:0.03648\n",
            "[173]\tvalidation_0-error:0.03648\n",
            "[0]\tvalidation_0-error:0.03842\n",
            "[50]\tvalidation_0-error:0.03957\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03880\n",
            "[164]\tvalidation_0-error:0.03842\n",
            "[0]\tvalidation_0-error:0.03496\n",
            "[50]\tvalidation_0-error:0.03458\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[175]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.03265\n",
            "[50]\tvalidation_0-error:0.03342\n",
            "[100]\tvalidation_0-error:0.03342\n",
            "[150]\tvalidation_0-error:0.03342\n",
            "[165]\tvalidation_0-error:0.03342\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[181]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.04034\n",
            "[50]\tvalidation_0-error:0.03842\n",
            "[100]\tvalidation_0-error:0.03880\n",
            "[150]\tvalidation_0-error:0.03880\n",
            "[168]\tvalidation_0-error:0.03957\n",
            "[0]\tvalidation_0-error:0.03765\n",
            "[50]\tvalidation_0-error:0.03880\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03803\n",
            "[166]\tvalidation_0-error:0.03803\n",
            "[0]\tvalidation_0-error:0.03957\n",
            "[50]\tvalidation_0-error:0.03880\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03842\n",
            "[200]\tvalidation_0-error:0.03880\n",
            "[217]\tvalidation_0-error:0.03880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03879\n",
            "[50]\tvalidation_0-error:0.03917\n",
            "[100]\tvalidation_0-error:0.03917\n",
            "[150]\tvalidation_0-error:0.03917\n",
            "[166]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03842\n",
            "[50]\tvalidation_0-error:0.03726\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[183]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.03035\n",
            "[50]\tvalidation_0-error:0.03035\n",
            "[100]\tvalidation_0-error:0.02997\n",
            "[150]\tvalidation_0-error:0.02997\n",
            "[196]\tvalidation_0-error:0.03035\n",
            "[0]\tvalidation_0-error:0.03496\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[165]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.04226\n",
            "[50]\tvalidation_0-error:0.04111\n",
            "[100]\tvalidation_0-error:0.04072\n",
            "[150]\tvalidation_0-error:0.04072\n",
            "[200]\tvalidation_0-error:0.04072\n",
            "[242]\tvalidation_0-error:0.04072\n",
            "[0]\tvalidation_0-error:0.03573\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03650\n",
            "[150]\tvalidation_0-error:0.03650\n",
            "[165]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.03995\n",
            "[50]\tvalidation_0-error:0.03726\n",
            "[100]\tvalidation_0-error:0.03726\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[200]\tvalidation_0-error:0.03688\n",
            "[225]\tvalidation_0-error:0.03765\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03611\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[200]\tvalidation_0-error:0.03573\n",
            "[222]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.03725\n",
            "[50]\tvalidation_0-error:0.03571\n",
            "[100]\tvalidation_0-error:0.03610\n",
            "[150]\tvalidation_0-error:0.03648\n",
            "[192]\tvalidation_0-error:0.03687\n",
            "[0]\tvalidation_0-error:0.03842\n",
            "[50]\tvalidation_0-error:0.03880\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03803\n",
            "[200]\tvalidation_0-error:0.03765\n",
            "[250]\tvalidation_0-error:0.03726\n",
            "[300]\tvalidation_0-error:0.03842\n",
            "[350]\tvalidation_0-error:0.03803\n",
            "[400]\tvalidation_0-error:0.03919\n",
            "[401]\tvalidation_0-error:0.03919\n",
            "[0]\tvalidation_0-error:0.03496\n",
            "[50]\tvalidation_0-error:0.03458\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[193]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.03304\n",
            "[50]\tvalidation_0-error:0.03381\n",
            "[100]\tvalidation_0-error:0.03342\n",
            "[150]\tvalidation_0-error:0.03304\n",
            "[164]\tvalidation_0-error:0.03304\n",
            "[0]\tvalidation_0-error:0.03573\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[169]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.04072\n",
            "[50]\tvalidation_0-error:0.03919\n",
            "[100]\tvalidation_0-error:0.03880\n",
            "[150]\tvalidation_0-error:0.03957\n",
            "[166]\tvalidation_0-error:0.03995\n",
            "[0]\tvalidation_0-error:0.03726\n",
            "[50]\tvalidation_0-error:0.03842\n",
            "[100]\tvalidation_0-error:0.03803\n",
            "[150]\tvalidation_0-error:0.03765\n",
            "[165]\tvalidation_0-error:0.03765\n",
            "[0]\tvalidation_0-error:0.03995\n",
            "[50]\tvalidation_0-error:0.03803\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03880\n",
            "[200]\tvalidation_0-error:0.03880\n",
            "[250]\tvalidation_0-error:0.03919\n",
            "[256]\tvalidation_0-error:0.03919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03840\n",
            "[50]\tvalidation_0-error:0.03994\n",
            "[100]\tvalidation_0-error:0.03955\n",
            "[150]\tvalidation_0-error:0.03917\n",
            "[167]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03765\n",
            "[50]\tvalidation_0-error:0.03688\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[167]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.03112\n",
            "[50]\tvalidation_0-error:0.03035\n",
            "[100]\tvalidation_0-error:0.02958\n",
            "[150]\tvalidation_0-error:0.02997\n",
            "[200]\tvalidation_0-error:0.03035\n",
            "[250]\tvalidation_0-error:0.03035\n",
            "[255]\tvalidation_0-error:0.03035\n",
            "[0]\tvalidation_0-error:0.03573\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03496\n",
            "[200]\tvalidation_0-error:0.03534\n",
            "[250]\tvalidation_0-error:0.03573\n",
            "[294]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.04341\n",
            "[50]\tvalidation_0-error:0.04072\n",
            "[100]\tvalidation_0-error:0.04072\n",
            "[150]\tvalidation_0-error:0.04072\n",
            "[167]\tvalidation_0-error:0.04111\n",
            "[0]\tvalidation_0-error:0.03534\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03573\n",
            "[150]\tvalidation_0-error:0.03611\n",
            "[172]\tvalidation_0-error:0.03611\n",
            "[0]\tvalidation_0-error:0.04034\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03765\n",
            "[191]\tvalidation_0-error:0.03803\n",
            "[0]\tvalidation_0-error:0.03765\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[181]\tvalidation_0-error:0.03688\n",
            "[0]\tvalidation_0-error:0.03648\n",
            "[50]\tvalidation_0-error:0.03610\n",
            "[100]\tvalidation_0-error:0.03648\n",
            "[150]\tvalidation_0-error:0.03648\n",
            "[169]\tvalidation_0-error:0.03648\n",
            "[0]\tvalidation_0-error:0.03957\n",
            "[50]\tvalidation_0-error:0.03957\n",
            "[100]\tvalidation_0-error:0.03842\n",
            "[150]\tvalidation_0-error:0.03765\n",
            "[200]\tvalidation_0-error:0.03688\n",
            "[250]\tvalidation_0-error:0.03688\n",
            "[300]\tvalidation_0-error:0.03842\n",
            "[334]\tvalidation_0-error:0.03880\n",
            "[0]\tvalidation_0-error:0.03573\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03496\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[165]\tvalidation_0-error:0.03573\n",
            "[0]\tvalidation_0-error:0.03265\n",
            "[50]\tvalidation_0-error:0.03304\n",
            "[100]\tvalidation_0-error:0.03304\n",
            "[150]\tvalidation_0-error:0.03304\n",
            "[165]\tvalidation_0-error:0.03304\n",
            "[0]\tvalidation_0-error:0.03726\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03573\n",
            "[150]\tvalidation_0-error:0.03573\n",
            "[170]\tvalidation_0-error:0.03611\n",
            "[0]\tvalidation_0-error:0.04034\n",
            "[50]\tvalidation_0-error:0.03919\n",
            "[100]\tvalidation_0-error:0.03995\n",
            "[150]\tvalidation_0-error:0.03957\n",
            "[173]\tvalidation_0-error:0.03995\n",
            "[0]\tvalidation_0-error:0.03726\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03726\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[169]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.04072\n",
            "[50]\tvalidation_0-error:0.03880\n",
            "[100]\tvalidation_0-error:0.03957\n",
            "[150]\tvalidation_0-error:0.03957\n",
            "[167]\tvalidation_0-error:0.03995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.03879\n",
            "[50]\tvalidation_0-error:0.04071\n",
            "[100]\tvalidation_0-error:0.03917\n",
            "[150]\tvalidation_0-error:0.03955\n",
            "[166]\tvalidation_0-error:0.03917\n",
            "[0]\tvalidation_0-error:0.03803\n",
            "[50]\tvalidation_0-error:0.03726\n",
            "[100]\tvalidation_0-error:0.03688\n",
            "[150]\tvalidation_0-error:0.03688\n",
            "[177]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.03112\n",
            "[50]\tvalidation_0-error:0.03035\n",
            "[100]\tvalidation_0-error:0.03035\n",
            "[150]\tvalidation_0-error:0.03035\n",
            "[200]\tvalidation_0-error:0.03073\n",
            "[250]\tvalidation_0-error:0.03150\n",
            "[277]\tvalidation_0-error:0.03150\n",
            "[0]\tvalidation_0-error:0.03534\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[166]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.04303\n",
            "[50]\tvalidation_0-error:0.04072\n",
            "[100]\tvalidation_0-error:0.04072\n",
            "[150]\tvalidation_0-error:0.04072\n",
            "[170]\tvalidation_0-error:0.04072\n",
            "[0]\tvalidation_0-error:0.03611\n",
            "[50]\tvalidation_0-error:0.03611\n",
            "[100]\tvalidation_0-error:0.03611\n",
            "[150]\tvalidation_0-error:0.03650\n",
            "[179]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.03842\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03726\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[200]\tvalidation_0-error:0.03726\n",
            "[241]\tvalidation_0-error:0.03765\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03573\n",
            "[100]\tvalidation_0-error:0.03611\n",
            "[150]\tvalidation_0-error:0.03650\n",
            "[166]\tvalidation_0-error:0.03650\n",
            "[0]\tvalidation_0-error:0.03763\n",
            "[50]\tvalidation_0-error:0.03610\n",
            "[100]\tvalidation_0-error:0.03648\n",
            "[150]\tvalidation_0-error:0.03648\n",
            "[174]\tvalidation_0-error:0.03648\n",
            "[0]\tvalidation_0-error:0.03919\n",
            "[50]\tvalidation_0-error:0.03957\n",
            "[100]\tvalidation_0-error:0.03880\n",
            "[150]\tvalidation_0-error:0.03765\n",
            "[200]\tvalidation_0-error:0.03726\n",
            "[250]\tvalidation_0-error:0.03726\n",
            "[300]\tvalidation_0-error:0.03803\n",
            "[346]\tvalidation_0-error:0.03880\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03534\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[200]\tvalidation_0-error:0.03573\n",
            "[216]\tvalidation_0-error:0.03611\n",
            "[0]\tvalidation_0-error:0.03265\n",
            "[50]\tvalidation_0-error:0.03342\n",
            "[100]\tvalidation_0-error:0.03342\n",
            "[150]\tvalidation_0-error:0.03304\n",
            "[164]\tvalidation_0-error:0.03304\n",
            "[0]\tvalidation_0-error:0.03650\n",
            "[50]\tvalidation_0-error:0.03534\n",
            "[100]\tvalidation_0-error:0.03496\n",
            "[150]\tvalidation_0-error:0.03534\n",
            "[195]\tvalidation_0-error:0.03534\n",
            "[0]\tvalidation_0-error:0.04111\n",
            "[50]\tvalidation_0-error:0.03919\n",
            "[100]\tvalidation_0-error:0.03957\n",
            "[150]\tvalidation_0-error:0.03957\n",
            "[168]\tvalidation_0-error:0.04034\n",
            "[0]\tvalidation_0-error:0.03688\n",
            "[50]\tvalidation_0-error:0.03765\n",
            "[100]\tvalidation_0-error:0.03765\n",
            "[150]\tvalidation_0-error:0.03726\n",
            "[164]\tvalidation_0-error:0.03726\n",
            "[0]\tvalidation_0-error:0.03995\n",
            "[50]\tvalidation_0-error:0.03842\n",
            "[100]\tvalidation_0-error:0.03919\n",
            "[150]\tvalidation_0-error:0.03957\n",
            "[166]\tvalidation_0-error:0.03957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/model.pkl\n",
            "Stopping HPO due to exhausted search space: 5 of 5 possible configs ran.\n",
            "Time for XGBoost_2_BAG_L1 model HPO: 274.0274484157562\n",
            "Best hyperparameter configuration for XGBoost_2_BAG_L1 model: \n",
            "{'n_estimators': 800, 'learning_rate': 0.03, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'binary:logistic', 'booster': 'gbtree', 'max_depth': 10, 'scale_pos_weight': 2.5533783783783783, 'subsample': 0.9, 'colsample_bytree': 0.9, 'min_child_weight': 5}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T1 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t62.56s\t = Training   runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "\t5118.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T2 ...\n",
            "\t0.9639\t = Validation score   (accuracy)\n",
            "\t50.18s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "\t6145.8\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T3 ...\n",
            "\t0.9638\t = Validation score   (accuracy)\n",
            "\t54.13s\t = Training   runtime\n",
            "\t0.48s\t = Validation runtime\n",
            "\t5427.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T4 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t53.94s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t6486.2\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/model.pkl\n",
            "Fitted model: XGBoost_2_BAG_L1/T5 ...\n",
            "\t0.9638\t = Validation score   (accuracy)\n",
            "\t53.02s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "\t6414.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_BAG_L1 ... Tuning model for up to 782.72s of the 11811.71s of remaining time.\n",
            "\tFitting LinearModel_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c4f8808a6844e3cbd88bb2403be889d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_BAG_L1 model HPO: 22.409611463546753\n",
            "Best hyperparameter configuration for LinearModel_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 0.1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T1 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t6.85s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "\t5269.0\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T2 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t5.21s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "\t7204.9\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T3 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t5.56s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "\t8314.2\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_BAG_L1/T4 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t4.64s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "\t10398.0\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_2_BAG_L1 ... Tuning model for up to 782.72s of the 11789.24s of remaining time.\n",
            "\tFitting LinearModel_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_2_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_2_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41bec731fdaf4bf29e9d1c3f98979b73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_2_BAG_L1 model HPO: 41.71655058860779\n",
            "Best hyperparameter configuration for LinearModel_2_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'lbfgs', 'C': 1, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': 0.99, 'proc.impute_strategy': 'median', 'penalty': 'L2', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T1 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t14.2s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "\t6343.5\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T2 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t9.61s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t6583.1\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T3 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t8.85s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "\t9345.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_2_BAG_L1/T4 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t8.91s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "\t9164.2\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: LinearModel_3_BAG_L1 ... Tuning model for up to 782.72s of the 11747.47s of remaining time.\n",
            "\tFitting LinearModel_3_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for LinearModel_3_BAG_L1 model...\n",
            "\tHyperparameter search space for LinearModel_3_BAG_L1: \n",
            "proc.skew_threshold:   Categorical[0.99, None]\n",
            "penalty:   Categorical['L2', 'L1']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf94ab7c79f4432aa11359cfe5f0218a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Training Model with the following hyperparameter settings:\n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'class_weight': 'balanced', 'n_jobs': 2}\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/model.pkl\n",
            "Stopping HPO due to exhausted search space: 4 of 4 possible configs ran.\n",
            "Time for LinearModel_3_BAG_L1 model HPO: 37.409783363342285\n",
            "Best hyperparameter configuration for LinearModel_3_BAG_L1 model: \n",
            "{'random_state': 0, 'fit_intercept': True, 'solver': 'liblinear', 'C': 10, 'vectorizer_dict_size': 75000, 'proc.ngram_range': (1, 5), 'proc.skew_threshold': None, 'proc.impute_strategy': 'median', 'penalty': 'L1', 'handle_text': 'ignore', 'class_weight': 'balanced'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T1 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t10.29s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "\t6190.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T2 ...\n",
            "\t0.9635\t = Validation score   (accuracy)\n",
            "\t9.71s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t6539.2\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T3 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t8.31s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "\t10230.4\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/model.pkl\n",
            "Fitted model: LinearModel_3_BAG_L1/T4 ...\n",
            "\t0.9636\t = Validation score   (accuracy)\n",
            "\t8.93s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "\t9349.2\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 782.72s of the 11709.99s of remaining time.\n",
            "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_BAG_L1 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_BAG_L1: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c05c042ce224eaeaa1e6984df7fac74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(55, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1726, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1553, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1521, Val accuracy: 0.9608, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1529, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1501, Val accuracy: 0.9608, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1501, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1505, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1483, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1497, Val accuracy: 0.9616, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1461, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1457, Val accuracy: 0.9612, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1465, Val accuracy: 0.9624, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1446, Val accuracy: 0.962, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1446, Val accuracy: 0.962, Best Epoch: 12\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1437, Val accuracy: 0.9616, Best Epoch: 12\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1437, Val accuracy: 0.9616, Best Epoch: 12\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.143, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1437, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1434, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1428, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1418, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1418, Val accuracy: 0.9593, Best Epoch: 12\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1416, Val accuracy: 0.9601, Best Epoch: 12\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1415, Val accuracy: 0.9601, Best Epoch: 12\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.14, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1412, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1417, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1398, Val accuracy: 0.9608, Best Epoch: 12\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1404, Val accuracy: 0.9604, Best Epoch: 12\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1399, Val accuracy: 0.9608, Best Epoch: 12\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1403, Val accuracy: 0.9604, Best Epoch: 12\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1412, Val accuracy: 0.9612, Best Epoch: 12\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1377, Val accuracy: 0.9604, Best Epoch: 12\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1418, Val accuracy: 0.9608, Best Epoch: 12\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1383, Val accuracy: 0.962, Best Epoch: 12\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1397, Val accuracy: 0.9601, Best Epoch: 12\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1386, Val accuracy: 0.9608, Best Epoch: 12\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1374, Val accuracy: 0.9608, Best Epoch: 12\n",
            "Best model found on Epoch 12 (Update 1704). Val accuracy: 0.9623655913978495\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1745, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1559, Val accuracy: 0.9631, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1538, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1556, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.151, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1505, Val accuracy: 0.9635, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1498, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1495, Val accuracy: 0.9635, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1491, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1474, Val accuracy: 0.9635, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.146, Val accuracy: 0.9635, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1464, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1462, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1448, Val accuracy: 0.9627, Best Epoch: 11\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1451, Val accuracy: 0.9631, Best Epoch: 11\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1447, Val accuracy: 0.9635, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1439, Val accuracy: 0.9631, Best Epoch: 16\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1437, Val accuracy: 0.9631, Best Epoch: 16\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1438, Val accuracy: 0.9624, Best Epoch: 16\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1451, Val accuracy: 0.9627, Best Epoch: 16\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.145, Val accuracy: 0.962, Best Epoch: 16\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1437, Val accuracy: 0.962, Best Epoch: 16\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1429, Val accuracy: 0.9631, Best Epoch: 16\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1431, Val accuracy: 0.9624, Best Epoch: 16\n",
            "Best model found on Epoch 16 (Update 2272). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1768, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1623, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1589, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1582, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1542, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1548, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1518, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.151, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1514, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1513, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1513, Val accuracy: 0.9704, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.15, Val accuracy: 0.9708, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1525, Val accuracy: 0.9708, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1495, Val accuracy: 0.9708, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1485, Val accuracy: 0.9704, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1492, Val accuracy: 0.9704, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1484, Val accuracy: 0.9708, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1491, Val accuracy: 0.9704, Best Epoch: 17\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1483, Val accuracy: 0.9708, Best Epoch: 19\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.147, Val accuracy: 0.97, Best Epoch: 19\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1469, Val accuracy: 0.9704, Best Epoch: 19\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1452, Val accuracy: 0.9704, Best Epoch: 19\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1469, Val accuracy: 0.9708, Best Epoch: 23\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.146, Val accuracy: 0.9704, Best Epoch: 23\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1462, Val accuracy: 0.9704, Best Epoch: 23\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1467, Val accuracy: 0.9704, Best Epoch: 23\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1435, Val accuracy: 0.9697, Best Epoch: 23\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1452, Val accuracy: 0.97, Best Epoch: 23\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1438, Val accuracy: 0.9689, Best Epoch: 23\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.144, Val accuracy: 0.9697, Best Epoch: 23\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1462, Val accuracy: 0.9704, Best Epoch: 23\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1424, Val accuracy: 0.9697, Best Epoch: 23\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1463, Val accuracy: 0.9708, Best Epoch: 33\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.142, Val accuracy: 0.9689, Best Epoch: 33\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1419, Val accuracy: 0.97, Best Epoch: 33\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1421, Val accuracy: 0.9689, Best Epoch: 33\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1437, Val accuracy: 0.9704, Best Epoch: 33\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1409, Val accuracy: 0.9697, Best Epoch: 33\n",
            "Best model found on Epoch 33 (Update 4686). Val accuracy: 0.9708029197080292\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1726, Val accuracy: 0.9662, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1571, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1556, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1538, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1543, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1526, Val accuracy: 0.9658, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1499, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.149, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1481, Val accuracy: 0.9662, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1484, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1475, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1473, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.147, Val accuracy: 0.9654, Best Epoch: 9\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1482, Val accuracy: 0.9662, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1445, Val accuracy: 0.965, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1468, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.146, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1467, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1479, Val accuracy: 0.9654, Best Epoch: 14\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1449, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1452, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Best model found on Epoch 14 (Update 1988). Val accuracy: 0.9661928543987707\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1715, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.154, Val accuracy: 0.9581, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1558, Val accuracy: 0.9577, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1519, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1485, Val accuracy: 0.9589, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.148, Val accuracy: 0.9581, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1484, Val accuracy: 0.9593, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1456, Val accuracy: 0.9589, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1449, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1454, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1437, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1442, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1428, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1427, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1436, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1428, Val accuracy: 0.957, Best Epoch: 7\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1437, Val accuracy: 0.9577, Best Epoch: 7\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1419, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1416, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1412, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1429, Val accuracy: 0.9581, Best Epoch: 7\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1434, Val accuracy: 0.9574, Best Epoch: 7\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1426, Val accuracy: 0.9577, Best Epoch: 7\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1412, Val accuracy: 0.9585, Best Epoch: 7\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1397, Val accuracy: 0.9574, Best Epoch: 7\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1416, Val accuracy: 0.9577, Best Epoch: 7\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1407, Val accuracy: 0.9574, Best Epoch: 7\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1393, Val accuracy: 0.9577, Best Epoch: 7\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1413, Val accuracy: 0.9574, Best Epoch: 7\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1392, Val accuracy: 0.9577, Best Epoch: 7\n",
            "Best model found on Epoch 7 (Update 994). Val accuracy: 0.9592777564348828\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1734, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1602, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1561, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1558, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1513, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1514, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1513, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1492, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1505, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1475, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1481, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1469, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1462, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1467, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1458, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1438, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.144, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.143, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1433, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1419, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1452, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Best model found on Epoch 1 (Update 142). Val accuracy: 0.9654245101805609\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1703, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1563, Val accuracy: 0.9631, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1538, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1509, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1527, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1499, Val accuracy: 0.9635, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1487, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1482, Val accuracy: 0.9635, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1489, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1483, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1473, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1461, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1455, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1464, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1446, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1455, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1444, Val accuracy: 0.9631, Best Epoch: 8\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1454, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1432, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.144, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1448, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1437, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.144, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1428, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1445, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1415, Val accuracy: 0.9627, Best Epoch: 8\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1424, Val accuracy: 0.9631, Best Epoch: 8\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1422, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Best model found on Epoch 8 (Update 1136). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1716, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.156, Val accuracy: 0.9643, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1582, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1544, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1514, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1509, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1509, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1487, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.147, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1485, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1474, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.145, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1466, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1459, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1443, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1483, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1446, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1455, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.145, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1449, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1441, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1424, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1432, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1437, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1435, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1418, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Best model found on Epoch 4 (Update 568). Val accuracy: 0.9650403380714561\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1732, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1593, Val accuracy: 0.9643, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1557, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1529, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1516, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1514, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1512, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1479, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1473, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1486, Val accuracy: 0.9647, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1473, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1471, Val accuracy: 0.9643, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1469, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1455, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1442, Val accuracy: 0.9643, Best Epoch: 10\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1447, Val accuracy: 0.9643, Best Epoch: 10\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1454, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1446, Val accuracy: 0.9647, Best Epoch: 18\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1444, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1439, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1428, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1432, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1411, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1412, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1431, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1414, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1412, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Best model found on Epoch 18 (Update 2556). Val accuracy: 0.9646697388632872\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1744, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.156, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1534, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1528, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1523, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1515, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1479, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1495, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1473, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1475, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1481, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1468, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1464, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1436, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1443, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1447, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1457, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1433, Val accuracy: 0.9612, Best Epoch: 17\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1444, Val accuracy: 0.9616, Best Epoch: 17\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1426, Val accuracy: 0.9616, Best Epoch: 17\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1417, Val accuracy: 0.9616, Best Epoch: 17\n",
            "Best model found on Epoch 17 (Update 2414). Val accuracy: 0.9623511333077218\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1747, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1578, Val accuracy: 0.9662, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1542, Val accuracy: 0.9662, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.153, Val accuracy: 0.9666, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1526, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1527, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1508, Val accuracy: 0.9666, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1496, Val accuracy: 0.9666, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1514, Val accuracy: 0.9662, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.149, Val accuracy: 0.9658, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1488, Val accuracy: 0.9662, Best Epoch: 8\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1487, Val accuracy: 0.9662, Best Epoch: 8\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.148, Val accuracy: 0.9658, Best Epoch: 8\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1466, Val accuracy: 0.9658, Best Epoch: 8\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1481, Val accuracy: 0.9666, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1478, Val accuracy: 0.9662, Best Epoch: 15\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1451, Val accuracy: 0.9662, Best Epoch: 15\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1475, Val accuracy: 0.9666, Best Epoch: 18\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1466, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1443, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1454, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1449, Val accuracy: 0.9654, Best Epoch: 18\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1448, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1422, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1437, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1412, Val accuracy: 0.9666, Best Epoch: 26\n",
            "Best model found on Epoch 26 (Update 3692). Val accuracy: 0.9665770265078756\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1743, Val accuracy: 0.9666, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1601, Val accuracy: 0.9673, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1582, Val accuracy: 0.9673, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1559, Val accuracy: 0.9673, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1537, Val accuracy: 0.9673, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1519, Val accuracy: 0.9673, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1512, Val accuracy: 0.967, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1524, Val accuracy: 0.967, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1506, Val accuracy: 0.9673, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1494, Val accuracy: 0.9677, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1493, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1499, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1487, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1484, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1474, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1464, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1475, Val accuracy: 0.9662, Best Epoch: 10\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1471, Val accuracy: 0.9658, Best Epoch: 10\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1479, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.148, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1467, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1453, Val accuracy: 0.9662, Best Epoch: 10\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1464, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1434, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1444, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1442, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1457, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1437, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1448, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1426, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1427, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1428, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1446, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1428, Val accuracy: 0.9673, Best Epoch: 10\n",
            "Best model found on Epoch 10 (Update 1420). Val accuracy: 0.9677295428351902\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1739, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1576, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1557, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1548, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1536, Val accuracy: 0.9639, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1513, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.151, Val accuracy: 0.9639, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1502, Val accuracy: 0.9635, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1475, Val accuracy: 0.9647, Best Epoch: 6\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1463, Val accuracy: 0.9643, Best Epoch: 6\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1492, Val accuracy: 0.9643, Best Epoch: 6\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1475, Val accuracy: 0.965, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1468, Val accuracy: 0.965, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.147, Val accuracy: 0.9643, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1467, Val accuracy: 0.9647, Best Epoch: 13\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1452, Val accuracy: 0.9647, Best Epoch: 13\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1454, Val accuracy: 0.9639, Best Epoch: 13\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1437, Val accuracy: 0.9639, Best Epoch: 13\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1449, Val accuracy: 0.9635, Best Epoch: 13\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1439, Val accuracy: 0.9643, Best Epoch: 13\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1428, Val accuracy: 0.9647, Best Epoch: 13\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1444, Val accuracy: 0.9643, Best Epoch: 13\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1429, Val accuracy: 0.9647, Best Epoch: 13\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1435, Val accuracy: 0.9635, Best Epoch: 13\n",
            "Best model found on Epoch 13 (Update 1846). Val accuracy: 0.9650403380714561\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1708, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1563, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1528, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1514, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1507, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1496, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1507, Val accuracy: 0.9624, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1487, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.148, Val accuracy: 0.9627, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1466, Val accuracy: 0.9627, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1452, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1462, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1452, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1449, Val accuracy: 0.9631, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1458, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1441, Val accuracy: 0.9608, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1443, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1444, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1451, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1429, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1424, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1435, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1425, Val accuracy: 0.9612, Best Epoch: 14\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1416, Val accuracy: 0.9612, Best Epoch: 14\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1439, Val accuracy: 0.9604, Best Epoch: 14\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.142, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1413, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1403, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1435, Val accuracy: 0.96, Best Epoch: 14\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1399, Val accuracy: 0.9624, Best Epoch: 14\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1411, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1392, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1393, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.139, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.142, Val accuracy: 0.9612, Best Epoch: 14\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1397, Val accuracy: 0.9616, Best Epoch: 14\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1406, Val accuracy: 0.9604, Best Epoch: 14\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1403, Val accuracy: 0.9631, Best Epoch: 38\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.14, Val accuracy: 0.962, Best Epoch: 38\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.14, Val accuracy: 0.9624, Best Epoch: 38\n",
            "Best model found on Epoch 38 (Update 5396). Val accuracy: 0.9631194775259316\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1748, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1563, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1561, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1548, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1515, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1531, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1504, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1489, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1478, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1455, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1465, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1458, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1452, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1452, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1451, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1441, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1446, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1433, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1435, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1425, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1404, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1407, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1412, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1436, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1408, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.141, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Best model found on Epoch 4 (Update 568). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1709, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1565, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1554, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1526, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1503, Val accuracy: 0.9624, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1506, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1488, Val accuracy: 0.9616, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1485, Val accuracy: 0.9593, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1481, Val accuracy: 0.962, Best Epoch: 6\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1472, Val accuracy: 0.962, Best Epoch: 6\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1467, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1462, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.146, Val accuracy: 0.962, Best Epoch: 11\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1463, Val accuracy: 0.962, Best Epoch: 11\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1449, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1439, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1445, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1443, Val accuracy: 0.962, Best Epoch: 11\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1436, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1449, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1453, Val accuracy: 0.962, Best Epoch: 11\n",
            "Best model found on Epoch 11 (Update 1562). Val accuracy: 0.9623511333077218\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1695, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1559, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.158, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1572, Val accuracy: 0.9608, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1579, Val accuracy: 0.9017, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1573, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1595, Val accuracy: 0.9608, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1573, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1588, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.156, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1569, Val accuracy: 0.9574, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1566, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1554, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1573, Val accuracy: 0.9616, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 10 (Update 1420). Val accuracy: 0.9619815668202765\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1769, Val accuracy: 0.9574, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1578, Val accuracy: 0.9627, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1586, Val accuracy: 0.9608, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1589, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1572, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1587, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1581, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1574, Val accuracy: 0.9635, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1589, Val accuracy: 0.9635, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1577, Val accuracy: 0.9616, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1559, Val accuracy: 0.9535, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1578, Val accuracy: 0.9639, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.157, Val accuracy: 0.9635, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1564, Val accuracy: 0.9635, Best Epoch: 12\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 12 (Update 1704). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1747, Val accuracy: 0.9712, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.163, Val accuracy: 0.9697, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1624, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1608, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1623, Val accuracy: 0.9708, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1608, Val accuracy: 0.9708, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1621, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1598, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1624, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1613, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.161, Val accuracy: 0.9708, Best Epoch: 1\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1602, Val accuracy: 0.9693, Best Epoch: 1\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1639, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1621, Val accuracy: 0.9712, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
            "Best model found on Epoch 14 (Update 1988). Val accuracy: 0.971187091817134\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.172, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1575, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.159, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1597, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1601, Val accuracy: 0.9666, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1594, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1583, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1585, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1579, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1576, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1572, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1596, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1588, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1596, Val accuracy: 0.9654, Best Epoch: 5\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1587, Val accuracy: 0.9654, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 5 (Update 710). Val accuracy: 0.9665770265078756\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1716, Val accuracy: 0.9577, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1556, Val accuracy: 0.957, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1571, Val accuracy: 0.9589, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.158, Val accuracy: 0.9577, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1551, Val accuracy: 0.9581, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1562, Val accuracy: 0.8932, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1573, Val accuracy: 0.9577, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1561, Val accuracy: 0.9581, Best Epoch: 3\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1547, Val accuracy: 0.9589, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1554, Val accuracy: 0.9581, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1557, Val accuracy: 0.9551, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1559, Val accuracy: 0.9577, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1552, Val accuracy: 0.9589, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1548, Val accuracy: 0.9562, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2126 (Epoch 14))\n",
            "Best model found on Epoch 13 (Update 1846). Val accuracy: 0.958893584325778\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1668, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1602, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.16, Val accuracy: 0.9643, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1619, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1592, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1594, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.158, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1588, Val accuracy: 0.9647, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1587, Val accuracy: 0.9647, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1566, Val accuracy: 0.9647, Best Epoch: 7\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1596, Val accuracy: 0.9627, Best Epoch: 7\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.159, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1595, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1566, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1552, Val accuracy: 0.9647, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2208 (Epoch 15))\n",
            "Best model found on Epoch 7 (Update 994). Val accuracy: 0.9654245101805609\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1687, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1595, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1591, Val accuracy: 0.9627, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1584, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1595, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.157, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1578, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1578, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1599, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1586, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1578, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1584, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1568, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1579, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1564, Val accuracy: 0.9624, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2201 (Epoch 15))\n",
            "Best model found on Epoch 5 (Update 710). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1705, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1584, Val accuracy: 0.9627, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1626, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1607, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1588, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1602, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1595, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1614, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1606, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1601, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1612, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1592, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1597, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1594, Val accuracy: 0.9612, Best Epoch: 2\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2111 (Epoch 14))\n",
            "Best model found on Epoch 2 (Update 284). Val accuracy: 0.9627353054168267\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1705, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1602, Val accuracy: 0.9639, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1589, Val accuracy: 0.9639, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1598, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1591, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1566, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.158, Val accuracy: 0.9647, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1573, Val accuracy: 0.9639, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1571, Val accuracy: 0.9635, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1595, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1579, Val accuracy: 0.9635, Best Epoch: 7\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1573, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1566, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1593, Val accuracy: 0.9631, Best Epoch: 7\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2070 (Epoch 14))\n",
            "Best model found on Epoch 7 (Update 994). Val accuracy: 0.9646697388632872\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1703, Val accuracy: 0.9566, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1581, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1599, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1582, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1581, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1577, Val accuracy: 0.9562, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1576, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1559, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1573, Val accuracy: 0.96, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1554, Val accuracy: 0.9604, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1577, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1577, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.159, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1566, Val accuracy: 0.9604, Best Epoch: 8\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1573, Val accuracy: 0.9616, Best Epoch: 8\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
            "Best model found on Epoch 8 (Update 1136). Val accuracy: 0.9623511333077218\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1747, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1607, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1583, Val accuracy: 0.9662, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1588, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1605, Val accuracy: 0.9662, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1593, Val accuracy: 0.9662, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.159, Val accuracy: 0.8582, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1589, Val accuracy: 0.9662, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1603, Val accuracy: 0.9662, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1584, Val accuracy: 0.9662, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1593, Val accuracy: 0.9662, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1585, Val accuracy: 0.9662, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1571, Val accuracy: 0.9662, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1585, Val accuracy: 0.9662, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1587, Val accuracy: 0.9662, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1574, Val accuracy: 0.9662, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2323 (Epoch 16))\n",
            "Best model found on Epoch 16 (Update 2272). Val accuracy: 0.9661928543987707\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1698, Val accuracy: 0.9666, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1621, Val accuracy: 0.967, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.161, Val accuracy: 0.967, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1619, Val accuracy: 0.9666, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.161, Val accuracy: 0.967, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1587, Val accuracy: 0.9673, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.161, Val accuracy: 0.9666, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1639, Val accuracy: 0.9666, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1596, Val accuracy: 0.9666, Best Epoch: 6\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1616, Val accuracy: 0.967, Best Epoch: 6\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1603, Val accuracy: 0.967, Best Epoch: 6\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1613, Val accuracy: 0.9673, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1616, Val accuracy: 0.9673, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1596, Val accuracy: 0.9666, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1617, Val accuracy: 0.9673, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2258 (Epoch 15))\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.9673453707260853\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1709, Val accuracy: 0.9516, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1588, Val accuracy: 0.9639, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.162, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1589, Val accuracy: 0.9654, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1604, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.158, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1578, Val accuracy: 0.9639, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1582, Val accuracy: 0.9654, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1562, Val accuracy: 0.9562, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1562, Val accuracy: 0.9647, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1597, Val accuracy: 0.9658, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1583, Val accuracy: 0.9654, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1593, Val accuracy: 0.965, Best Epoch: 11\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1597, Val accuracy: 0.9647, Best Epoch: 11\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1572, Val accuracy: 0.9647, Best Epoch: 11\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2212 (Epoch 15))\n",
            "Best model found on Epoch 11 (Update 1562). Val accuracy: 0.9658086822896658\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1684, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1595, Val accuracy: 0.9597, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1585, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.157, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1571, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1577, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1585, Val accuracy: 0.9604, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1579, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1581, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1593, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1575, Val accuracy: 0.9608, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1576, Val accuracy: 0.9589, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1565, Val accuracy: 0.9566, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1557, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1558, Val accuracy: 0.9616, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2214 (Epoch 15))\n",
            "Best model found on Epoch 10 (Update 1420). Val accuracy: 0.9623511333077218\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1711, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1564, Val accuracy: 0.9631, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1594, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.158, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1588, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.16, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.157, Val accuracy: 0.9624, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1593, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1565, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1558, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1588, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1577, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1575, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1574, Val accuracy: 0.9635, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1589, Val accuracy: 0.9631, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2248 (Epoch 15))\n",
            "Best model found on Epoch 14 (Update 1988). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.2, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 300 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1699, Val accuracy: 0.9527, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1587, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1598, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1573, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1575, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1572, Val accuracy: 0.9616, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1559, Val accuracy: 0.9566, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1578, Val accuracy: 0.9597, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1579, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.157, Val accuracy: 0.9612, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1563, Val accuracy: 0.9535, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1579, Val accuracy: 0.9616, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.158, Val accuracy: 0.962, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1578, Val accuracy: 0.9616, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1566, Val accuracy: 0.9616, Best Epoch: 13\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1565, Val accuracy: 0.9527, Best Epoch: 13\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1556, Val accuracy: 0.9616, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 13 (Update 1846). Val accuracy: 0.961966961198617\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_BAG_L1 model HPO: 765.2126007080078\n",
            "Best hyperparameter configuration for NeuralNetTorch_BAG_L1 model: \n",
            "{'num_epochs': 300, 'epochs_wo_improve': None, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2, 'optimizer': 'adam', 'learning_rate': 0.01, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t298.52s\t = Training   runtime\n",
            "\t0.69s\t = Validation runtime\n",
            "\t3774.9\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
            "\t0.9642\t = Validation score   (accuracy)\n",
            "\t466.58s\t = Training   runtime\n",
            "\t3.13s\t = Validation runtime\n",
            "\t831.9\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Hyperparameter tuning model: NeuralNetTorch_2_BAG_L1 ... Tuning model for up to 782.72s of the 10944.73s of remaining time.\n",
            "\tFitting NeuralNetTorch_2_BAG_L1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch_2_BAG_L1 model...\n",
            "\tHyperparameter search space for NeuralNetTorch_2_BAG_L1: \n",
            "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
            "weight_decay:   Real: lower=1e-12, upper=0.1\n",
            "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
            "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
            "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
            "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
            "num_layers:   Categorical[2, 3, 4]\n",
            "hidden_size:   Categorical[128, 256, 512]\n",
            "use_batchnorm:   Categorical[False, True]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb8f82ae83649bf9aad4ae308411608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(55, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1622, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1499, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.149, Val accuracy: 0.9601, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1506, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1504, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1501, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1505, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1476, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1508, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1482, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1457, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1492, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1463, Val accuracy: 0.9616, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1463, Val accuracy: 0.9612, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1453, Val accuracy: 0.9612, Best Epoch: 13\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1465, Val accuracy: 0.9616, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1443, Val accuracy: 0.9608, Best Epoch: 16\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1454, Val accuracy: 0.9612, Best Epoch: 16\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1452, Val accuracy: 0.9608, Best Epoch: 16\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1457, Val accuracy: 0.9612, Best Epoch: 16\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1459, Val accuracy: 0.9612, Best Epoch: 16\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1444, Val accuracy: 0.9616, Best Epoch: 22\n",
            "Best model found on Epoch 22 (Update 3124). Val accuracy: 0.9615975422427036\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1646, Val accuracy: 0.9635, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1514, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1503, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1517, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1506, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1496, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1492, Val accuracy: 0.9635, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1501, Val accuracy: 0.9635, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1493, Val accuracy: 0.9635, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1485, Val accuracy: 0.9631, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1481, Val accuracy: 0.9631, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1487, Val accuracy: 0.9616, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1468, Val accuracy: 0.9635, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1464, Val accuracy: 0.9635, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1463, Val accuracy: 0.9635, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1496, Val accuracy: 0.9627, Best Epoch: 15\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1462, Val accuracy: 0.962, Best Epoch: 15\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1449, Val accuracy: 0.962, Best Epoch: 15\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1459, Val accuracy: 0.9631, Best Epoch: 15\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1471, Val accuracy: 0.962, Best Epoch: 15\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1467, Val accuracy: 0.9631, Best Epoch: 15\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.167, Val accuracy: 0.9704, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1557, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1552, Val accuracy: 0.9704, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1533, Val accuracy: 0.9708, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1546, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1539, Val accuracy: 0.97, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1513, Val accuracy: 0.9697, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.152, Val accuracy: 0.97, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1515, Val accuracy: 0.97, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1514, Val accuracy: 0.97, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1524, Val accuracy: 0.9704, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1527, Val accuracy: 0.9704, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.151, Val accuracy: 0.9708, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1511, Val accuracy: 0.9708, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1497, Val accuracy: 0.97, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1514, Val accuracy: 0.9712, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1489, Val accuracy: 0.97, Best Epoch: 16\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1517, Val accuracy: 0.9708, Best Epoch: 16\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1502, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1493, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1484, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1482, Val accuracy: 0.9708, Best Epoch: 16\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1468, Val accuracy: 0.9697, Best Epoch: 16\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1501, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1466, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1474, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1455, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1499, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.146, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1458, Val accuracy: 0.97, Best Epoch: 16\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1452, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1484, Val accuracy: 0.97, Best Epoch: 16\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1462, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1471, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1447, Val accuracy: 0.97, Best Epoch: 16\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1445, Val accuracy: 0.9697, Best Epoch: 16\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1463, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1457, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.1455, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.1446, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1448, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1453, Val accuracy: 0.97, Best Epoch: 16\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.143, Val accuracy: 0.9704, Best Epoch: 16\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.1446, Val accuracy: 0.9697, Best Epoch: 16\n",
            "Best model found on Epoch 16 (Update 2272). Val accuracy: 0.971187091817134\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1656, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1516, Val accuracy: 0.9658, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1527, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.153, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1535, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.152, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1499, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1492, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1501, Val accuracy: 0.9658, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.149, Val accuracy: 0.9658, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1487, Val accuracy: 0.9658, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1482, Val accuracy: 0.9662, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1471, Val accuracy: 0.9658, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1491, Val accuracy: 0.9662, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1486, Val accuracy: 0.9654, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1485, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1481, Val accuracy: 0.9658, Best Epoch: 14\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.147, Val accuracy: 0.9662, Best Epoch: 18\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1456, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.147, Val accuracy: 0.9654, Best Epoch: 18\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1479, Val accuracy: 0.9662, Best Epoch: 21\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1478, Val accuracy: 0.9658, Best Epoch: 21\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1477, Val accuracy: 0.9658, Best Epoch: 21\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1452, Val accuracy: 0.9666, Best Epoch: 24\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1447, Val accuracy: 0.9658, Best Epoch: 24\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1486, Val accuracy: 0.9662, Best Epoch: 24\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1454, Val accuracy: 0.9658, Best Epoch: 24\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1437, Val accuracy: 0.9666, Best Epoch: 28\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1472, Val accuracy: 0.9658, Best Epoch: 28\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1447, Val accuracy: 0.9658, Best Epoch: 28\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1448, Val accuracy: 0.9658, Best Epoch: 28\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1441, Val accuracy: 0.9658, Best Epoch: 28\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1444, Val accuracy: 0.9666, Best Epoch: 33\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.145, Val accuracy: 0.9658, Best Epoch: 33\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1436, Val accuracy: 0.9666, Best Epoch: 35\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1413, Val accuracy: 0.9658, Best Epoch: 35\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1414, Val accuracy: 0.9662, Best Epoch: 35\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1448, Val accuracy: 0.9658, Best Epoch: 35\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.142, Val accuracy: 0.9662, Best Epoch: 35\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.145, Val accuracy: 0.9662, Best Epoch: 35\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1429, Val accuracy: 0.9666, Best Epoch: 41\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1403, Val accuracy: 0.9662, Best Epoch: 41\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.1435, Val accuracy: 0.9666, Best Epoch: 43\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.1411, Val accuracy: 0.9662, Best Epoch: 43\n",
            "Epoch 45 (Update 6390).\tTrain loss: 0.1405, Val accuracy: 0.9662, Best Epoch: 43\n",
            "Epoch 46 (Update 6532).\tTrain loss: 0.1416, Val accuracy: 0.9658, Best Epoch: 43\n",
            "Epoch 47 (Update 6674).\tTrain loss: 0.1403, Val accuracy: 0.9662, Best Epoch: 43\n",
            "Epoch 48 (Update 6816).\tTrain loss: 0.1407, Val accuracy: 0.9662, Best Epoch: 43\n",
            "Epoch 49 (Update 6958).\tTrain loss: 0.1404, Val accuracy: 0.9662, Best Epoch: 43\n",
            "Epoch 50 (Update 7100).\tTrain loss: 0.1406, Val accuracy: 0.9666, Best Epoch: 50\n",
            "Epoch 51 (Update 7242).\tTrain loss: 0.141, Val accuracy: 0.9662, Best Epoch: 50\n",
            "Epoch 52 (Update 7384).\tTrain loss: 0.1415, Val accuracy: 0.9662, Best Epoch: 50\n",
            "Epoch 53 (Update 7526).\tTrain loss: 0.1391, Val accuracy: 0.9666, Best Epoch: 53\n",
            "Epoch 54 (Update 7668).\tTrain loss: 0.1393, Val accuracy: 0.9662, Best Epoch: 53\n",
            "Epoch 55 (Update 7810).\tTrain loss: 0.1392, Val accuracy: 0.9658, Best Epoch: 53\n",
            "Epoch 56 (Update 7952).\tTrain loss: 0.1411, Val accuracy: 0.9666, Best Epoch: 56\n",
            "Best model found on Epoch 56 (Update 7952). Val accuracy: 0.9665770265078756\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1639, Val accuracy: 0.9589, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1496, Val accuracy: 0.9581, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1503, Val accuracy: 0.9585, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1498, Val accuracy: 0.9589, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.149, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1479, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1481, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1471, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1478, Val accuracy: 0.9585, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1458, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1465, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1464, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1458, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.145, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1466, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1446, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1448, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1437, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1426, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1438, Val accuracy: 0.9577, Best Epoch: 4\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1442, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Best model found on Epoch 4 (Update 568). Val accuracy: 0.958893584325778\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1625, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1522, Val accuracy: 0.9639, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1538, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1519, Val accuracy: 0.9643, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1501, Val accuracy: 0.9643, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1503, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1505, Val accuracy: 0.9654, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1496, Val accuracy: 0.9635, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1508, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1479, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1518, Val accuracy: 0.965, Best Epoch: 7\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1485, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1485, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1467, Val accuracy: 0.9654, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1477, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1456, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1462, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.146, Val accuracy: 0.9639, Best Epoch: 14\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1461, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1474, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1472, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1451, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.144, Val accuracy: 0.9639, Best Epoch: 14\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1462, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1455, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1444, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1448, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1437, Val accuracy: 0.965, Best Epoch: 14\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1454, Val accuracy: 0.9639, Best Epoch: 14\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1449, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Best model found on Epoch 14 (Update 1988). Val accuracy: 0.9654245101805609\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1623, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1512, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1505, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1503, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1503, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1499, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1499, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1495, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.149, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1472, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1481, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1492, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1471, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1458, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1471, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1475, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1457, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1482, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1457, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.145, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1471, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1441, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Best model found on Epoch 3 (Update 426). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.164, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1509, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1535, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1518, Val accuracy: 0.9647, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1514, Val accuracy: 0.965, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1504, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1486, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1492, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1494, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1489, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1466, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.147, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1465, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1469, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1463, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1488, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1454, Val accuracy: 0.9647, Best Epoch: 5\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1456, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1451, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1476, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1466, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1456, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.144, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1445, Val accuracy: 0.9643, Best Epoch: 5\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1459, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1453, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1426, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Best model found on Epoch 5 (Update 710). Val accuracy: 0.9650403380714561\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1641, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1542, Val accuracy: 0.9639, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1522, Val accuracy: 0.9639, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1518, Val accuracy: 0.9643, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1502, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1513, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1505, Val accuracy: 0.9635, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.148, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1473, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.151, Val accuracy: 0.9631, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1489, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1484, Val accuracy: 0.9643, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1466, Val accuracy: 0.9631, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.147, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1467, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1466, Val accuracy: 0.9639, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1507, Val accuracy: 0.9639, Best Epoch: 14\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1468, Val accuracy: 0.9635, Best Epoch: 14\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1459, Val accuracy: 0.9643, Best Epoch: 19\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1454, Val accuracy: 0.9643, Best Epoch: 20\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1447, Val accuracy: 0.9627, Best Epoch: 20\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1454, Val accuracy: 0.9643, Best Epoch: 22\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.143, Val accuracy: 0.9635, Best Epoch: 22\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1441, Val accuracy: 0.9639, Best Epoch: 22\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1447, Val accuracy: 0.9631, Best Epoch: 22\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1436, Val accuracy: 0.9639, Best Epoch: 22\n",
            "Best model found on Epoch 22 (Update 3124). Val accuracy: 0.9642857142857143\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.163, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1511, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1511, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1493, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1507, Val accuracy: 0.962, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1497, Val accuracy: 0.962, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1477, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.149, Val accuracy: 0.9624, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1501, Val accuracy: 0.9612, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1488, Val accuracy: 0.9616, Best Epoch: 8\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1501, Val accuracy: 0.9608, Best Epoch: 8\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1504, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1467, Val accuracy: 0.9627, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1465, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1467, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1459, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1459, Val accuracy: 0.9627, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1477, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1475, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1444, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1434, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1485, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1438, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1426, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1452, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1445, Val accuracy: 0.9604, Best Epoch: 17\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1414, Val accuracy: 0.9608, Best Epoch: 17\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1444, Val accuracy: 0.9612, Best Epoch: 17\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1435, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1421, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1439, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1415, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1445, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1436, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1427, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1448, Val accuracy: 0.9612, Best Epoch: 17\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1402, Val accuracy: 0.962, Best Epoch: 17\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1405, Val accuracy: 0.9616, Best Epoch: 17\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.1399, Val accuracy: 0.9624, Best Epoch: 17\n",
            "Best model found on Epoch 17 (Update 2414). Val accuracy: 0.9627353054168267\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1651, Val accuracy: 0.9662, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1532, Val accuracy: 0.9662, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.152, Val accuracy: 0.9662, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1508, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1512, Val accuracy: 0.9662, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1514, Val accuracy: 0.9662, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1502, Val accuracy: 0.9662, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1486, Val accuracy: 0.9662, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1504, Val accuracy: 0.9662, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1494, Val accuracy: 0.9662, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1494, Val accuracy: 0.9658, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1495, Val accuracy: 0.9662, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1468, Val accuracy: 0.9662, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1474, Val accuracy: 0.9658, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1477, Val accuracy: 0.9666, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1484, Val accuracy: 0.9666, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1492, Val accuracy: 0.9666, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1463, Val accuracy: 0.9662, Best Epoch: 17\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.148, Val accuracy: 0.967, Best Epoch: 19\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1471, Val accuracy: 0.9662, Best Epoch: 19\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1455, Val accuracy: 0.9654, Best Epoch: 19\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1457, Val accuracy: 0.967, Best Epoch: 22\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1497, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1466, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1467, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1436, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1459, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1459, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1442, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1443, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1457, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1463, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.145, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1436, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1442, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1427, Val accuracy: 0.9662, Best Epoch: 22\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1417, Val accuracy: 0.965, Best Epoch: 22\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1437, Val accuracy: 0.9666, Best Epoch: 22\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.142, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.142, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1423, Val accuracy: 0.9666, Best Epoch: 22\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1435, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.1465, Val accuracy: 0.965, Best Epoch: 22\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.1397, Val accuracy: 0.965, Best Epoch: 22\n",
            "Epoch 45 (Update 6390).\tTrain loss: 0.1408, Val accuracy: 0.9658, Best Epoch: 22\n",
            "Epoch 46 (Update 6532).\tTrain loss: 0.1405, Val accuracy: 0.9643, Best Epoch: 22\n",
            "Epoch 47 (Update 6674).\tTrain loss: 0.1419, Val accuracy: 0.965, Best Epoch: 22\n",
            "Epoch 48 (Update 6816).\tTrain loss: 0.1398, Val accuracy: 0.9647, Best Epoch: 22\n",
            "Best model found on Epoch 22 (Update 3124). Val accuracy: 0.9669611986169804\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1661, Val accuracy: 0.9677, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.156, Val accuracy: 0.9662, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1531, Val accuracy: 0.967, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1543, Val accuracy: 0.9677, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1516, Val accuracy: 0.9673, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1512, Val accuracy: 0.9673, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1511, Val accuracy: 0.967, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1511, Val accuracy: 0.967, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1517, Val accuracy: 0.9673, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1502, Val accuracy: 0.967, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1496, Val accuracy: 0.9677, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1493, Val accuracy: 0.9677, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1496, Val accuracy: 0.9673, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1509, Val accuracy: 0.967, Best Epoch: 12\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1499, Val accuracy: 0.967, Best Epoch: 12\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1467, Val accuracy: 0.9677, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1505, Val accuracy: 0.9677, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.149, Val accuracy: 0.9662, Best Epoch: 17\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1476, Val accuracy: 0.9662, Best Epoch: 17\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1482, Val accuracy: 0.9662, Best Epoch: 17\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1476, Val accuracy: 0.9666, Best Epoch: 17\n",
            "Best model found on Epoch 17 (Update 2414). Val accuracy: 0.9677295428351902\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1643, Val accuracy: 0.9647, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1528, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1523, Val accuracy: 0.9639, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1518, Val accuracy: 0.965, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1499, Val accuracy: 0.9639, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1506, Val accuracy: 0.965, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1495, Val accuracy: 0.9639, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1489, Val accuracy: 0.9631, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.148, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1476, Val accuracy: 0.965, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1476, Val accuracy: 0.9647, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1469, Val accuracy: 0.9647, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.149, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1471, Val accuracy: 0.965, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.148, Val accuracy: 0.9643, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1491, Val accuracy: 0.965, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1478, Val accuracy: 0.9643, Best Epoch: 16\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1459, Val accuracy: 0.9658, Best Epoch: 18\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1461, Val accuracy: 0.9635, Best Epoch: 18\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1452, Val accuracy: 0.9647, Best Epoch: 18\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1467, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1465, Val accuracy: 0.965, Best Epoch: 18\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1436, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1442, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1445, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1436, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1443, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1431, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1418, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1451, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1449, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1435, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1428, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1449, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1426, Val accuracy: 0.965, Best Epoch: 18\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1416, Val accuracy: 0.9647, Best Epoch: 18\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1427, Val accuracy: 0.9654, Best Epoch: 18\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1399, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.1445, Val accuracy: 0.9635, Best Epoch: 18\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.1419, Val accuracy: 0.9631, Best Epoch: 18\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1419, Val accuracy: 0.9627, Best Epoch: 18\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1397, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.1419, Val accuracy: 0.9643, Best Epoch: 18\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.1401, Val accuracy: 0.9631, Best Epoch: 18\n",
            "Epoch 45 (Update 6390).\tTrain loss: 0.1412, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Epoch 46 (Update 6532).\tTrain loss: 0.1406, Val accuracy: 0.9639, Best Epoch: 18\n",
            "Best model found on Epoch 18 (Update 2556). Val accuracy: 0.9658086822896658\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1621, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1514, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1527, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.15, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1499, Val accuracy: 0.9616, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1482, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1492, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1493, Val accuracy: 0.9616, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.148, Val accuracy: 0.9616, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1478, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1466, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.148, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1477, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1463, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1461, Val accuracy: 0.9612, Best Epoch: 10\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.147, Val accuracy: 0.9612, Best Epoch: 10\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1475, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1451, Val accuracy: 0.9608, Best Epoch: 10\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1445, Val accuracy: 0.9608, Best Epoch: 10\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1468, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1436, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.144, Val accuracy: 0.9616, Best Epoch: 10\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1432, Val accuracy: 0.9627, Best Epoch: 23\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1432, Val accuracy: 0.96, Best Epoch: 23\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1439, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1433, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.1445, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1422, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.144, Val accuracy: 0.9604, Best Epoch: 23\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1415, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1424, Val accuracy: 0.962, Best Epoch: 23\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.142, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1412, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1414, Val accuracy: 0.96, Best Epoch: 23\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.1425, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1418, Val accuracy: 0.9604, Best Epoch: 23\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1415, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1418, Val accuracy: 0.9604, Best Epoch: 23\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.1425, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.1408, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1393, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1407, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.1416, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.14, Val accuracy: 0.9604, Best Epoch: 23\n",
            "Epoch 45 (Update 6390).\tTrain loss: 0.1405, Val accuracy: 0.962, Best Epoch: 23\n",
            "Epoch 46 (Update 6532).\tTrain loss: 0.1383, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 47 (Update 6674).\tTrain loss: 0.1396, Val accuracy: 0.962, Best Epoch: 23\n",
            "Epoch 48 (Update 6816).\tTrain loss: 0.138, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 49 (Update 6958).\tTrain loss: 0.1378, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 50 (Update 7100).\tTrain loss: 0.1389, Val accuracy: 0.9616, Best Epoch: 23\n",
            "Epoch 51 (Update 7242).\tTrain loss: 0.1375, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 52 (Update 7384).\tTrain loss: 0.1378, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Epoch 53 (Update 7526).\tTrain loss: 0.1377, Val accuracy: 0.9608, Best Epoch: 23\n",
            "Epoch 54 (Update 7668).\tTrain loss: 0.1389, Val accuracy: 0.9612, Best Epoch: 23\n",
            "Best model found on Epoch 23 (Update 3266). Val accuracy: 0.9627353054168267\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Post_frequency\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1619, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1514, Val accuracy: 0.9624, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.15, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1515, Val accuracy: 0.9627, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1496, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1504, Val accuracy: 0.9631, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1497, Val accuracy: 0.9624, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1496, Val accuracy: 0.9627, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1479, Val accuracy: 0.9635, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1469, Val accuracy: 0.9627, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1474, Val accuracy: 0.9631, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1474, Val accuracy: 0.9627, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1473, Val accuracy: 0.9631, Best Epoch: 9\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1462, Val accuracy: 0.9635, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1479, Val accuracy: 0.9635, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1463, Val accuracy: 0.9635, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1474, Val accuracy: 0.9631, Best Epoch: 16\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1465, Val accuracy: 0.9624, Best Epoch: 16\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1488, Val accuracy: 0.9631, Best Epoch: 16\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1438, Val accuracy: 0.9635, Best Epoch: 20\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1428, Val accuracy: 0.9635, Best Epoch: 21\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.1437, Val accuracy: 0.9631, Best Epoch: 21\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1448, Val accuracy: 0.9627, Best Epoch: 21\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1439, Val accuracy: 0.9627, Best Epoch: 21\n",
            "Epoch 25 (Update 3550).\tTrain loss: 0.1443, Val accuracy: 0.9631, Best Epoch: 21\n",
            "Epoch 26 (Update 3692).\tTrain loss: 0.1459, Val accuracy: 0.9616, Best Epoch: 21\n",
            "Epoch 27 (Update 3834).\tTrain loss: 0.145, Val accuracy: 0.9631, Best Epoch: 21\n",
            "Epoch 28 (Update 3976).\tTrain loss: 0.1434, Val accuracy: 0.9631, Best Epoch: 21\n",
            "Epoch 29 (Update 4118).\tTrain loss: 0.1415, Val accuracy: 0.9631, Best Epoch: 21\n",
            "Epoch 30 (Update 4260).\tTrain loss: 0.1422, Val accuracy: 0.9635, Best Epoch: 30\n",
            "Epoch 31 (Update 4402).\tTrain loss: 0.1415, Val accuracy: 0.9639, Best Epoch: 31\n",
            "Epoch 32 (Update 4544).\tTrain loss: 0.1416, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 33 (Update 4686).\tTrain loss: 0.1411, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 34 (Update 4828).\tTrain loss: 0.1414, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 35 (Update 4970).\tTrain loss: 0.14, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 36 (Update 5112).\tTrain loss: 0.1408, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 37 (Update 5254).\tTrain loss: 0.1415, Val accuracy: 0.9635, Best Epoch: 31\n",
            "Epoch 38 (Update 5396).\tTrain loss: 0.1415, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 39 (Update 5538).\tTrain loss: 0.1393, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 40 (Update 5680).\tTrain loss: 0.142, Val accuracy: 0.9635, Best Epoch: 31\n",
            "Epoch 41 (Update 5822).\tTrain loss: 0.1407, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 42 (Update 5964).\tTrain loss: 0.1394, Val accuracy: 0.9616, Best Epoch: 31\n",
            "Epoch 43 (Update 6106).\tTrain loss: 0.1402, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 44 (Update 6248).\tTrain loss: 0.14, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 45 (Update 6390).\tTrain loss: 0.1393, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 46 (Update 6532).\tTrain loss: 0.14, Val accuracy: 0.9624, Best Epoch: 31\n",
            "Epoch 47 (Update 6674).\tTrain loss: 0.1403, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 48 (Update 6816).\tTrain loss: 0.138, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 49 (Update 6958).\tTrain loss: 0.1391, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 50 (Update 7100).\tTrain loss: 0.1377, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 51 (Update 7242).\tTrain loss: 0.1392, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 52 (Update 7384).\tTrain loss: 0.1388, Val accuracy: 0.9635, Best Epoch: 31\n",
            "Epoch 53 (Update 7526).\tTrain loss: 0.136, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 54 (Update 7668).\tTrain loss: 0.1412, Val accuracy: 0.9635, Best Epoch: 31\n",
            "Epoch 55 (Update 7810).\tTrain loss: 0.1387, Val accuracy: 0.9612, Best Epoch: 31\n",
            "Epoch 56 (Update 7952).\tTrain loss: 0.1365, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 57 (Update 8094).\tTrain loss: 0.1363, Val accuracy: 0.9624, Best Epoch: 31\n",
            "Epoch 58 (Update 8236).\tTrain loss: 0.1372, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 59 (Update 8378).\tTrain loss: 0.136, Val accuracy: 0.9612, Best Epoch: 31\n",
            "Epoch 60 (Update 8520).\tTrain loss: 0.1371, Val accuracy: 0.9612, Best Epoch: 31\n",
            "Epoch 61 (Update 8662).\tTrain loss: 0.1353, Val accuracy: 0.962, Best Epoch: 31\n",
            "Epoch 62 (Update 8804).\tTrain loss: 0.1378, Val accuracy: 0.9631, Best Epoch: 31\n",
            "Epoch 63 (Update 8946).\tTrain loss: 0.1358, Val accuracy: 0.9627, Best Epoch: 31\n",
            "Epoch 64 (Update 9088).\tTrain loss: 0.1369, Val accuracy: 0.9608, Best Epoch: 31\n",
            "Epoch 65 (Update 9230).\tTrain loss: 0.134, Val accuracy: 0.9616, Best Epoch: 31\n",
            "Epoch 66 (Update 9372).\tTrain loss: 0.1347, Val accuracy: 0.9612, Best Epoch: 31\n",
            "Best model found on Epoch 31 (Update 4402). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (11 vector, 2 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0): Embedding(33, 11)\n",
            "    (1): Embedding(56, 15)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1637, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1528, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1516, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1496, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1494, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1506, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1485, Val accuracy: 0.9597, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1481, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1503, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1474, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.147, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1471, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1481, Val accuracy: 0.9608, Best Epoch: 3\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1489, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1478, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1453, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1455, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1456, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1455, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 20 (Update 2840).\tTrain loss: 0.1439, Val accuracy: 0.9612, Best Epoch: 3\n",
            "Epoch 21 (Update 2982).\tTrain loss: 0.1445, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 22 (Update 3124).\tTrain loss: 0.143, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Epoch 23 (Update 3266).\tTrain loss: 0.1443, Val accuracy: 0.9608, Best Epoch: 3\n",
            "Epoch 24 (Update 3408).\tTrain loss: 0.1447, Val accuracy: 0.9616, Best Epoch: 3\n",
            "Best model found on Epoch 3 (Update 426). Val accuracy: 0.9627353054168267\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/dataset_train.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/dataset_val.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/utils/model_template.pkl\n",
            "\tFitting 16 child models (S1F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1669, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1576, Val accuracy: 0.9616, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.162, Val accuracy: 0.9608, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1583, Val accuracy: 0.9616, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1593, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1579, Val accuracy: 0.9608, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1572, Val accuracy: 0.9604, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1575, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1566, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1567, Val accuracy: 0.9608, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1561, Val accuracy: 0.9616, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1567, Val accuracy: 0.9612, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1569, Val accuracy: 0.9604, Best Epoch: 11\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1559, Val accuracy: 0.9608, Best Epoch: 11\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1557, Val accuracy: 0.9616, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1552, Val accuracy: 0.9597, Best Epoch: 15\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1554, Val accuracy: 0.9616, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 17 (Update 2414). Val accuracy: 0.9615975422427036\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1679, Val accuracy: 0.9639, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1578, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1611, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1591, Val accuracy: 0.9635, Best Epoch: 1\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1595, Val accuracy: 0.9608, Best Epoch: 1\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1592, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.158, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1572, Val accuracy: 0.962, Best Epoch: 1\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1571, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1575, Val accuracy: 0.9635, Best Epoch: 1\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1566, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1561, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1577, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1565, Val accuracy: 0.9616, Best Epoch: 1\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1569, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1561, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1566, Val accuracy: 0.9635, Best Epoch: 1\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 17)\n",
            "Best model found on Epoch 1 (Update 142). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1703, Val accuracy: 0.9712, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1638, Val accuracy: 0.97, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1649, Val accuracy: 0.9716, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1644, Val accuracy: 0.9708, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1627, Val accuracy: 0.9712, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1626, Val accuracy: 0.9639, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.162, Val accuracy: 0.9704, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1617, Val accuracy: 0.9712, Best Epoch: 3\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1624, Val accuracy: 0.9704, Best Epoch: 3\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1613, Val accuracy: 0.9716, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1617, Val accuracy: 0.972, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1614, Val accuracy: 0.9708, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1622, Val accuracy: 0.9708, Best Epoch: 11\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1615, Val accuracy: 0.9708, Best Epoch: 11\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1605, Val accuracy: 0.9708, Best Epoch: 11\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1618, Val accuracy: 0.9712, Best Epoch: 11\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2372 (Epoch 16))\n",
            "Best model found on Epoch 11 (Update 1562). Val accuracy: 0.9719554360353438\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1689, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1581, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1623, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1618, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1607, Val accuracy: 0.9658, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1589, Val accuracy: 0.9666, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1599, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1591, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1589, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1572, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1591, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1591, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1581, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1588, Val accuracy: 0.9658, Best Epoch: 6\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1575, Val accuracy: 0.9654, Best Epoch: 6\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1571, Val accuracy: 0.9643, Best Epoch: 6\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2323 (Epoch 16))\n",
            "Best model found on Epoch 6 (Update 852). Val accuracy: 0.9665770265078756\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1655, Val accuracy: 0.957, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1568, Val accuracy: 0.9562, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1591, Val accuracy: 0.9574, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1587, Val accuracy: 0.9581, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1579, Val accuracy: 0.9589, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1569, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1573, Val accuracy: 0.9581, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1558, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1555, Val accuracy: 0.9581, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.156, Val accuracy: 0.9577, Best Epoch: 5\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1545, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1552, Val accuracy: 0.9577, Best Epoch: 5\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1556, Val accuracy: 0.9585, Best Epoch: 5\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1545, Val accuracy: 0.957, Best Epoch: 5\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1548, Val accuracy: 0.9589, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1549, Val accuracy: 0.9581, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2350 (Epoch 16))\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.958893584325778\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1677, Val accuracy: 0.9643, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1601, Val accuracy: 0.965, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1623, Val accuracy: 0.9643, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1619, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1606, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1597, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1588, Val accuracy: 0.9647, Best Epoch: 2\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1581, Val accuracy: 0.9643, Best Epoch: 2\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1593, Val accuracy: 0.965, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1573, Val accuracy: 0.9635, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.158, Val accuracy: 0.9639, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1574, Val accuracy: 0.9639, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1573, Val accuracy: 0.9647, Best Epoch: 9\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1562, Val accuracy: 0.9643, Best Epoch: 9\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1561, Val accuracy: 0.9639, Best Epoch: 9\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.161, Val accuracy: 0.9647, Best Epoch: 9\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2398 (Epoch 16))\n",
            "Best model found on Epoch 9 (Update 1278). Val accuracy: 0.9650403380714561\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1657, Val accuracy: 0.9627, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1593, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1625, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1597, Val accuracy: 0.9627, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1601, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.158, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1591, Val accuracy: 0.9635, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1583, Val accuracy: 0.9631, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1587, Val accuracy: 0.9612, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1586, Val accuracy: 0.9635, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1583, Val accuracy: 0.9635, Best Epoch: 11\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1587, Val accuracy: 0.9624, Best Epoch: 11\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1563, Val accuracy: 0.9635, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1557, Val accuracy: 0.9631, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.157, Val accuracy: 0.9635, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1566, Val accuracy: 0.9627, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2408 (Epoch 16))\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.9635036496350365\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1672, Val accuracy: 0.9624, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1582, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1627, Val accuracy: 0.9643, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1627, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1603, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1595, Val accuracy: 0.9647, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1586, Val accuracy: 0.9647, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1593, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1587, Val accuracy: 0.9643, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1587, Val accuracy: 0.9647, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1574, Val accuracy: 0.9643, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1576, Val accuracy: 0.9647, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1585, Val accuracy: 0.9639, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1577, Val accuracy: 0.9647, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1575, Val accuracy: 0.965, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1583, Val accuracy: 0.9639, Best Epoch: 15\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.157, Val accuracy: 0.9647, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2452 (Epoch 17))\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.9650403380714561\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18221 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1655, Val accuracy: 0.9562, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1587, Val accuracy: 0.962, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1607, Val accuracy: 0.9639, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.161, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1605, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1586, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.159, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1577, Val accuracy: 0.9639, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1573, Val accuracy: 0.9639, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1583, Val accuracy: 0.9639, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1582, Val accuracy: 0.9635, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1576, Val accuracy: 0.9643, Best Epoch: 12\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1569, Val accuracy: 0.9631, Best Epoch: 12\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1577, Val accuracy: 0.962, Best Epoch: 12\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1569, Val accuracy: 0.9643, Best Epoch: 15\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.157, Val accuracy: 0.9635, Best Epoch: 15\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2403 (Epoch 16))\n",
            "Best model found on Epoch 15 (Update 2130). Val accuracy: 0.9642857142857143\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1673, Val accuracy: 0.96, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1592, Val accuracy: 0.9604, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1616, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1606, Val accuracy: 0.962, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1601, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1591, Val accuracy: 0.962, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1577, Val accuracy: 0.962, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1572, Val accuracy: 0.962, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1566, Val accuracy: 0.9608, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1562, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1567, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1577, Val accuracy: 0.9612, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.157, Val accuracy: 0.9624, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.157, Val accuracy: 0.9627, Best Epoch: 14\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1564, Val accuracy: 0.9612, Best Epoch: 14\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1558, Val accuracy: 0.962, Best Epoch: 14\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1561, Val accuracy: 0.9616, Best Epoch: 14\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2470 (Epoch 17))\n",
            "Best model found on Epoch 14 (Update 1988). Val accuracy: 0.9627353054168267\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1708, Val accuracy: 0.9662, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1602, Val accuracy: 0.965, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1619, Val accuracy: 0.9666, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1618, Val accuracy: 0.967, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.161, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1595, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1602, Val accuracy: 0.9658, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.159, Val accuracy: 0.9658, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1589, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1583, Val accuracy: 0.9662, Best Epoch: 4\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1584, Val accuracy: 0.9666, Best Epoch: 4\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1578, Val accuracy: 0.9666, Best Epoch: 4\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1577, Val accuracy: 0.9666, Best Epoch: 4\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1572, Val accuracy: 0.9658, Best Epoch: 4\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1576, Val accuracy: 0.9666, Best Epoch: 4\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1573, Val accuracy: 0.9662, Best Epoch: 4\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2396 (Epoch 16))\n",
            "Best model found on Epoch 4 (Update 568). Val accuracy: 0.9669611986169804\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1701, Val accuracy: 0.9631, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1622, Val accuracy: 0.9662, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1645, Val accuracy: 0.967, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1641, Val accuracy: 0.9666, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1619, Val accuracy: 0.9673, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1607, Val accuracy: 0.9673, Best Epoch: 6\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1603, Val accuracy: 0.9673, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1612, Val accuracy: 0.9673, Best Epoch: 8\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1592, Val accuracy: 0.967, Best Epoch: 8\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1603, Val accuracy: 0.9677, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1594, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1591, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1586, Val accuracy: 0.9666, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1593, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1596, Val accuracy: 0.967, Best Epoch: 10\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1578, Val accuracy: 0.9677, Best Epoch: 16\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1589, Val accuracy: 0.9666, Best Epoch: 16\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2525 (Epoch 17))\n",
            "Best model found on Epoch 16 (Update 2272). Val accuracy: 0.9677295428351902\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1684, Val accuracy: 0.9654, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1602, Val accuracy: 0.9654, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1627, Val accuracy: 0.9658, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.162, Val accuracy: 0.9654, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1608, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.16, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.158, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1582, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.157, Val accuracy: 0.9643, Best Epoch: 3\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1564, Val accuracy: 0.9643, Best Epoch: 3\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1578, Val accuracy: 0.9647, Best Epoch: 3\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1565, Val accuracy: 0.965, Best Epoch: 3\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1575, Val accuracy: 0.9658, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1571, Val accuracy: 0.965, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1569, Val accuracy: 0.9654, Best Epoch: 13\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1567, Val accuracy: 0.9647, Best Epoch: 13\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1562, Val accuracy: 0.9662, Best Epoch: 17\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1573, Val accuracy: 0.965, Best Epoch: 17\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2634 (Epoch 18))\n",
            "Best model found on Epoch 17 (Update 2414). Val accuracy: 0.9661928543987707\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1654, Val accuracy: 0.9608, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1584, Val accuracy: 0.9604, Best Epoch: 1\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1608, Val accuracy: 0.9624, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1597, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1596, Val accuracy: 0.962, Best Epoch: 3\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1578, Val accuracy: 0.9593, Best Epoch: 3\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1582, Val accuracy: 0.9624, Best Epoch: 7\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1578, Val accuracy: 0.9616, Best Epoch: 7\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1582, Val accuracy: 0.9608, Best Epoch: 7\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1571, Val accuracy: 0.9627, Best Epoch: 10\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1569, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1564, Val accuracy: 0.9624, Best Epoch: 10\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1561, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1552, Val accuracy: 0.9608, Best Epoch: 10\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1552, Val accuracy: 0.96, Best Epoch: 10\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.157, Val accuracy: 0.9608, Best Epoch: 10\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1555, Val accuracy: 0.962, Best Epoch: 10\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1567, Val accuracy: 0.962, Best Epoch: 10\n",
            "\tRan out of time, stopping training early. (Stopped on Update 2610 (Epoch 18))\n",
            "Best model found on Epoch 10 (Update 1420). Val accuracy: 0.9627353054168267\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.167, Val accuracy: 0.9635, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1581, Val accuracy: 0.9635, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1616, Val accuracy: 0.9635, Best Epoch: 3\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1608, Val accuracy: 0.9631, Best Epoch: 3\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1582, Val accuracy: 0.9639, Best Epoch: 5\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1579, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1575, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1574, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1558, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1556, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1561, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.1566, Val accuracy: 0.9624, Best Epoch: 5\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1561, Val accuracy: 0.9631, Best Epoch: 5\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1564, Val accuracy: 0.9608, Best Epoch: 5\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1567, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1559, Val accuracy: 0.9635, Best Epoch: 5\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1564, Val accuracy: 0.9627, Best Epoch: 5\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1561, Val accuracy: 0.9635, Best Epoch: 5\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 18)\n",
            "Best model found on Epoch 5 (Update 710). Val accuracy: 0.9638878217441413\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"Time_spent_Alone\",\n",
            "        \"Social_event_attendance\",\n",
            "        \"Going_outside\",\n",
            "        \"Friends_circle_size\",\n",
            "        \"Social_Activity_Score\",\n",
            "        \"Introversion_Score\",\n",
            "        \"Friends_Activity_Ratio\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"Post_frequency\",\n",
            "        \"Digital_Social_Ratio\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"Fear_Alone_Inter\",\n",
            "        \"Social_Fear_Ratio\"\n",
            "    ],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": [\n",
            "        \"Stage_fear\",\n",
            "        \"Drained_after_socializing\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18222 examples, 13 features (13 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): BatchNorm1d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Linear(in_features=53, out_features=128, bias=True)\n",
            "    (2): Tanh()\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (6): Tanh()\n",
            "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): Tanh()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 142).\tTrain loss: 0.1673, Val accuracy: 0.9612, Best Epoch: 1\n",
            "Epoch 2 (Update 284).\tTrain loss: 0.1586, Val accuracy: 0.9612, Best Epoch: 2\n",
            "Epoch 3 (Update 426).\tTrain loss: 0.1617, Val accuracy: 0.9608, Best Epoch: 2\n",
            "Epoch 4 (Update 568).\tTrain loss: 0.1591, Val accuracy: 0.9616, Best Epoch: 4\n",
            "Epoch 5 (Update 710).\tTrain loss: 0.1594, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 6 (Update 852).\tTrain loss: 0.1582, Val accuracy: 0.9612, Best Epoch: 4\n",
            "Epoch 7 (Update 994).\tTrain loss: 0.1584, Val accuracy: 0.9597, Best Epoch: 4\n",
            "Epoch 8 (Update 1136).\tTrain loss: 0.1577, Val accuracy: 0.9604, Best Epoch: 4\n",
            "Epoch 9 (Update 1278).\tTrain loss: 0.1578, Val accuracy: 0.962, Best Epoch: 9\n",
            "Epoch 10 (Update 1420).\tTrain loss: 0.1578, Val accuracy: 0.9608, Best Epoch: 9\n",
            "Epoch 11 (Update 1562).\tTrain loss: 0.1565, Val accuracy: 0.9608, Best Epoch: 9\n",
            "Epoch 12 (Update 1704).\tTrain loss: 0.156, Val accuracy: 0.9604, Best Epoch: 9\n",
            "Epoch 13 (Update 1846).\tTrain loss: 0.1562, Val accuracy: 0.9624, Best Epoch: 13\n",
            "Epoch 14 (Update 1988).\tTrain loss: 0.1561, Val accuracy: 0.9612, Best Epoch: 13\n",
            "Epoch 15 (Update 2130).\tTrain loss: 0.1551, Val accuracy: 0.9608, Best Epoch: 13\n",
            "Epoch 16 (Update 2272).\tTrain loss: 0.1557, Val accuracy: 0.9616, Best Epoch: 13\n",
            "Epoch 17 (Update 2414).\tTrain loss: 0.1543, Val accuracy: 0.9581, Best Epoch: 13\n",
            "Epoch 18 (Update 2556).\tTrain loss: 0.1548, Val accuracy: 0.9604, Best Epoch: 13\n",
            "Epoch 19 (Update 2698).\tTrain loss: 0.1547, Val accuracy: 0.9608, Best Epoch: 13\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
            "Best model found on Epoch 13 (Update 1846). Val accuracy: 0.9623511333077218\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "\tStopping HPO to satisfy time limit...\n",
            "Time for NeuralNetTorch_2_BAG_L1 model HPO: 766.6662056446075\n",
            "Best hyperparameter configuration for NeuralNetTorch_2_BAG_L1 model: \n",
            "{'num_epochs': 500, 'epochs_wo_improve': None, 'activation': 'tanh', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3, 'optimizer': 'adam', 'learning_rate': 0.005, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L1/T1 ...\n",
            "\t0.9644\t = Validation score   (accuracy)\n",
            "\t360.27s\t = Training   runtime\n",
            "\t0.7s\t = Validation runtime\n",
            "\t3731.6\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Fitted model: NeuralNetTorch_2_BAG_L1/T2 ...\n",
            "\t0.9643\t = Validation score   (accuracy)\n",
            "\t406.3s\t = Training   runtime\n",
            "\t1.51s\t = Validation runtime\n",
            "\t1725.1\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/KNeighbors_3_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/RandomForest_2_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/XGBoost_2_BAG_L1/T5/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_2_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T3/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/LinearModel_3_BAG_L1/T4/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/utils/oof.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1217.57s of the 10177.93s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 8\n",
            "Ensemble weights: \n",
            "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            " 0.    0.    0.    0.    0.    0.125 0.25  0.375 0.25 ]\n",
            "\t0.11s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'NeuralNetTorch_2_BAG_L1/T1': 0.375, 'NeuralNetTorch_BAG_L1/T2': 0.25, 'NeuralNetTorch_2_BAG_L1/T2': 0.25, 'NeuralNetTorch_BAG_L1/T1': 0.125}\n",
            "\t0.9646\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t432.0\t = Inference  throughput (rows/s | 2604 batch size)\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 1999.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 432.0 rows/s (2604 batch size)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/utils/data/y.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
            "\tthreshold: 0.500\t| val: 0.9646\t| NEW BEST\n",
            "\tthreshold: 0.480\t| val: 0.9644\n",
            "\tthreshold: 0.520\t| val: 0.9646\n",
            "\tthreshold: 0.460\t| val: 0.9644\n",
            "\tthreshold: 0.540\t| val: 0.9646\n",
            "\tthreshold: 0.440\t| val: 0.9643\n",
            "\tthreshold: 0.560\t| val: 0.9645\n",
            "\tthreshold: 0.420\t| val: 0.9643\n",
            "\tthreshold: 0.580\t| val: 0.9645\n",
            "\tthreshold: 0.400\t| val: 0.9642\n",
            "\tthreshold: 0.600\t| val: 0.9645\n",
            "\tthreshold: 0.380\t| val: 0.9643\n",
            "\tthreshold: 0.620\t| val: 0.9646\n",
            "\tthreshold: 0.360\t| val: 0.9641\n",
            "\tthreshold: 0.640\t| val: 0.9645\n",
            "\tthreshold: 0.340\t| val: 0.9641\n",
            "\tthreshold: 0.660\t| val: 0.9644\n",
            "\tthreshold: 0.320\t| val: 0.9641\n",
            "\tthreshold: 0.680\t| val: 0.9644\n",
            "\tthreshold: 0.300\t| val: 0.9640\n",
            "\tthreshold: 0.700\t| val: 0.9643\n",
            "\tthreshold: 0.280\t| val: 0.9639\n",
            "\tthreshold: 0.720\t| val: 0.9643\n",
            "\tthreshold: 0.260\t| val: 0.9639\n",
            "\tthreshold: 0.740\t| val: 0.9642\n",
            "\tthreshold: 0.240\t| val: 0.9638\n",
            "\tthreshold: 0.760\t| val: 0.9642\n",
            "\tthreshold: 0.220\t| val: 0.9637\n",
            "\tthreshold: 0.780\t| val: 0.9639\n",
            "\tthreshold: 0.200\t| val: 0.9636\n",
            "\tthreshold: 0.800\t| val: 0.9637\n",
            "\tthreshold: 0.180\t| val: 0.9635\n",
            "\tthreshold: 0.820\t| val: 0.9633\n",
            "\tthreshold: 0.160\t| val: 0.9631\n",
            "\tthreshold: 0.840\t| val: 0.9628\n",
            "\tthreshold: 0.140\t| val: 0.9627\n",
            "\tthreshold: 0.860\t| val: 0.9615\n",
            "\tthreshold: 0.120\t| val: 0.9624\n",
            "\tthreshold: 0.880\t| val: 0.9566\n",
            "\tthreshold: 0.100\t| val: 0.9617\n",
            "\tthreshold: 0.900\t| val: 0.9402\n",
            "\tthreshold: 0.080\t| val: 0.9607\n",
            "\tthreshold: 0.920\t| val: 0.8978\n",
            "\tthreshold: 0.060\t| val: 0.9555\n",
            "\tthreshold: 0.940\t| val: 0.8084\n",
            "\tthreshold: 0.040\t| val: 0.9064\n",
            "\tthreshold: 0.960\t| val: 0.7333\n",
            "\tthreshold: 0.020\t| val: 0.3928\n",
            "\tthreshold: 0.980\t| val: 0.7253\n",
            "\tthreshold: 0.000\t| val: 0.2747\n",
            "\tthreshold: 1.000\t| val: 0.7253\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tthreshold: 0.501\t| val: 0.9646\n",
            "\tthreshold: 0.502\t| val: 0.9646\n",
            "\tthreshold: 0.503\t| val: 0.9646\n",
            "\tthreshold: 0.504\t| val: 0.9646\n",
            "\tthreshold: 0.505\t| val: 0.9646\n",
            "\tthreshold: 0.506\t| val: 0.9646\n",
            "\tthreshold: 0.507\t| val: 0.9646\n",
            "\tthreshold: 0.508\t| val: 0.9646\n",
            "\tthreshold: 0.509\t| val: 0.9646\n",
            "\tthreshold: 0.510\t| val: 0.9646\n",
            "\tthreshold: 0.511\t| val: 0.9646\n",
            "\tthreshold: 0.512\t| val: 0.9646\n",
            "\tthreshold: 0.513\t| val: 0.9646\n",
            "\tthreshold: 0.514\t| val: 0.9646\n",
            "\tthreshold: 0.515\t| val: 0.9646\n",
            "\tthreshold: 0.516\t| val: 0.9646\n",
            "\tthreshold: 0.517\t| val: 0.9646\n",
            "\tthreshold: 0.518\t| val: 0.9646\n",
            "\tthreshold: 0.519\t| val: 0.9646\n",
            "\tthreshold: 0.499\t| val: 0.9646\n",
            "\tthreshold: 0.498\t| val: 0.9646\n",
            "\tthreshold: 0.497\t| val: 0.9646\n",
            "\tthreshold: 0.496\t| val: 0.9645\n",
            "\tthreshold: 0.495\t| val: 0.9645\n",
            "\tthreshold: 0.494\t| val: 0.9645\n",
            "\tthreshold: 0.493\t| val: 0.9645\n",
            "\tthreshold: 0.492\t| val: 0.9645\n",
            "\tthreshold: 0.491\t| val: 0.9644\n",
            "\tthreshold: 0.490\t| val: 0.9644\n",
            "\tthreshold: 0.489\t| val: 0.9644\n",
            "\tthreshold: 0.488\t| val: 0.9644\n",
            "\tthreshold: 0.487\t| val: 0.9644\n",
            "\tthreshold: 0.486\t| val: 0.9644\n",
            "\tthreshold: 0.485\t| val: 0.9644\n",
            "\tthreshold: 0.484\t| val: 0.9644\n",
            "\tthreshold: 0.483\t| val: 0.9644\n",
            "\tthreshold: 0.482\t| val: 0.9644\n",
            "\tthreshold: 0.481\t| val: 0.9644\n",
            "\tBase Threshold: 0.500\t| val: 0.9646\n",
            "\tBest Threshold: 0.500\t| val: 0.9646\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/models/trainer.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/learner.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/predictor.pkl\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/version.txt with contents \"1.3.1\"\n",
            "Saving /content/AutogluonModels/ag-20250721_125522/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250721_125522\")\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced training completed successfully!\n",
            "Enhanced Model Leaderboard:\n",
            "                        model  score_val eval_metric  pred_time_val  \\\n",
            "0         WeightedEnsemble_L2   0.964562    accuracy       6.030915   \n",
            "1  NeuralNetTorch_2_BAG_L1/T1   0.964370    accuracy       0.697826   \n",
            "2    NeuralNetTorch_BAG_L1/T1   0.964322    accuracy       0.689823   \n",
            "3  NeuralNetTorch_2_BAG_L1/T2   0.964322    accuracy       1.509497   \n",
            "4    NeuralNetTorch_BAG_L1/T2   0.964226    accuracy       3.130223   \n",
            "5         XGBoost_2_BAG_L1/T2   0.963938    accuracy       0.423703   \n",
            "6              XGBoost_BAG_L1   0.963890    accuracy       0.332353   \n",
            "7         XGBoost_2_BAG_L1/T3   0.963842    accuracy       0.479789   \n",
            "8         XGBoost_2_BAG_L1/T5   0.963794    accuracy       0.405962   \n",
            "9       LinearModel_BAG_L1/T2   0.963649    accuracy       0.361423   \n",
            "\n",
            "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
            "0  1532.723500                0.003546           1.050594            2   \n",
            "1   360.270030                0.697826         360.270030            1   \n",
            "2   298.521391                0.689823         298.521391            1   \n",
            "3   406.296582                1.509497         406.296582            1   \n",
            "4   466.584904                3.130223         466.584904            1   \n",
            "5    50.175025                0.423703          50.175025            1   \n",
            "6    52.460432                0.332353          52.460432            1   \n",
            "7    54.130672                0.479789          54.130672            1   \n",
            "8    53.020691                0.405962          53.020691            1   \n",
            "9     5.210967                0.361423           5.210967            1   \n",
            "\n",
            "   can_infer  fit_order  \n",
            "0       True         28  \n",
            "1       True         26  \n",
            "2       True         24  \n",
            "3       True         27  \n",
            "4       True         25  \n",
            "5       True          8  \n",
            "6       True          6  \n",
            "7       True          9  \n",
            "8       True         11  \n",
            "9       True         13  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Validation Accuracy: 0.965186\n",
            "Validation prediction vs actual distribution:\n",
            "Predictions: Personality\n",
            "Extrovert    3024\n",
            "Introvert    1141\n",
            "Name: count, dtype: int64\n",
            "Actual: Personality\n",
            "Extrovert    3021\n",
            "Introvert    1144\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "\t665.14s\t= Expected runtime (133.03s per shuffle set)\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "\t545.85s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Most Important Features:\n",
            "                           importance    stddev   p_value  n  p99_high  \\\n",
            "Time_spent_Alone              0.00096  0.000477  0.005429  5  0.001943   \n",
            "Social_Activity_Score         0.00060  0.000469  0.022956  5  0.001566   \n",
            "Fear_Alone_Inter              0.00040  0.000141  0.001599  5  0.000691   \n",
            "Drained_after_socializing     0.00028  0.000303  0.053969  5  0.000905   \n",
            "Post_frequency                0.00024  0.000297  0.072352  5  0.000851   \n",
            "Social_Fear_Ratio             0.00024  0.000297  0.072352  5  0.000851   \n",
            "Introversion_Score            0.00020  0.000374  0.149007  5  0.000970   \n",
            "Going_outside                 0.00020  0.000245  0.070964  5  0.000704   \n",
            "Stage_fear                    0.00012  0.000110  0.035242  5  0.000346   \n",
            "Friends_Activity_Ratio        0.00008  0.000110  0.088904  5  0.000306   \n",
            "\n",
            "                            p99_low  \n",
            "Time_spent_Alone          -0.000023  \n",
            "Social_Activity_Score     -0.000366  \n",
            "Fear_Alone_Inter           0.000109  \n",
            "Drained_after_socializing -0.000345  \n",
            "Post_frequency            -0.000371  \n",
            "Social_Fear_Ratio         -0.000371  \n",
            "Introversion_Score        -0.000570  \n",
            "Going_outside             -0.000304  \n",
            "Stage_fear                -0.000106  \n",
            "Friends_Activity_Ratio    -0.000146  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Generate Final Predictions and Submission\n",
        "# Generate predictions on test set using the enhanced predictor\n",
        "test_ag = TabularDataset(test_optimized)\n",
        "test_predictions = predictor.predict(test_ag)\n",
        "test_probabilities = predictor.predict_proba(test_ag)\n",
        "\n",
        "print(\"Enhanced AutoGluon predictions generated successfully!\")\n",
        "print(\"Test prediction distribution:\")\n",
        "print(pd.Series(test_predictions).value_counts())\n",
        "\n",
        "# Show confidence distribution\n",
        "if len(test_probabilities.columns) > 1:\n",
        "    confidence_scores = test_probabilities.max(axis=1)\n",
        "    print(f\"Prediction confidence - Mean: {confidence_scores.mean():.4f}, Min: {confidence_scores.min():.4f}, Max: {confidence_scores.max():.4f}\")\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test.index,\n",
        "    'Personality': test_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('enhanced_submission.csv', index=False)\n",
        "print(\"Enhanced submission file 'enhanced_submission.csv' created successfully!\")\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(\"Sample predictions:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "# Save probabilities for potential threshold optimization\n",
        "test_probabilities.index = test.index\n",
        "test_probabilities.to_csv('test_probabilities.csv')\n",
        "print(\"Test probabilities saved to 'test_probabilities.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd3xfvxk_2Uv",
        "outputId": "8128a0f5-8a84-4532-8f60-b3d77d54bb48"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_2_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T1/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/NeuralNetTorch_BAG_L1/T2/model.pkl\n",
            "Loading: /content/AutogluonModels/ag-20250721_125522/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced AutoGluon predictions generated successfully!\n",
            "Test prediction distribution:\n",
            "Personality\n",
            "Extrovert    4615\n",
            "Introvert    1560\n",
            "Name: count, dtype: int64\n",
            "Prediction confidence - Mean: 0.9602, Min: 0.5481, Max: 0.9859\n",
            "Enhanced submission file 'enhanced_submission.csv' created successfully!\n",
            "Submission shape: (6175, 2)\n",
            "Sample predictions:\n",
            "          id Personality\n",
            "id                      \n",
            "18524  18524   Extrovert\n",
            "18525  18525   Introvert\n",
            "18526  18526   Extrovert\n",
            "18527  18527   Extrovert\n",
            "18528  18528   Introvert\n",
            "18529  18529   Extrovert\n",
            "18530  18530   Extrovert\n",
            "18531  18531   Introvert\n",
            "18532  18532   Extrovert\n",
            "18533  18533   Introvert\n",
            "Test probabilities saved to 'test_probabilities.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Advanced Calibration and Threshold Optimization\n",
        "if len(val_probabilities.columns) > 1:\n",
        "    try:\n",
        "        # Get validation probabilities for threshold optimization\n",
        "        val_probs = val_probabilities.iloc[:, 1].values  # Positive class (adjust index if needed)\n",
        "\n",
        "        # Advanced threshold optimization\n",
        "        def optimize_threshold_advanced(y_true, y_prob):\n",
        "            thresholds = np.arange(0.1, 0.9, 0.005)  # Finer granularity\n",
        "            best_accuracy = 0\n",
        "            best_threshold = 0.5\n",
        "            threshold_scores = []\n",
        "\n",
        "            # Create label encoder for consistent comparison\n",
        "            le = LabelEncoder()\n",
        "            le.fit(['Extrovert', 'Introvert'])  # Ensure consistent mapping\n",
        "            y_true_encoded = le.transform(y_true)\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                y_pred_binary = (y_prob >= threshold).astype(int)\n",
        "                accuracy = accuracy_score(y_true_encoded, y_pred_binary)\n",
        "                threshold_scores.append((threshold, accuracy))\n",
        "\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_threshold = threshold\n",
        "\n",
        "            return best_threshold, best_accuracy, threshold_scores\n",
        "\n",
        "        optimal_threshold, optimal_accuracy, threshold_scores = optimize_threshold_advanced(y_val_final, val_probs)\n",
        "\n",
        "        print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
        "        print(f\"Optimal validation accuracy: {optimal_accuracy:.6f}\")\n",
        "\n",
        "        # Apply optimal threshold to test predictions\n",
        "        test_probs = test_probabilities.iloc[:, 1].values\n",
        "        test_predictions_optimized = (test_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "        # Map back to original labels\n",
        "        le = LabelEncoder()\n",
        "        le.fit(['Extrovert', 'Introvert'])\n",
        "        test_predictions_final = le.inverse_transform(test_predictions_optimized)\n",
        "\n",
        "        # Create optimized submission\n",
        "        submission_optimized = pd.DataFrame({\n",
        "            'id': test.index,\n",
        "            'Personality': test_predictions_final\n",
        "        })\n",
        "\n",
        "        submission_optimized.to_csv('submission_threshold_optimized.csv', index=False)\n",
        "\n",
        "        print(\"Threshold-optimized submission created!\")\n",
        "        print(\"Optimized test prediction distribution:\")\n",
        "        print(pd.Series(test_predictions_final).value_counts())\n",
        "\n",
        "        # Compare standard vs optimized predictions\n",
        "        prediction_changes = sum(test_predictions != test_predictions_final)\n",
        "        print(f\"Predictions changed by threshold optimization: {prediction_changes} out of {len(test_predictions)}\")\n",
        "\n",
        "        # Temperature Calibration (additional enhancement)\n",
        "        class TemperatureScaler:\n",
        "            def __init__(self):\n",
        "                self.temperature = 1.0\n",
        "\n",
        "            def fit(self, logits, y_true):\n",
        "                from scipy.optimize import minimize_scalar\n",
        "\n",
        "                def objective(temp):\n",
        "                    calibrated_probs = self.calibrate_probs(logits, temp)\n",
        "                    # Use log loss as calibration metric\n",
        "                    le = LabelEncoder()\n",
        "                    y_encoded = le.fit_transform(y_true)\n",
        "                    loss = -np.mean(y_encoded * np.log(calibrated_probs + 1e-15) +\n",
        "                                   (1 - y_encoded) * np.log(1 - calibrated_probs + 1e-15))\n",
        "                    return loss\n",
        "\n",
        "                result = minimize_scalar(objective, bounds=(0.1, 5.0), method='bounded')\n",
        "                self.temperature = result.x\n",
        "                return self\n",
        "\n",
        "            def calibrate_probs(self, logits, temperature):\n",
        "                return 1 / (1 + np.exp(-logits / temperature))\n",
        "\n",
        "            def predict_proba(self, logits):\n",
        "                return self.calibrate_probs(logits, self.temperature)\n",
        "\n",
        "        # Apply temperature calibration\n",
        "        temp_scaler = TemperatureScaler()\n",
        "        # Convert probabilities to logits for calibration\n",
        "        val_logits = np.log(val_probs / (1 - val_probs + 1e-15))\n",
        "        temp_scaler.fit(val_logits, y_val_final)\n",
        "\n",
        "        print(f\"Optimal temperature: {temp_scaler.temperature:.4f}\")\n",
        "\n",
        "        # Apply to test set\n",
        "        test_logits = np.log(test_probs / (1 - test_probs + 1e-15))\n",
        "        test_probs_calibrated = temp_scaler.predict_proba(test_logits)\n",
        "        test_predictions_temp_calibrated = (test_probs_calibrated >= optimal_threshold).astype(int)\n",
        "        test_predictions_temp_final = le.inverse_transform(test_predictions_temp_calibrated)\n",
        "\n",
        "        # Create temperature calibrated submission\n",
        "        submission_temp_calibrated = pd.DataFrame({\n",
        "            'id': test.index,\n",
        "            'Personality': test_predictions_temp_final\n",
        "        })\n",
        "\n",
        "        submission_temp_calibrated.to_csv('submission_temp_calibrated.csv', index=False)\n",
        "        print(\"Temperature calibrated submission created!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Advanced calibration failed: {e}\")\n",
        "        print(\"Using standard predictions\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping calibration - single probability column detected\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gu29xEaGqeU",
        "outputId": "3f9d443c-9153-496b-cfaf-e308d4edcd28"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal threshold: 0.6600\n",
            "Optimal validation accuracy: 0.965906\n",
            "Threshold-optimized submission created!\n",
            "Optimized test prediction distribution:\n",
            "Extrovert    4618\n",
            "Introvert    1557\n",
            "Name: count, dtype: int64\n",
            "Predictions changed by threshold optimization: 3 out of 6175\n",
            "Optimal temperature: 0.9340\n",
            "Temperature calibrated submission created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Enhanced Cross-Validation for Performance Verification\n",
        "\n",
        "!pip install autogluon.tabular[catboost]==1.3.1\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def enhanced_cv_evaluation(data, n_splits=5):\n",
        "    \"\"\"Robust CV evaluation to verify performance and detect overfitting\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    cv_scores = []\n",
        "    cv_detailed_results = []\n",
        "\n",
        "    print(f\"Running {n_splits}-fold cross-validation for performance verification...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(data.drop('Personality', axis=1), data['Personality'])):\n",
        "        print(f\"Training fold {fold+1}/{n_splits}...\")\n",
        "\n",
        "        train_fold = data.iloc[train_idx]\n",
        "        val_fold = data.iloc[val_idx]\n",
        "\n",
        "        # Use efficient configuration for CV\n",
        "        fold_predictor = TabularPredictor(\n",
        "            label='Personality',\n",
        "            path=f'cv_fold_{fold}',\n",
        "            verbosity=1\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            fold_predictor.fit(\n",
        "                TabularDataset(train_fold),\n",
        "                time_limit=1800,  # 30 minutes per fold\n",
        "                presets='high_quality',\n",
        "                hyperparameters={\n",
        "                    'XGB': {\n",
        "                        'n_estimators': 200,\n",
        "                        'max_depth': 8,\n",
        "                        'learning_rate': 0.05,\n",
        "                        'scale_pos_weight': class_weight_ratio\n",
        "                    },\n",
        "                    'RF': {\n",
        "                        'n_estimators': 150,\n",
        "                        'class_weight': 'balanced'\n",
        "                    },\n",
        "                    'CAT': {\n",
        "                        'iterations': 300,\n",
        "                        'depth': 8,\n",
        "                        'class_weights': [1, class_weight_ratio]\n",
        "                    }\n",
        "                },\n",
        "                num_bag_folds=3,\n",
        "                num_stack_levels=2\n",
        "            )\n",
        "\n",
        "            # Evaluate fold\n",
        "            val_result = fold_predictor.evaluate(TabularDataset(val_fold), silent=True)\n",
        "            val_accuracy = val_result['accuracy']\n",
        "\n",
        "            # Get predictions for detailed analysis\n",
        "            val_predictions = fold_predictor.predict(val_fold.drop('Personality', axis=1))\n",
        "            val_pred_dist = pd.Series(val_predictions).value_counts()\n",
        "            val_actual_dist = pd.Series(val_fold['Personality']).value_counts()\n",
        "\n",
        "            cv_scores.append(val_accuracy)\n",
        "            cv_detailed_results.append({\n",
        "                'fold': fold + 1,\n",
        "                'accuracy': val_accuracy,\n",
        "                'pred_dist': val_pred_dist,\n",
        "                'actual_dist': val_actual_dist\n",
        "            })\n",
        "\n",
        "            print(f\"Fold {fold+1} accuracy: {val_accuracy:.6f}\")\n",
        "            print(f\"  Predictions: {dict(val_pred_dist)}\")\n",
        "            print(f\"  Actual:      {dict(val_actual_dist)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Fold {fold+1} failed: {e}\")\n",
        "            cv_scores.append(0.0)  # Assign low score to failed folds\n",
        "\n",
        "    # Calculate CV statistics\n",
        "    cv_mean = np.mean(cv_scores)\n",
        "    cv_std = np.std(cv_scores)\n",
        "    cv_min = np.min(cv_scores)\n",
        "    cv_max = np.max(cv_scores)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Mean Accuracy:        {cv_mean:.6f}\")\n",
        "    print(f\"Standard Deviation:   {cv_std:.6f}\")\n",
        "    print(f\"Min Accuracy:         {cv_min:.6f}\")\n",
        "    print(f\"Max Accuracy:         {cv_max:.6f}\")\n",
        "    print(f\"95% Confidence Int:   [{cv_mean - 1.96*cv_std:.6f}, {cv_mean + 1.96*cv_std:.6f}]\")\n",
        "\n",
        "    # Performance assessment\n",
        "    if cv_mean > 0.980:\n",
        "        print(\"🎯 EXCELLENT! CV suggests test performance >98.0%\")\n",
        "    elif cv_mean > 0.975:\n",
        "        print(\"✅ VERY GOOD! CV suggests test performance >97.5%\")\n",
        "    elif cv_mean > 0.970:\n",
        "        print(\"✅ GOOD! CV suggests test performance >97.0%\")\n",
        "    else:\n",
        "        print(\"⚠️  NEEDS IMPROVEMENT - CV suggests <97.0%\")\n",
        "\n",
        "    # Stability check\n",
        "    if cv_std < 0.005:\n",
        "        print(\"📊 Model is VERY STABLE across folds\")\n",
        "    elif cv_std < 0.010:\n",
        "        print(\"📊 Model is STABLE across folds\")\n",
        "    else:\n",
        "        print(\"⚠️  Model shows variability across folds - consider more regularization\")\n",
        "\n",
        "    return cv_mean, cv_std, cv_detailed_results\n",
        "\n",
        "# Run enhanced CV evaluation\n",
        "print(\"Starting comprehensive cross-validation evaluation...\")\n",
        "cv_mean, cv_std, cv_details = enhanced_cv_evaluation(train_optimized, n_splits=5)\n",
        "\n",
        "# Final performance prediction\n",
        "predicted_test_performance = cv_mean\n",
        "print(f\"\\n🎯 PREDICTED TEST PERFORMANCE: {predicted_test_performance:.6f}\")\n",
        "\n",
        "if predicted_test_performance > 0.975:\n",
        "    print(\"Ready for submission! Expected to exceed target accuracy.\")\n",
        "else:\n",
        "    print(\"Consider additional tuning before final submission.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5CzZfJMAg-0",
        "outputId": "ed40dcd0-e200-466c-ab61-4f4990596876"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon.tabular==1.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[catboost]==1.3.1) (1.3.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.15.3)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.5)\n",
            "Requirement already satisfied: autogluon.core==1.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.3.1)\n",
            "Requirement already satisfied: autogluon.features==1.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.3.1)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[catboost]==1.3.1)\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.10.0)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.39.9)\n",
            "Requirement already satisfied: autogluon.common==1.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.3.1)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (5.9.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[catboost]==1.3.1) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[catboost]==1.3.1) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[catboost]==1.3.1) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.6.0)\n",
            "Requirement already satisfied: botocore<1.40.0,>=1.39.9 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.39.9)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[catboost]==1.3.1) (8.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1->autogluon.tabular[catboost]==1.3.1) (2025.7.14)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"cv_fold_0\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting comprehensive cross-validation evaluation...\n",
            "Running 5-fold cross-validation for performance verification...\n",
            "============================================================\n",
            "Training fold 1/5...\n",
            "Fold 1 accuracy: 0.965186\n",
            "  Predictions: {'Extrovert': np.int64(3032), 'Introvert': np.int64(1133)}\n",
            "  Actual:      {'Extrovert': np.int64(3021), 'Introvert': np.int64(1144)}\n",
            "Training fold 2/5...\n",
            "Fold 2 accuracy: 0.960624\n",
            "  Predictions: {'Extrovert': np.int64(3025), 'Introvert': np.int64(1140)}\n",
            "  Actual:      {'Extrovert': np.int64(3021), 'Introvert': np.int64(1144)}\n",
            "Training fold 3/5...\n",
            "Fold 3 accuracy: 0.959424\n",
            "  Predictions: {'Extrovert': np.int64(3016), 'Introvert': np.int64(1149)}\n",
            "  Actual:      {'Extrovert': np.int64(3021), 'Introvert': np.int64(1144)}\n",
            "Training fold 4/5...\n",
            "Fold 4 accuracy: 0.968067\n",
            "  Predictions: {'Extrovert': np.int64(3008), 'Introvert': np.int64(1157)}\n",
            "  Actual:      {'Extrovert': np.int64(3021), 'Introvert': np.int64(1144)}\n",
            "Training fold 5/5...\n",
            "Fold 5 accuracy: 0.962545\n",
            "  Predictions: {'Extrovert': np.int64(3043), 'Introvert': np.int64(1122)}\n",
            "  Actual:      {'Extrovert': np.int64(3021), 'Introvert': np.int64(1144)}\n",
            "\n",
            "============================================================\n",
            "CROSS-VALIDATION RESULTS SUMMARY\n",
            "============================================================\n",
            "Mean Accuracy:        0.963169\n",
            "Standard Deviation:   0.003129\n",
            "Min Accuracy:         0.959424\n",
            "Max Accuracy:         0.968067\n",
            "95% Confidence Int:   [0.957036, 0.969302]\n",
            "⚠️  NEEDS IMPROVEMENT - CV suggests <97.0%\n",
            "📊 Model is VERY STABLE across folds\n",
            "\n",
            "🎯 PREDICTED TEST PERFORMANCE: 0.963169\n",
            "Consider additional tuning before final submission.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRWMsR4nWIdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}